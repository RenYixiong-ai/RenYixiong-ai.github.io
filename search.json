[{"title":"Hexo 使用指南","url":"/2024/06/25/CS/hexo/hexo/","content":"主要用于实现我对 Hexo 各种奇奇怪怪的需求。\n\n视频嵌入\nHexo 中嵌入 Bilibili 视频\n&lt;iframe src=&quot;//player.bilibili.com/player.html?aid=你的视频AID&amp;bvid=你的视频BVID&amp;cid=你的视频CID&amp;page=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot; width=&quot;640&quot; height=&quot;480&quot;&gt; &lt;/iframe&gt;\nHexo 中嵌入 Toutube 视频\n&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/你的视频ID&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;\n","categories":["Hexo"],"tags":["Hexo"]},{"title":"A law of data separation in deep learning","url":"/2024/11/07/CS/data_law/data_law/","content":"这篇文章研究机器学习过程中，隐藏层对数据的处理方式，发现数据在等几何定律的分离，并且可以观察到类别的出现，因此总结归纳了一个可以量化的规律。\nReference: * A law of data\nseparation in deep learning * github地址\n\n其针对监督学习任务，接下来讨论的参数均是在同一层中，xki表示第k个类别第i个输出值，x̄k表示第k个类别的均值，x̄表示k个类别的均值。\n定义两个距离矩阵，首先是类别间(between)的距离SSb：\n$$\nSS_b = \\frac{1}{n}\\sum_{k=1}^K n_k(\\bar{x}_k - \\bar{x})(\\bar{x}_k -\n\\bar{x})^T,\n$$ 其中n是总样本量，通过求SSb的逆（伪逆）可以定义类别间的相似性SSb†。同时可以定义同一类(within)中的距离SSw：\n$$\nSS_w = \\frac{1}{n}\n\\sum_{k-1}^K\\sum_{i=1}^{n_k}(x_{ki}-\\bar{x}_k)(x_{ki}-\\bar{x}_k)^T.\n$$\n基于以上内容，定义距离上的“逆信噪比”： D = Tr(SSwSSb†).\n将不同类别间的相似性作为信号，而统一类别间的距离作为噪音，这个量的设计十分自然。并且当D越小，代表分割越好。\n同时在这里我们需要提出一个问题，对于分类任务，类别在高维空间中如何分布是一个很好的构型，等价于我们该从哪几个指标评判在高维空间类别分布。这里引入概念Equiangular\nTight Frame。\n\nPrevalence\nof Neural Collapse during the terminal phase of deep learning\ntraining\n\n他要求向量具有如下的性质：\n\n等角性：任意两个不同的框架向量之间的内积绝对值相同。这样保证了最大的分离。\n紧框架：ETF\n满足能量在向量组中的“紧”分布，这意味着向量组能够均匀地表示信号，满足帧不等式的等式情况。该要求使得模型的鲁棒性质提升。\n\n在实验中发现：\n\n\nSGD\n\n其中每幅图的纵坐标表示D，随着网络深度的加深，网络的分割能力越强。\n\n\nSGD\n\n通过降维，可以发现网络分类能力越来越强。\n基于此文章总结了下降规律为：\nDl = ρlD0\n其中ρ ∈ [0, 1]是一个由网络结构与训练方式决定的量，D0是初始的差别。\nAppend\n\n定义与特性：Equiangular Tight Frame (ETF)\n是一种具有等角性（Equiangularity）和紧帧性（Tightness）特征的向量集合。\n\n等角性：ETF\n中任意两个向量之间的内积绝对值相同，这种等角特性使得向量之间的夹角是均匀的。\n紧帧性：ETF\n满足紧帧条件，即每个向量的投影平方和在整个帧上均匀分布，保证了信号的能量在所有帧向量中保持一致。\n\nSimplex ETF：Simplex ETF 是一种特殊的\nETF，它的向量构成了一个正交单纯形的顶点。这种向量集合具有最均匀的分布，可以看作是理想的分散性参考，用于分析类别或信号分布的均匀性。\n用途和优势：\n\n信号处理与压缩感知：ETF\n的等角和紧帧特性使其非常适合用于稀疏信号的重构和能量均匀分布的信号表示。\n数据分析与分类：ETF\n提供了类别分散度的理想参考，通过比较类别特征向量与 Simplex ETF\n结构的相似性，可以评估类别在特征空间中的分布均匀性。\n鲁棒性和冗余表示：ETF\n的冗余和紧帧特性使得即使部分帧向量丢失，信号依然可以较好地重建，因此在存在噪声或缺失信息时表现出较强的鲁棒性。\n\n几何结构和构造：在实际应用中，ETF\n向量集通常构成一个等距或等角的几何结构（如正交单纯形的顶点），提供了一种理想的框架来衡量和评估向量之间的角度和距离分布。\n\nETF\n是一种在信号处理、压缩感知和数据分析中广泛应用的框架结构，凭借其均匀的能量分布和等角特性，在高维空间中提供了对称性、均匀性和冗余性。ETF\n尤其适用于需要均匀分布和高鲁棒性的场景，是一种用于信号重构、类别分布分析和特征提取的理想框架。\n","categories":["Machine Learning"],"tags":["Spin Glass","Fermi Bose Machine"]},{"title":"Markdown 文章中的交叉引用（利用锚点）","url":"/2024/04/15/CS/anchor_point/anchor_point/","content":"参考文章在带有数学公式的markdown文档里的交叉引用实现。\n这篇文章作为案例，实现公式的交叉引用。\n更多阅读： * 在带有数学公式的markdown文档里的交叉引用\n* $\\LaTeX$在MathJax中的命令 * MathJax\n与 Katex 在公式对齐、编号、交叉引用方面的不同 * Markdown杂记\n\n注意：这里渲染$\\LaTeX$的引擎需要为MathJax，之前还真没注意过这个区别。MathJax支持公式引用，但必须自己手动标号。我觉得应该是因为交叉引用会使实时渲染产生问题。但是可以静态渲染，然后再检查，麻烦了一点。希望这个问题能够解决吧。\n使用cassId方案\n添加锚点\n行间公式\n编号为1 $$\\cssId&#123;1&#125;&#123;\\overline&#123;v&#125;&#125;:\\overline&#123;S&#125;\\to\\&#123;F,T\\&#125;$$ 渲染为： $$\n\\cssId{1}{\\overline{v}}:\\overline{S}\\to\\{F,T\\}\n$$\n接下来加入环境，编号为3\n$$\\begin&#123;align&#125;\\cssId&#123;3&#125;&#123;\\overline&#123;v&#125;&#125;:\\overline&#123;S&#125;\\to\\&#123;F,T\\&#125;\\end&#123;align&#125;$$ 渲染为：\n$$\\begin{align}\n\\cssId{3}{\\overline{v}}:\\overline{S}\\to\\{F,T\\}\n\\end{align}$$\n行内公式\n编号为3： 这是一段没有意义的废话$\\cssId&#123;2&#125;&#123;\\overline&#123;v&#125;&#125;:\\overline&#123;S&#125;\\to\\&#123;F,T\\&#125;$ 渲染为：\n例如这样的行内公式$\\cssId{2}{\\overline{v}}:\\overline{S}\\to\\{F,T\\}$。\n引用锚点\n公式中的引用： \\href&#123; #1&#125;&#123;\\overline&#123;v&#125;&#125;=F(x)\n通过替换#之后的标签引用，而且前面要有空格。\n以下为渲染之后的例子： $$\\href{\n#1}{\\overline{v}}=F(x)$$ $$\\href{\n#2}{\\overline{v}}=F(x)$$ $$\\href{\n#3}{\\overline{v}}=F(x)$$\n使用mathjax方案\n编号为test： $$\\begin&#123;align&#125;a\\neq&amp; b \\label&#123;test&#125; \\\\c\\neq&amp; b \\label&#123;test2&#125; \\\\\\end&#123;align&#125;$$ 渲染为： $$\\begin{align}\na\\neq&amp; b \\label{test} \\\\\nc\\neq&amp; b \\label{test2} \\\\\n\\end{align}$$\n通过$\\eqref&#123;test&#125;$引用$\\eqref{test}$，或者通过$\\ref&#123;test2&#125;$引用公式$\\ref{test2}$。\n用HTML插入方案\n使用&lt;span id=\"anchor_name\"/&gt;来建立锚点，例如：\n&lt;span id=\"anchor_name\"/&gt;这篇文章作为案例，实现公式的交叉引用。\n使用相对地址引用锚点： [点击这里](#anchor_name)\n点击这里\nHexo官方方案\n目前跑通一个，给出下属链接：\n\n官方\n博客\n\n连接到之前的一篇文章： Hexo 使用指南 &#123;% post_link CS/hexo/hexo %&#125;\n","categories":["Note"],"tags":["Markdown"]},{"title":"ZheJiang Lab","url":"/2025/04/27/LLM/2025ZJLab/note/","content":"参加杨东平老师在之江实验室举办的大语言模型研讨会议，从物理、神经计算、生物等方面理解和看待语言模型以及神经网络的发展。\n\nIntroduction\n\n\n会议日程\n\n侧向预测编码\n参考文献： * Discontinuous\nphase transition of feature detection in lateral predictive coding *\nEnergy-information\ntrade-oﬀ induces continuous and discontinuous phase transitions in\nlateral predictive coding\n什么是lateral predictive\ncoding？\n通过观察同一层网络相互之间的关系，从而对自身进行预测，将预测结果与自身对照，产生误差，对误差进行回传。对于同一层的不同变量记为xil，误差ϵil = xil − f(xil)，通过Bottom-up（类似于反向传播）的方式优化。引入lateral\npredictive\ncoding的目的在于可以减少冗余，如果一个网络大部分内容可以预测（ϵ = 0），那么很多的信息就是无用信息。\n这是一个用lateral 方案对MNIST数据集进行预测的例子： # ==== LPC 模拟模型 ====class LPC_MNIST(nn.Module):    def __init__(self):        super().__init__()        self.linear = nn.Linear(28*28, 256)        self.lateral = nn.Linear(256, 256)  # lateral prediction within same layer        self.classifier = nn.Linear(256, 10)            def forward(self, x):        x = x.view(x.size(0), -1)  # 展平        # 主激活        h = torch.relu(self.linear(x))  # shape: (B, 256)        # 侧向预测（当前层内部）        h_detached = h.detach()  # 假设 lateral 连接不能访问当前梯度        h_pred = self.lateral(h_detached)  # h_i ≈ f(h_j≠i)        # 预测误差        error = h - h_pred        # 用预测误差作为表征送入分类器        out = self.classifier(error)        return out, error\n注意到，最后进行分类所使用的特征数据是误差ϵ。\n理论框架\n将LPC写为动力学过程： $$\n\\begin{align}\n\\frac{d \\bf x}{d t} = \\bf s -\\bf x - \\bf W \\bf x\n\\end{align}\n$$ 其中$\\bf s$是输入向量，$\\bf x$可以认为是预测误差。稳定解为：$\\bf x=(\\bf I+\\bf W)^{-1}\\bf s$。\n将预测误差和定义为能量： $$\\begin{align}\nE\\,\\equiv\\,\\sum_{i=1}^{N}\\Bigl\\langle\\bigl|x_{i}\\bigr|\\Bigr\\rangle\\,=\\,\\sum_{i=1}^{N}\\Bigl\\langle\\Bigl|\\sum_{j=1}^{N}\\bigl(\\frac{I}{I+W}\\bigr)_{i\nj}s_{j}\\Bigr|\\Bigr\\rangle\n\\end{align}$$\n熵为（文章的补充材料中有证明）： $$\\begin{align}\nS=-\\log\\bigl[\\operatorname*{det}(I+W)\\bigr]\n\\end{align}$$\n以熵作为输出信息的复杂度，从自由能和能量竞争的理论出发，发现lateral编码会出现非连续相变，或许进一步揭示了lateral\npredictive coding的潜在运行机制。\n核心思路是，定义能量，并且通过随机矩阵计算熵的表达式，通过自由能最小化的方式，用温度调控两者的分布\n大模型机理分析——数据合成与慢思考机制\n刘勇老师研究LLM如何进行思考，从泛化上界的视角研究MCTS提升模型能力的原理。\n我的思考是，如何把多智能体的想法和泛化上界相结合，通过证明把人类的经验总结进prompt会提升模型的表达能力。\n通过凝聚现象理解语言模型的推理与记忆\n参考文献： - Initialization is\nCritical to Whether Transformers Fit Composite Functions by Reasoning or\nMemorizing - ANCHOR\nFUNCTION: A TYPE OF BENCHMARK FUNCTIONS FOR STUDYING LANGUAGE\nMODELS\n通过设计精巧实验(称为 anchor\nfunction)，分析不同初始化方法下，模型产生的记忆与推理两种模式。\nAnchor function\nOne-anchor function\n考虑函数 f(X) : ℝn × d → ℝd\n，n是输入信息的长度，d是tokens的长度，X = (x1, x2, x3⋯xn)并且xi ∈ ℝd。有如下的映射关系：\n$$\\begin{align}\nf(\\mathbf{x_1}, \\mathbf{x_2}, \\mathbf{x_3}\\cdots\\mathbf{x_n}) =\n\\mathbf{x_{i+1}}\\quad \\text{where}\\quad x_i =a\n\\end{align}$$\n例如对于d = 1维、a = 3的情况下f(12, 33, 14, 3, 42, 54, 34, 20, 28) = 42。其中a = 3是一个钩子，找到序列中对应的位置，然后给出后一个位置的结果。可以得到一个更加普适的函数：\n$$\\begin{align}\nf(\\mathbf{x_1}, \\mathbf{x_2}, \\mathbf{x_3}\\cdots\\mathbf{x_n}) =\ng(\\mathbf{x_{i+1}})\\quad \\text{where}\\quad x_i =a\n\\end{align}$$ 其中𝕩𝕚为钩子(anchor)项，对应的𝕩𝕚 + 𝟙是钥匙(key)项。\nTwo-anchor composite\nfunction\nAnchor 集为一系列不同的token，例如A = {a1, a2, ⋯, aJ}，输出函数为g(𝕩; ak)。在每一个输入的序列中，有且仅有一对连续元素属于A： $$\\begin{align}\nf(\\mathbf{x_1}, \\mathbf{x_2}, \\mathbf{x_3}\\cdots\\mathbf{x_n}) =\ng(g(\\mathbf{x_{i-1}};\\mathbf{x_{i}});\\mathbf{x_{i+1}})\\quad\n\\text{where}\\quad x_i,x_{i+1} \\in A\n\\end{align}$$\n可以得到以下集中任务分类： \nExperiment\n\n\nfigure\n\n上图是实验示意图，输入包含三个部分：anchor项（黄色）、key项（橙色）、噪声项（灰色），输出为目标结果。anchor项是与众不同的，这个实验中为1, 2, 3, 4，并且每一种anchor表示对key项的一个操作。一共有用16种组合，其中15种项是在训练过程中作为输入集，并且这里面有14个是可以通过推理得出的，(3, 4)这个组合只能通过记忆得出，一组(4, 3)用于测试。这组测试anchor会给出三种可能的结果，一种是学习到对称性给出和(3, 4)一样的解，一种是学习到推理解，以及其它非推理解。\n通过实验发现，解的类型和初始化参数、网络深度有关，通过设置超参γ调控不同的学习模式，1/dinγ是每层参数的标准差，其中din是输入神经元数目。\n\n从实验中可以发现，存在一个明显的分界线，在不同的超参下识别的结果存在明显的分别。可能的解释是，在方差较小的时候，参数变化小，因此需要学习推理的内容；当方差变大模型可以学习更多的内容，因此参数倾向于记忆内容；方差进一步增大，模型会记忆更多内容，正确率下降。\n从以下几个方面分析模型学习到不同策略的原因： * 信息流 *\n信息在向量空间的表示 * 不同观点下的模型复杂度\n\n\ninformation-flow\n\n上面是从信息流动的角度分析，浅层的网络对于信息处理起到了重要的作用。(a)(b)图分析了对称解的情况，浅层网络将anchor映射到一组位置，然后将key表示在这个结果上；在图(b)中通过t-SNE降维的方法，将不同anchor得到的结果降维，发现能够很好分类。图(c)是推理的结果，显示会先把key映射到对应的anchor上然后进行处理。\n\n\ninformation-cosine\n\n上图是度量cosine相似度的热力图。图(a)是推理的结果，红框表示是相同的输出结果，可以发现，其具有很高的相似度；图(b)是对称的结果，基本没有相似性。这样显然的区别，表明模型推理能力和结构有关。为了进一步验证这个猜想，设计one-anchor的实验（图c），发现模型确实在推理的结果上表现相似。\n\n\ninformation-para\n\n上图(a)(b)是计算参数的权重Wcosin距离的热力图，其中图(a)表示推理的结果，可以看到出现明显的方向性，图(b)是对称解，并没有明显的方向性，复杂度柔和进模型中。图(c)(d)为t-SNE之后的embedding结果，图(c)为推理解有明显的方向，相比之下对称解图(d)显得杂乱。\n深度学习机理的动力学分析\n赵鸿老师通过自己的方式，从数据和参数层面，分析神经网络的相关性质，很物理也很有趣。\n储备池计算\n参考文献： * Recent advances in\nphysical reservoir computing: A review\n储备池计算（Reservoir\nComputing），就是通过非线性的动力学过程将数据特征升至高维时间空间中，从而完成特征提取。\n 上图是储备池计算的示意图，在a图中输入权重Win与动力学参数W是固定参数，不参与训练。只训练读出头部分Wout。\n大语言模型的训练\n陈星强和吴生礅在进行大模型的训练，通过unsloth这个包。重复这个工作，找他俩商量聊天，完成这个任务。\n","categories":["Machine Learning"],"tags":["Multi-Agent","Prompt"]},{"title":"DeepSeek","url":"/2025/02/08/LLM/DeepSeek/DeepSeek/","content":"回顾DeepSeek模型发展过程，从最初的数据训练和模型搭建出发，为了在受限的硬件条件下创在出更加高效的模型，修改模型的架构，最后提出基于强化学习的模型微调方案。\nReference: * DeepSeek LLM\nScaling Open-Source Language Models with Longtermism * DeepSeekMath: Pushing the Limits\nof Mathematical Reasoning in Open Language Models * DeepSeek-V2: A Strong,\nEconomical, and Efficient Mixture-of-Experts Language Model * DeepSeek-V3 Technical Report\n* DeepSeek-R1: Incentivizing\nReasoning Capability in LLMs via Reinforcement Learning * DeepSeekMoE: Towards Ultimate\nExpert Specialization in Mixture-of-Experts Language Models * Brief analysis of DeepSeek R1\nand its implications for Generative AI * Auxiliary-Loss-Free Load\nBalancing Strategy for Mixture-of-Experts * Training language models to\nfollow instructions with human feedback\n\nDeepSeek-V1\n重复数据删除（deduplication）：唯一性的实例。\n过滤（filtering）:增强数据的信息密度。\n混合（remixing）：多样化表示。\n在tokenizer过程中，使用Byte-level Byte-Pair Encoding (BBPE)\n算法。\n模型结构基于LLaMA\nDeepSeek-V2\n在模型架构上进行改变，引入Multi-head Latent Attention\n(MLA)，并且使用混合专家模型Mixture-of-Experts\n(MoE)节省参数量级。这个版本的俄模型，核心在于经济、高效的训练。\n\n\n模型表现能力\n\n图中展示了使用混合技术带来的模型能力提升。\n\n\n模型结构\n\n在新的架构中，Attention部分通过重新设计进一步压榨硬件设备的性能和传统的Transformer有什么区别？。\n同时为了提升推理的精度，在Feed-Forward\nNetwork部分采用专家模型不同类型的专家模型，分别在什么时候使用呢？如果和共享的模块一样，需要进行全部的推理，这个专家模块依旧十分消耗硬件资源。\n\n\nTransformer\n\n经典的Multi-Head Attention (MHA)结构如下：\n$$\\begin{aligned}\n&amp; {\\left[\\mathbf{q}_{t, 1} ; \\mathbf{q}_{t, 2} ; \\ldots ;\n\\mathbf{q}_{t, n_h}\\right]=\\mathbf{q}_t} \\\\\n&amp; {\\left[\\mathbf{k}_{t, 1} ; \\mathbf{k}_{t, 2} ; \\ldots ;\n\\mathbf{k}_{t, n_h}\\right]=\\mathbf{k}_t,} \\\\\n&amp; {\\left[\\mathbf{v}_{t, 1} ; \\mathbf{v}_{t, 2} ; \\ldots ;\n\\mathbf{v}_{t, n_h}\\right]=\\mathbf{v}_t,} \\\\\n&amp; \\mathbf{o}_{t, i}=\\sum_{j=1}^t\n\\operatorname{Softmax}_j\\left(\\frac{\\mathbf{q}_{t, i}^T \\mathbf{k}_{j,\ni}}{\\sqrt{d_h}}\\right) \\mathbf{v}_{j, i} \\\\\n&amp; \\quad \\mathbf{u}_t=W^O\\left[\\mathbf{o}_{t, 1} ; \\mathbf{o}_{t, 2}\n; \\ldots ; \\mathbf{o}_{t, n_h}\\right]\n\\end{aligned}$$\n由于每一个向量都需要单独的存储k, q, v矩阵，造成很高的存储开销。为了节省开销，采用Low-Rank\nKey-Value Joint Compression技术，提出新的Multi-Head Latent\nAttention（MLA），保存低纬信息ctkv通过上投影技术，还原k, v的值。\n$$\\begin{aligned}\n\\mathbf{c}_t^{K V} &amp; =W^{D K V} \\mathbf{h}_t \\\\\n\\mathbf{k}_t^C &amp; =W^{U K} \\mathbf{c}_t^{K V} \\\\\n\\mathbf{v}_t^C &amp; =W^{U V} \\mathbf{c}_t^{K V}\n\\end{aligned}$$\n专家模型为：\n$$\\begin{aligned} &amp;\n\\mathbf{h}_t^{\\prime}=\\mathbf{u}_t+\\sum_{i=1}^{N_s}\n\\operatorname{FFN}_i^{(s)}\\left(\\mathbf{u}_t\\right)+\\sum_{i=1}^{N_r}\ng_{i, t} \\operatorname{FFN}_i^{(r)}\\left(\\mathbf{u}_t\\right), \\\\ &amp;\ng_{i, t}= \\begin{cases}s_{i, t}, &amp; s_{i, t} \\in\n\\operatorname{Topk}\\left(\\left\\{s_{j, t} \\mid 1 \\leqslant j \\leqslant\nN_r\\right\\}, K_r\\right), \\\\ 0, &amp; \\text { otherwise, }\\end{cases} \\\\\n&amp; s_{i, t}=\\operatorname{Softmax}_i\\left(\\mathbf{u}_t^T\n\\mathbf{e}_i\\right),\\end{aligned}$$\n其中FEN(s)是通用(share)权重，FEN(r)是专家（routed\nexperts）权重。\n在损失函数的设计上，集中于三部分：专家权重、硬件平衡、通讯平衡。同时为了减轻由于加载不要均衡造成的问题，引入了Token-Dropping技术。\nDeepSeek-V3\n为了均衡模型表现性能和加载均衡，V3的混合专家模型中采用了auxiliary-loss-free\nload balancing strategy。\n$$g_{i, t}^{\\prime}= \\begin{cases}s_{i,\nt}, &amp; s_{i, t}+b_i \\in \\operatorname{Topk}\\left(\\left\\{s_{j, t}+b_j\n\\mid 1 \\leqslant j \\leqslant N_r\\right\\}, K_r\\right), \\\\ 0, &amp; \\text\n{ otherwise } .\\end{cases}$$\n给专家模型增加一个偏置项。这个偏置项有什么作用呢？为什么通过这个偏置能够均衡之前的问题。定义超参γ为偏执更新速度，如果一个专家模型过载，将会通过参数γ来降低偏置；相反，如果调用过多就会通过过参数γ提升其偏置。\nDeepSeek-R1\n\n\nR1表现能力\n\n主要贡献在于使用纯强化学习的方式进行微调，获得更高的表现能力。模型基座是DeepSeek-V3。\n模型DeepSeek-R1-Zero使用完全的强化学习思路，没有其它的数据进行有监督微调；模型DeepSeek-R1同样使用强化学习进行微调，但是使用少量的数据（long\nChain-of-Thought examples）进行微调，有更好的表现能力。\n采用基于PPO算法改进的Group Relative Policy Optimization\n(GRPO)算法，放弃评价模型（critic model），使用群体分数估计baseline。\n$$\\begin{gathered}\n\\mathcal{J}_{G R P O}(\\theta)=\\mathbb{E}\\left[q \\sim\nP(Q),\\left\\{o_i\\right\\}_{i=1}^G \\sim \\pi_{\\theta_{o l d}}(O \\mid\nq)\\right] \\frac{1}{G} \\sum_{i=1}^G\\left(\\min\n\\left(\\frac{\\pi_\\theta\\left(o_i \\mid q\\right)}{\\pi_{\\theta_{o l\nd}}\\left(o_i \\mid q\\right)} A_i,\n\\operatorname{clip}\\left(\\frac{\\pi_\\theta\\left(o_i \\mid\nq\\right)}{\\pi_{\\theta_{\\text {old }}}\\left(o_i \\mid q\\right)},\n1-\\varepsilon, 1+\\varepsilon\\right) A_i\\right)-\\beta \\mathbb{D}_{K\nL}\\left(\\pi_\\theta| | \\pi_{r e f}\\right)\\right) \\\\ \\mathbb{D}_{K\nL}\\left(\\pi_\\theta| | \\pi_{r e f}\\right)=\\frac{\\pi_{r e f}\\left(o_i \\mid\nq\\right)}{\\pi_\\theta\\left(o_i \\mid q\\right)}-\\log \\frac{\\pi_{r e\nf}\\left(o_i \\mid q\\right)}{\\pi_\\theta\\left(o_i \\mid q\\right)}-1\n\\end{gathered}$$\n优势函数A为： $$A_i=\\frac{r_i-\\operatorname{mean}\\left(\\left\\{r_1,\nr_2, \\cdots, r_G\\right\\}\\right)}{\\operatorname{std}\\left(\\left\\{r_1,\nr_2, \\cdots, r_G\\right\\}\\right)}$$\n\n\nPPO vs GRPO\n\n上面是PPO与GRPO的对比图。PPO算法核心为通过裁切限制算法的优化幅度，在公式中表现为：\n$$\n\\min \\left(\\frac{\\pi_\\theta\\left(o_i \\mid q\\right)}{\\pi_{\\theta_{o l\nd}}\\left(o_i \\mid q\\right)} A_i,\n\\operatorname{clip}\\left(\\frac{\\pi_\\theta\\left(o_i \\mid\nq\\right)}{\\pi_{\\theta_{\\text {old }}}\\left(o_i \\mid q\\right)},\n1-\\varepsilon, 1+\\varepsilon\\right) A_i\\right)\n$$\nGRPO在这基础上计算多个优势函数取平均。为了减轻奖励模型的过优化问题，在其中加入了KL散度作为惩罚项，并且通过β调整惩罚项的大小，为了使得KL散度恒为正，进行了一些调整。\n","categories":["Machine Learning","Large Language models"],"tags":["Machine Learning","Reinforcement Learning"]},{"title":"Transformer Attention as a Bayesian Manifolds","url":"/2026/01/02/LLM/Bayesian_Transformer/Bayesian_Transformer/","content":"Transformer不是在特定情形下进行贝叶斯推断，而是作为其工作的基本原理。或者说Transformer本质上就是在几何上的贝叶斯推断引擎。该论证工作分为三步进行，首先通过精巧的实验设计，验证Transformers与贝叶斯推断等价，然后解释这种等价性的源头，最后进行结论外推，在更广泛更真实的情境下这种等价性是否存在。\nReference: * The Bayesian\nGeometry of Transformer Attention * Gradient\nDynamics of Attention: How Cross-Entropy Sculpts Bayesian Manifolds\n* Attention Is Bayesian\nInference * Geometric\nScaling of Bayesian Inference in LLMs * 优化即几何，几何即推理：用数学终结Transformer的黑盒时代\n\n实验设计\n文章提出了贝叶斯风洞实验（Bayesian wind\ntunnels），一种完全受控的实验环境。通过双射消除和隐马尔科夫模型，验证Transformers等价于贝叶斯推断，\nresidual\nstreams是信念提取、推理是后验更新、注意力提供了文本地址路由。\n很有意思的论证过程，通过一个实验完成了Transformers的三个角度叙述： 1.\n贝叶斯风洞实验是什么？这种实验设计精巧在什么地方？对模型本身进行了什么裁减，这种裁减是否合理？\n2.\n文章接下来描述到几何上面，这里需要考虑几何和Transformers是如何联系的？几何与贝叶斯推断是怎么联系的？\n3. residual streams、 feed-forward\nnetworks、attention三个指标是否能完全涵盖Transformers的推理过程么，这是否完备？\n理论框架\n考虑潜在参数θ ∼ π(θ)，对于每一个任务，从一个特定分布中提取输入数据x，标签写为 y ∼ p(y ∣ x, θ)，模型观测到文本c = {(xi, yi)}i = 1k，并必须从新的输入中给出预测。通过最小化交叉熵损失函数得到模型权重：\nℒ(q) = Eθ ∼ πEc, (x, y) ∼ p(⋅|θ)[−log q(y ∣ x, c)]\n最小化交叉熵损失函数就是贝叶斯后验分布： $$\\begin{align}\n&amp;q^\\star(y \\mid x, c)\n~=~\n\\int p(y \\mid x, \\theta)\\,\np(\\theta \\mid c)\\, d\\theta \\\\\n&amp;p(\\theta \\mid c)\n~\\propto~\n\\pi(\\theta) \\prod_{(x_i,y_i)\\in c} p(y_i \\mid x_i, \\theta)\n\\end{align}$$\n为验证模型为贝叶斯推断，核心点在于设计实验，通过贝斯推断计算结果并与模型预测结果相比较，一致则说明模型的推理过程为贝叶斯推断。\n双射实验\n考虑一个双设的任务π : {1, …, V} → {1, …, V}，输入前k − 1个观测𝒪k − 1，预测的输入xk是之前没有训练过的，因此贝叶斯规则变为：\n$$\\begin{equation}\np(\\pi(x_k)=y \\mid c)=\n\\begin{cases}\n\\dfrac{1}{V-k+1}, &amp; y\\notin \\mathcal{O}_{k-1},\\\\\n0, &amp;\\text{otherwise}.\n\\end{cases}\n\\end{equation}$$\n因此后验熵为： HBayes(k) = log2(V − k + 1)\n隐马尔科夫模型(HMM)\n考虑转移矩阵$T \\in \\R^{S\\times\nS}$和估计矩阵$E \\in \\R^{S\\times\nV}$，以及初始状态π0，当观测到前t步之后，模型后一步的隐藏概率为：\n$$\\begin{equation}\n\\alpha_t(s)\n~=~\np(s_t=s \\mid o_{1:t})\n~=~\n\\frac{\nE(o_t \\mid s)\n\\sum_{s'} T(s \\mid s') \\alpha_{t-1}(s')\n}{\n\\sum_{s''} E(o_t \\mid s'') \\sum_{s'} T(s'' \\mid s') \\alpha_{t-1}(s')\n}\n\\end{equation}$$\n因此后验熵为： $$\\begin{equation}\nH_{\\text{Bayes}}(t)\n~=~\n-\\sum_{s=1}^S \\alpha_t(s)\\log_2 \\alpha_t(s)\n\\end{equation}$$\n实验设计\n在两个实验上，对比理论与实验结果的差异： $$\\begin{equation}\n\\text{MAE}=\\frac{1}{L}\\sum_{t=1}^{L}\n\\bigl| H_{\\text{model}}(t) - H_{\\text{Bayes}}(t) \\bigr|\n\\end{equation}$$\n双射实验长度为20，选取其中100000条作为测试，前面的输入数据为 [x1, y1, SEP, x2, y2, SEP, …, x19, y19, SEP]\n \n总结\n回答最开始的问题，风洞实验指的是完全受控的实验环境，在这篇文章中是双射实验和隐马尔科夫模型\n理论验证\n文章的起源是为什么简单的交叉熵损失函数，可以在大模型中产生独特的几何结构，从而达到贝叶斯推断过程。因此提供了一阶分析，刻画交叉熵重塑注意力机制分数和价值向量。\n$$\\begin{align}\n&amp;\\frac{\\partial L}{\\partial s_{ij}}\n= \\alpha_{ij}\\bigl(b_{ij}-\\mathbb{E}_{\\alpha_i}[b]\\bigr),\n\\qquad\nb_{ij} := u_i^\\top v_j \\\\\n&amp;\\Delta v_j = -\\eta\\sum_i \\alpha_{ij} u_i\n\\end{align}$$\nGradient descent  ⇒  Bayesian\nmanifolds  ⇒  In-context inference.\n核心是通过更新梯度，描述梯度变化在几何上的展现形式。如下图所示，value会被更新到上游u的方向上（图中蓝色与更新方向红色），并且v的联合变化也会回传到整体变化方向g上。\n\n\n几何解释梯度变化\n\n整个过程类似于最大化似然估计(EM)。\n","categories":["Machine Learning"],"tags":["Large Language Model","Bayesian Optimization"]},{"title":"Why Do Multi-Agent LLM Systems Fail?","url":"/2025/04/07/LLM/MultiAgentFail/MultiAgentFail/","content":"多智能体（Multi-Agent System,\nMAS）合作处理问题的思路十分流行，但是在一些热门的batchmark上并没有明显的表现差距。本文针对MAS没有性能提升的问题进行探究，总结出以下三个方面：\n\nspecification and system design failures\ninter-agent misalignment\ntask verification and termination.\n\n文献： * Why Do\nMulti-Agent LLM Systems Fail? * 源代码GitHub\n\nIntroduction\n单智能体，是通过精心设计prompt，用于处理特定问题的语言模型。多智能体（Multi-Agent\nSystem,\nMAS）是通过合理设计流程，使智能体与环境、相互交流，并且可以读取文档、历史记录等信息，用于处理复杂、多步的真实世界问题，目前已经在多个方面进行探索——软件工程、药物发现、科学模拟以及通用目标智能体。\nMAS相对于单智能体，有效原因普遍认为来自于协同努力、任务目标的分解、并行化、文本独立、集成特定模型以及逻辑性讨论。但是在实际情况中，针对一些问题构建的MAS在泛化的问题上没有普遍提升，目前依旧没有恰当方式构建鲁棒、稳定的MAS。因此针对更加核心、基本的问题“为什么MAS会失败呢？”进行讨论。\n基于社会学的方法（Grounded\nTheory），提出了多智能体失败分类(Multi-Agent System Failure Taxonomy,\nMASFT)。为了使判别自动化，同时提出了LLM作为评判的管线，通过Cohen’s\nKappa一致性指标表明和人类评价具有较高的一致性(0.77)。\nMASFT\n\n\nMASFT\n\n这个表格中囊括了三个阶段：对话前(Pre\nExecution)、对话中(Execution)、对话后(Post\nExecution)；这三个阶段分别表示了问题出现的位置。同时也存在三种类型：系统与角色错误(Specification\nand System Design Failures)、智能体对话失调(Inter-Agent\nMisalignment)、任务验证与终止(Task Verification and\nTermination)。问题的跨度越长，代表这个问题在MAS中越容易发生错误。\nFunction\n\n\nFail\n\n展示如何通过Grounded Theory中的方法，界定不同类别。\nBetter MAS\n针对MAS失败的原因，针对策略与结构两方面提出可能的解决思路。在策略上针对难以解决的问题，设定专门的prompt；在结构上，大多数的系统失败因素是由于，较弱以及非独立的验证方式，可以针对这点进行改进。\n","categories":["Largent language Model"],"tags":["Multi-Agent","Prompt"]},{"title":"RECONCILE and ReAgent","url":"/2025/04/13/LLM/multiAgent/multiAgent/","content":"提出两种多智能体合作方案。\n文献： * RECONCILE:\nRound-Table Conference Improves Reasoning via Consensus among Diverse\nLLMs * ReConcile\ncode * ReAgent:\nReversible Multi-Agent Reasoning for Knowledge-Enhanced Multi-Hop QA\n* []\n\nRECONCILE\nRECONCILE(Round-Table Conference Improves Reasoning via Consensus\namong Diverse\nLLMs)，通过不同预训练模型相互合作，通过一致性完成推理任务。\n多智能体合作的有效性，来源三个方面： 1. 解决方案多样性 2.\n估计每一个智能体的一致性 3. 利用一致性使得不同智能完成合作\n\n左边是传统的思路，通过单个预训练模型，利用不同的prompt搭建智能体，通过不同的结构设计达成目标。右边这篇论文提出的新方案，采用多个预训练模型通过多轮圆桌讨论对话完成任务目标。\n\n左侧是一轮的流程，右侧展示了三轮对话之后的情况。\n\n算法流程图。\nReAgent\nReAgent(a Reversible\nmulti-Agent)是一种新的多智能体架构，通过显式的回溯历史记录增强多跳步(multi-hop)的推理。\n\n解决multi-hop推理问题，需要的信息碎片多、逻辑链条长，对于LLM来说具有挑战性。已经有的解决方案是通过模型的推理，这个依靠模型训练阶段的表现，另一种方案是MAS。MAS通过前向的逐步推理，能够有效提升模型在multi-hop问题上的表现能力，但是其有一些问题，如果模型在最开始就出现错误，之后很难对这个结果进行纠正。一些MAS框架开始着手于解决这个问题，包括ReAgent。\n\n上图是ReAgent的体系架构，分为推理与回溯两部分。左边是推理部分，分为执行层、监督层、交互层：在执行层中将复杂的任务分解为子问题，给出推断然后检查验证，最后整合答案输出；交互层负责提供信息的读取的接口；监督层负责处理冲突，并且检查是否符合规则。右边的回溯机制，展示了执行与监督层是工作交互的逻辑。\n \n","categories":["Largent language Model"],"tags":["Multi-Agent","Prompt"]},{"title":"Detailed balance in large language model-driven agents","url":"/2025/12/17/LLM/DB_LLM/DB_LLM/","content":"研究神经网络的势能分布一般从损失函数的哈密顿量出发，然而损失函数一般是局域的分布，很难解释深度情况的。本文作者提供了一种全新的解析视角，通过对数据采样，依靠样本间的流动构造伪势能解释样本流动的原因。\nReference: * Detailed\nbalance in large language model-driven agents * code\n* data\n\n之前和作者聊过，提出该工作的动机是因为其之前的LLM+符号回归的工作，核心思路是将之前遗传算法等算子切换为LLM，从中发现LLM似乎重视提出几个相似的算子。由此提出了势能的想法。这是一篇很有意思的工作，从唯相的角度研究势能分布。在细致阅读前有这样几个问题：\n1. 为什么是细致平衡？众所周知，细致平衡不是平衡态的必要条件。 2.\n具体的实现细节我还没有想到，是如何从状态转移提取势能。 3.\n大模型返回的样本，是否会收到提示词的影响？即提示词是否会改变势能的形状？\n4. 这种转移背后对应的物理含义是什么？势能表示的是什么势能？\nTheory\n\n\n示意图\n\n给模型一串输入让模型按照设定的约束给出输出，这样的一个过程认为是从一个采样点跳跃到另一个采样点𝒯(g ← f) = P(g|f)。上图是根据约束的样本空间表面，从一个点到另一个点认为是一个跳跃。\n这个约束是将26个字母进行标号，要求给出的词和为100。具体的prompt为：\nprefix = &quot;If the 26 English letters A B C D E F G H I J K L M N O P Q R S T U V W X Y Z correspond to the numbers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 respectively, then ~ Knowledge K + N + O + W + L + E + D + G + E = 11 + 14 + 15 + 23 + 12 + 5 + 4 +7 +5 = 96% Workhard W + O + R + K + H + A + R + D = 23 + 15 + 18 + 11 + 8 + 1 +18 + 4 = 98% This means that knowledge and hard work can contribute up to 96% and 98% to our lives. Is it Luck? L + U + C+ K = 12 + 21 + 3 + 11 = 47% Is it Love? L + O+ V + E = 12 +15+ 22 + 5 = 54% It seems that these things we usually consider important do not play the most crucial role. So, what can determine our life at 100%? Is it Money? M + O + N + E + Y = 13 +15 +14 + 5 + 25 = 72% It seems not.&quot;prompt = (    f&quot;&#123;prefix&#125;&quot;    f&quot;An example word is &#123;words&#125;, whose letters add up to 100%. &quot;    &quot;Please give me a new word whose letters add up to 100%. &quot;    &quot;Only provide the word without any additional explanation.&quot;)\n作者假设采样空间是平衡态，采用了较强的平衡假设——细致平衡条件，从f → g以及g → f之间应当满足P(g|f) = P(f｜g)。\n假设这样的跳转，类似于运动的变化，运动能量来源于某种势能“V”（动力学过程中的Lyapunov\nfunction），定义这种驱动项为K (V(f) − V(g))。其中K是非凸函数，本文采用K(x) = exp (−βx/2)。从而定义作用量S为：\n$$\\begin{align}\n  \\mathcal{S} = \\int_{f\\in \\mathcal{C}}\\int_{g\\in \\mathcal{C}}\n\\mathcal{T}(g\\gets f)\\, K\\!\\left(V(f)-V(g)\\right)\\, Df\\, Dg\n\\end{align}$$\n通过对作用量变分δ𝒮 = 0得到： $$\\begin{align}\n  \\int_{g \\in \\mathcal{C}} \\mathcal{T}(g\\gets f)\\,\nK'\\!\\left(V_{\\mathcal{T}}(f)-V_{\\mathcal{T}}(g)\\right)\\, Dg\\nonumber -\n\\int_{h \\in \\mathcal{C}} \\mathcal{T}(f\\gets h)\\,\nK'\\!\\left(V_{\\mathcal{T}}(h)-V_{\\mathcal{T}}(f)\\right)\\, Dh = 0\n\\end{align}$$\n接下来通过训练，给每一个状态标出一个标量，最小化变分量，从而使其满足细致平衡条件。\nExperiments\n\n上图给出了不同结果之间的距离，以及跳到标量最低的值。\n","categories":["Machine Learning","Large Language models"],"tags":["Machine Learning"]},{"title":"Large Language Diffusion Models","url":"/2026/01/07/LLM/LLDM/LLDM/","content":"现在的大语言模型是变分自回归模型，这篇文章提出了通过生成扩散的过程训练大语言模型(Large\nLanguage Diffusion with mAsking,\nLLaDA)。并通过实验验证模型能力，同时证明LLM的能力并非依赖变分自回归训练机制。\nReference: * Large Language Diffusion\nModels * Code \n文章核心是提出了LLM扩散训练方法，改变了之前仅仅依靠变分自回归的训练方式。可以想到的核心问题：\n1. 扩散训练方式是什么？ 2.\n通过什么指标，在哪些任务上与经典模型对比？\nDiffusion\n首先从理论上证明变分与自回归在理论上等价： maxθ𝔼pdata(x)log pθ(x) ⇔ minθKL(pdata(x)||pθ(x))\n扩散的训练目标是在数据的期望上，模型的概率期望分布最小；而变分训练的目标是目标分布与变分分布的KL散度最小。\n训练\n\n\nLLaDa整体训练方式。\n\n训练阶段与经典的自回归过程一致，分为预训练与微调两阶段。在(a)图中为模型预训练过程，在文本中随机遮盖一部分token，遮盖的概率为U[0, 1]；(b)图为模型的微调过程，只有回答的部分进行遮盖；(c)图为采样过程（推理过程），其中扩散过程从t = 1（完全遮盖）到t = 0（无遮盖）过程。\n \n采样过程与扩散模型在图片中应用一致，逐步减去遮盖，使用交叉熵作为损失函数：\n$$\\mathcal{L}(\\theta)  \\triangleq   -  \\mathbb{E}_{t,\nx_0,  x_t} \\left[\\frac{1}{t} \\sum_{ i = 1 }^L \\textbf{1}[x_t^i =\n\\textrm{M}] \\log p_{\\theta}(x_0^i|x_t) \\right]$$ 其中x0为训练集采样的点，t ∈ [0, 1]的随机变量，xt是模型前向传播采样的点，其中1确保只计算遮盖的点。\n推理\n\n\n推理\n\n首先给予prompt——p0，然后离散化恢复过程，从全遮盖模型中采样。采样的步数是一个速度与质量取舍的超参。中间步骤将之前生成的rt与p0同时输入，计算pθ(rt + 1|p0, rt)，给出遮盖的部分。同时计算如下期望以消除偏差，让模型持续处于正确的路上：\n$$ -\\mathbb{E}_{l, r_0, r_l}\n\\left[\\frac{L}{l} \\sum_{i=1}^L \\textbf{1}[r_l^i = \\textrm{M}] \\log\np_{\\theta}(r_0^i|p_0, r_l) \\right]$$\n实验\n实际效果比较一般，作者同样承认这篇文章的贡献主要在于新的训练方法。\n\nOur\nmodel adopts a novel learning paradigm that differs from the traditional\nautoregressive approach which has been well-established in both industry\nand academia for years.\n\n总结\n这篇文章想要说明自己提供了扩散+语言模型的想法，实际上作者还是使用自回归+Bert的构思。创新点在与采用动态的掩码设计，与Bert固定掩码不同。\n文章中没有体现出，扩散模型连续的性质，实际上还是离散自回归的思路。\n","categories":["Large Language Model"],"tags":["Large Language Model","Physics","Diffusion Model"]},{"title":"Active Learning Literature Survey","url":"/2024/10/16/DL/ActiveLearning/ActiveLearning/","content":"介绍Active\nLearning的基本概念与算法，以及相关python库——ALiPy的使用。\n\nThe key idea behind active learning is that a machine learning\nalgorithm can achieve greater accuracy with fewer labeled training\ninstances if it is allowed to choose the data from which is learns.\n\nReference: * Active\nLearning Literature Survey * ALiPy: Active Learning in\nPython * GitHub:ALiPy\n\nIntroduction\n\n\nactive learning\n\nactive\nlearning的任务是利用可选择标注的样本的优势，在使用较少的情况下以高正确率完成训练。上图中说明，active\nlearning从没有标签的u中选择数据，让人工对其进行标注。\n\n\nexample\n\n上图很好的说明这个问题，(a)是需要分类的两个数据，(b)为随机选取30个点进行分类的结果，(c)是通过active\nlearning 选择的30个样本，其结果与正确分类十分一致。\nScenarios\n其中包含三个主要方案： * membership query synthesis * stream-based\nselective sampling * pool-based active learning\n\n\nScenarios\n\nMembership Query Synthesis\n这种方案不依赖于事先的分布，可以从相空间中随意选取。优势是非常直接且直观，但是问题是该方案很容易生成一些没有特征指标的内容，在人类标注的过程中会困惑，例如手写数字体识别给出四不像的内容。\nStream-Based Selective\nSampling\n首先从真实的分布中进行选取，然后由learner从中决定是否打标签，这一过程称之为（stream-based\nor sequential active learning）\nPool-Based Active Learning\n真实世界中，很多样本可以单次批量化标注，因此一些方案是将大的未标注区域分为小的未标注区域，然后集中进行标注。\nQuery Strategy Frameworks\nactive\nlearning需要计算未标注数据的信息，该章节总结了通常的计算框架。定义xA*为通过算法A最富有信息的实例。\nUncertainty Sampling\n通常uncertainty\nsampling策略使用熵（entropy）作为不确定性的测量，在分类任务中熵写为：\n$$\nx_{E N T}^*=\\underset{x}{\\operatorname{argmax}}-\\sum_i P\\left(y_i \\mid x\n; \\theta\\right) \\log P\\left(y_i \\mid x ; \\theta\\right)\n$$\n其中yi遍历所有已经标注的数据点。\n另一判据是最小置信构型（least confident）:\n$$\nx_{L C}^*=\\underset{x}{\\operatorname{argmin}} P\\left(y^* \\mid x ;\n\\theta\\right)\n$$\n其中 y* = argmaxyP(y ∣ x; θ)\n是概率最高的标签。对于二分类任务，这个方法等价于熵判据。\nQuery-By-Committee\n通过多个模型的评判选择，当多数模型反对一个样本分类的时候，说明这个样本有最大的信息。这个方法背后的逻辑是通过最小化相空间\n\n\n最小化相空间\n\n如果机器学习的任务是在相空间中寻找最小化构型，那么active\nlearning的目标就是在小样本的情况下尽可能的限制相空间的采样范围。为了度量反对的指标，设计了一些度量函数，其中一个是投票熵：\n$$\nx_{V E}^*=\\underset{x}{\\operatorname{argmax}}-\\sum_i\n\\frac{V\\left(y_i\\right)}{C} \\log \\frac{V\\left(y_i\\right)}{C}\n$$\n其中yi重复所有可能的标签，V(yi)是从多个模型处所收到的反对票。另一种衡量距离的方法是通过KL散度：\n$$\n\\begin{gathered}x_{K L}^*=\\underset{x}{\\operatorname{argmax}}\n\\frac{1}{C} \\sum_{c=1}^C D\\left(P_{\\theta^{(c)}} \\|\nP_{\\mathcal{C}}\\right) \\\\\nD\\left(P_{\\theta^{(c)}} \\| P_{\\mathcal{C}}\\right)=\\sum_i P\\left(y_i \\mid\nx ; \\theta^{(c)}\\right) \\log \\frac{P\\left(y_i \\mid x ;\n\\theta^{(c)}\\right)}{P\\left(y_i \\mid x ;\n\\mathcal{C}\\right)}\\end{gathered}$$\n其中$P\\left(y_i \\mid x ;\n\\mathcal{C}\\right)=\\frac{1}{C} \\sum_{c=1}^C P\\left(y_i \\mid x ;\n\\theta^{(c)}\\right)$，这个度量就是希望选取最偏离平均值的点，减少不同模型之间的差异，希望最后的结果与平均值接近。\nExpected Model Change\n该方案的出发点为，寻找哪些如果打标签将会极大改变当前模型的样本。令∇ℓ(ℒ; θ)为目标函数ℓ的梯度，并且∇ℓ(ℒ ∪ ⟨x, y⟩; θ)为在添加数据⟨x, y⟩之后的新梯度。由于不知道现在样本的真实标签，因此通过概率计算：\n$$x_{E G\nL}^*=\\underset{x}{\\operatorname{argmax}} \\sum_i P\\left(y_i \\mid x ;\n\\theta\\right)\\left\\|\\nabla \\ell\\left(\\mathcal{L} \\cup\\left\\langle x,\ny_i\\right\\rangle ; \\theta\\right)\\right\\|$$\n其中∥⋅∥是欧式范数，并且∇ℓ(ℒ; θ)在之前的训练之后，往往会趋近于0，因此使用近似∇ℓ(ℒ ∪ ⟨x, yi⟩; θ) ≈ ∇ℓ(⟨x, yi⟩; θ)加速计算。\nVariance\nReduction and Fisher Information Ratio\n这个方法可以用于回归任务。模型生成误差可以描述为：\n$$\\begin{aligned} E_T\\left[(o-y)^2 \\mid\nx\\right]= &amp; E\\left[(y-E[y \\mid x])^2\\right] \\\\\n&amp; +\\left(E_{\\mathcal{L}}[o]-E[y \\mid x]\\right)^2 \\\\\n&amp;\n+E_{\\mathcal{L}}\\left[\\left(o-E_{\\mathcal{L}}[o]\\right)^2\\right]\\end{aligned}$$\n其中Eℒ[⋅]是给定标签集ℒ的期望，E[⋅]是候选密度P(y|x)的期望，ET是两者的期望。o = g(x; θ)是模型预测的记号，g是学习的函数。E[(y − E[y ∣ x])2]是噪声，表示真实值\ny\n与其条件期望值之间的偏差平方的期望，这项源于数据本身的性质，不受模型的影响，也称为噪声。$(E_{}[o]-E[y\nx])^2 是表示模型的偏差（Bias），即模型预测的期望值与真实期望值之间的差异平方。E_{})^2]$\n表示模型的方差（Variance），即模型预测的变化性或不确定性，反映了模型的Epistemic\nUncertainty（认知不确定性），可以通过获取更多数据或改进模型来减少。\nEstimated Error Reduction\nDensity-Weighted Methods\n从未标注的池子里面寻找有争议的点进行标注，例如SVM算法要区分间隔。\n\n\nDensity-Weighted Methods\n\nAnalysis of Active Learning\n这部分讨论了为什么active learning是有效的。\nProblem Setting Variants\n这部分讨论如何把active learning问题进行推广。\nRelated Research Areas\nActive learning 有两个要素： * 可以主动选择学习的目标 *\n未标注的数据是可以获取的\nSemi-Supervised Learning\nReinforcement Learning\n强化学习需要在exploration-exploitation之间进行取舍。\nEquivalence Query Learning\nActive Class Selection\nend\n","categories":["Machine Learning"],"tags":["Activate Learning","ALiPy"]},{"title":"DeepSeek-OCR: Contexts Optical Compression","url":"/2025/04/13/LLM/deepseek-ocr/main/","content":"将文本作为图片进行输入，利用视觉token提升上下文输入长度。\n文献： * DeepSeek-OCR:\nContexts Optical Compression\n\n这项工作将文本信息通过像素的形式表达，然后利用vision\ntoken进行读取识别，发现在压缩率达到10X的情况下，模型准确率维持在较高水平，由此说明视觉的vision\ntoken可以容纳更多的上下文信息。\n\n如上图所示，紫色和蓝色分别使用不同的视觉token，柱状图表示准确率，折线图表示压缩率(文本token/视觉token)。处理较大文本token时候，压缩率高正确率低是符合预期情况的。\n实验结果十分优秀，并且一些量的变化趋势与直觉是相吻合的，这里有几点疑惑需要解答：\n*\n文本信息是天然有结构的，为什么通过视觉的像素方法反而比文本tokenizer的方法压缩率要高？这点违反直觉，应当使用先验知识（文本是序列化）文本tokenizer压缩率更高。这可能预示着文本信息可能存在更强的压缩方式。\n* 这个规律在更大规模的数据集上是不是还成立？\n模型架构\n\n上图为核心架构。输入一个图像文档，分为多个patches，然后给每个图片标记位置(local\nattention)，通过卷积网络将图像识别为vision token，最后整合为embedding\nlayer。接下来随着prompt一起输入DeepSeek-3B模型。\n之后有一些技术细节需要讨论，如何将不同分辨率的图像编码到相同token数目。\n\n上图是针对不同分辨率图像，采用的几种嵌入方式。除了嵌入融合技术问题外，还有如何训练的技术细节。\n讨论\n\n对于压缩原理，文章认为可以类比为人类的记忆过程，较远的信息（之前的记忆）通过降低分辨率从而模糊处理（遗忘），更近的信息提高分辨率（记忆清晰）。\n文章本没有对于为什么使用视觉模块会有更好表现，进行进一步的探讨。\n","categories":["Largent language Model"],"tags":["Multi-Agent","Prompt"]},{"title":"Research Reviews of Combinatorial Optimization Methods Based on Deep Reinforcement Learning","url":"/2024/06/01/DL/DRL_COM/DRL_COM/","content":"The application of deep reinforcement learning to combinatorial\noptimization methods.\nReference: - Machine\nLearning for Combinatorial Optimization: a Methodological Tour\nd’Horizon\nLink:\n- Learning to Perform Local Rewriting for Combinatorial Optimization\n- graph networks\n- pointer networks\n- Neural Combiantorial Optimization with Reinforcement Learning\n\nCombinatorial Optimization\nProblem\nCombinatorial optimization problem(COP) usually described as:\n$$\\begin{align}\n\\begin{aligned}\n&amp; \\min F(x) \\\\\n&amp; \\text { s.t. } G(x) \\geq 0 \\\\\n&amp; x \\in D\n\\end{aligned}\n\\end{align}$$\nSolving combinatorial optimization problems involves two types of\nmethods: exact and approximate approaches.\nFor exact approaches, there are the ‘Branch and Bound’ and ‘Dynamic\nProgramming’ algorithms.\n\nBranch and\nBound algorithm\nLecture\n009-Branch-and-Bound\n\nThe Branch and Bound algorithm depends on efficient estimation of the\nlower and upper bounds of regions/branches of the search space. If no\nbounds are available, the algorithm degenerates to an exhaustive\nsearch.\nCan the Branch and Bound algorithm be used for\ncontinuous problems?\nFor approximate approaches, there are the “Approximate” and\n“Heuristic” algorithm.\nIntroduction\nHopefield addresses the first thought about using Neural Networks to\nsolve optimization problems.\n\n“\nNeural ”  computation  of  decisions  in optimization  problems\nNeural\nNetworks for Combinatorial Optimization: A Review of More Than a Decade\nof Research\n\nIn 2015, Vinyals initiated the application of neural networks in\noptimization by comparing combinatorial optimization to machine\ntranslation and introducing the Pointer Network (Ptr-Net). This\ncomparison highlighted their common ground in sequence-to-sequence\n(Seq2Seq) modeling.\n\npointer networks\n\nAfter introducting Ptr-Net, many advanced algorithms have been\ndeveloped that combine graph networks or transforms.\nCombining the Pointer Network (Ptr-Net) with graph\nnetworks is futile. The essence of graph networks lies in message\npassing, which relies on mean-field theory. Therefore, enhancing these\nalgorithms amounts to an approximation. The method of choosing the mean\nfield determines whether those functions can succeed.\nThe above algorithm employs an end-to-end approach, which has the\nadvantage of providing answers directly and more quickly compared to\ntraditional algorithms. However, the drawback is that it does not\nguarantee the optimality of the solutions and may fail when dealing with\nlarger problems.\nAnother type is to base deep reinforcement learning on boosting\ntraditional algorithms, with the dual directions of improving the branch\nand bound method and the iterative searching approach.\n\nMachine Learning for\nCombinatorial Optimization: a Methodological Tour d’Horizon\n\nBefore continuing our discussion, let’s address why reinforcement\nlearning is needed to solve combinatorial optimization problems. While\nsupervised learning networks perform well, their capability is\nconstrained by the training data. As a result, the quality of the\nsolution cannot exceed that of the input data. Hence, it is essential to\nemploy reinforcement learning to enhance the solution quality.\n\nThe performance of the model is tied to the quality of the\nsupervised labels.\nGetting high-quality labeled data is expensive and may be infeasible\nfor new problem statements.  How were they sure they\ngot the best answer?\nOne cares more about finding a competitive solution more than\nreplicating the results of another algorithm.\n\nEnd-to-End Approach\nUsing pointer networks and graph networks is a common approach to solving\ncombinatorial optimization problems with reinforcement learning.\n\n\nsurbey of point to point\nmodel\n\nTwo directions for improving the end-to-end approach are changing the\nmodel and using different training patterns. In my view, the network\nmodel determines the peak performance level, while the training patterns\ninfluence whether this peak can be reached and factors like time and\ndata requirements.\nHowever, sometimes network models incorporate training patterns,\nnecessitating an in-depth exploration of specific algorithms. This study\noriginated from Neural Combiantorial Optimization with Reinforcement Learning, which was later modified by\nReinforcement Learning for Solving the Vehicle Routing Problem, followed by numerous improved versions.\nLocal Search Methods based\nDRL\nPreviously, local search algorithm rules were designed manually,\nwhich is a form of heuristic search. However, we now aim to use\nreinforcement learning to automatically generate these search rules to\nget better performance.\nChen addressed a combination optimaztion search model “Learning to Perform Local Rewriting for Combinatorial Optimization”\nbased on DRL. Yolcu modify\nthe local search methods in satisfiability problem, though need less\nstep find the ground-state, it will use more time. Gao based on Large\nNeighborhood Search optimize Destory abd Repair operator. Lu created Learn\nto improve(LSI).\n\n\nLocal Search Methods based\nDRL\n\n","categories":["Machine Learning"],"tags":["Spin Glass","Reinforcement Learning","Combinatorial Optimization Methods"]},{"title":"Neural Combiantorial Optimization with Reinforcement Learning","url":"/2024/06/11/DL/DRL_COM/NCORL/","content":"Utilizing neural networks and reinforcement learning to tackle the\nTraveling Salesman Problem, where the neural network model is a\nRecurrent Neural Network (RNN), and the policy for reinforcement\nlearning employs policy gradients.\nReference: * Neural\nCombinatorial Optimization with Reinforcement Learning * code\n\nOn the 2D Euclidean TSP, given an input graph, represented as a\nsequence of n cities in a two\ndimensional space s = {xi}i = 1n\nwhere each xi ∈ ℝ2,\nwe are concerned with finding a permutation of the points π, termed a tour, that visits each\ncity once and has the minimum total length. We define the length of a\ntour defined by a permutation π as $$\\begin{align}\nL(\\pi \\mid\ns)=\\left\\|\\mathbf{x}_{\\pi(n)}-\\mathbf{x}_{\\pi(1)}\\right\\|_2+\\sum_{i=1}^{n-1}\\left\\|\\mathbf{x}_{\\pi(i)}-\\mathbf{x}_{\\pi(i+1)}\\right\\|_2,\n\\end{align}$$ where ∥ ⋅ ∥2 denotes ℓ2 norm. The aim\nNeural network architecture uses the chain relue to factorize the\nprobability of a tour as: $$\\begin{align}\np(\\pi \\mid s)=\\prod_{i=1}^n p(\\pi(i) \\mid \\pi(&lt;i), s)\n\\end{align}$$ where p(π ∣ s) is\nstochastic policy, and then uses individual softmax modules to represent\neach term\nThe architecture is pointer network. \nPropose to use model-free policy-based Reinforcement Learning to\noptimize the parameters of a pointer network denoted θ. Our training objective is\nthe expected tour length which, given an input graph s, is defined as\n$$\\begin{align}\nJ(\\boldsymbol{\\theta} \\mid s)&amp;=\\mathbb{E}_{\\pi \\sim p_\\theta(. \\mid\ns)} L(\\pi \\mid s) \\\\\n\\nabla_\\theta J(\\theta \\mid s)&amp;=\\mathbb{E}_{\\pi \\sim p_\\theta(. \\mid\ns)}\\left[(L(\\pi \\mid s)-b(s)) \\nabla_\\theta \\log p_\\theta(\\pi \\mid\ns)\\right]\\\\\n\\nabla_\\theta J(\\theta) &amp;\\approx \\frac{1}{B}\n\\sum_{i=1}^B\\left(L\\left(\\pi_i \\mid s_i\\right)-b\\left(s_i\\right)\\right)\n\\nabla_\\theta \\log p_\\theta\\left(\\pi_i \\mid s_i\\right)\n\\end{align}$$ where b(s) denotes a baseline\nfunction that does not depend on π and estimates the expected tour\nlength to reduce the variance of the gradients.\nFrom the above discussion, it is clear that b(s)， which provides a\nmethod to measure path length, is crucial for achieving an optimal\nnetwork. The network will deliver an exact policy if b(s) offers a precise\nvalue.\nWe introduce an auxiliary network, called a critic and parameterized\nby θv, to\nlearn the expected tour length found by our current policy pθ given an\ninput sequence s.\n$$\\begin{align}\n\\mathcal{L}\\left(\\theta_v\\right)=\\frac{1}{B}\n\\sum_{i=1}^B\\left\\|b_{\\theta_v}\\left(s_i\\right)-L\\left(\\pi_i \\mid\ns_i\\right)\\right\\|_2^2\n\\end{align}$$\nI believe b(s) is more than just an\nauxiliary network. As crucial as an engine in chess, b(s) provides a criterion\nfor key optimization problems, which can be seamlessly integrated into\nsearch algorithms. However, to utilize it effectively for the TSP, we\nneed to devise a functional approach to incorporate actions into s.\n\n\narchitecture\n\n","categories":["Machine Learning"],"tags":["Spin Glass","Reinforcement Learning","Combinatorial Optimization Methods"]},{"title":"Learning to Perform Local Rewriting for Combinatorial Optimization","url":"/2024/06/03/DL/DRL_COM/NeuRewriter/","content":"这篇文章提出了NeuRewriter的方法，使用强化学习中 actor-critic\n的方式训练。\n感觉类似于 “A Monte Carlo Policy Gradient Method with Local Search\nfor Binary Optimization”\n中的操作。当然了，NeuRewriter是最先提出来的，时间跨度基本都有4年了。\nReference: * Learning to\nPerform Local Rewriting for Combinatorial Optimization * github地址\n\nProblem Setup\nLet 𝒮 be the solution’s space of\nproblem domain, and c : 𝒮 → ℝ\nbe the cost function. The goal of optimization is to find arg mins ∈ 𝒮c(s).\nFormally, each solutionis a state, and each local region and the\nassociated rule is an action.\nOptimization as a rewriting problem. Let 𝒰 be the rewriting ruleset. Suppose st is the\ncurrent solution (or state) at iteration t. We first compute a\nstate-dependent region set Ω(st),\nthen pick a region ωt ∈ Ω(st)\nusing the region-picking policy πω(ωt ∣ st).\nWe then pick a rewriting rule ut applicable to\nthat region ωt using the\nrule-picking policy πu(ut ∣ st[ωt]),\nwhere st[ωt]\nis a subset of state st.\nΩ(st)\nis a problem-dependent region set. For expression simplification, Ω(st)\nincludes all sub-trees of the expression parse trees; for job\nscheduling, Ω(st)\ncovers all job nodes for scheduling; and for vehicle routing, it\nincludes all nodes in the route.\nWe then apply this rewriting rule ut ∈ 𝒰 to st[ωt],\nand obtain the next state st + 1= f(st, ωt, ut).\nGiven an initial solution (or state) s0, our goal is to find a\nsequence of rewriting steps (s0, (ω0, u0)), (s1, (ω1, u1)), …, (sT − 1, (ωT − 1, uT − 1)), sT\nso that the final cost c(sT)\nis minimized.\nIn this part mention two new functions:\nregion-picking and rule-picking, what’s mean of them? At the end of the\nfollowing is rewriting rule. I need the accurate meaning of\nrewriting. Before this paper, same idea had been proposed by Halide.\nInstead of searching from scratch, this work searches solution by\niteratively applying local rewriting rules to the existing until\nconvergence. Thus, rewriting formulation is suitable for such\nproblem:\n\nEasily find feasible solution.\nWell-behaved local structures, which could be utilized to\nincrementally improve the solution. It’s a hard to\nsatisfy feature in spin glass.\n\n\nThree words means nedd to know: * region-picking * rule-picking *\nrewriting rule\n\nNeural Rewriter Model\n\n\nModel Overview\n\nAbove is the entire model framework. Show the pseudo-code below.\n\n\nForwardPass\n\nScore predictor. Given the state st, the score\npredictor computes a score Q(st, ωt)\nfor every ωt ∈ Ω(st),\nwhich measures the benefit of rewriting st[ωt].\nA high score indicates that rewriting st[ωt]\ncould be desirable.\nIn lines 2-10, I believe this algorithm resembles the Monte Carlo\nmethod; it initially establishes a probability distribution by Ωω and gets each\nscore; then selects one from it. However, the choice is not entirely\nrandom—an acceptance probability is set. Through this process,\nhigh-quality data for learning are generated. Thus, region-picking\nfunction serves as a judgment function to assess whether the situation\nis favorable or not. The loss function of this par write as:\n$$\\begin{align}\nL_\\omega(\\theta)=\\frac{1}{T}\n\\sum_{t=0}^{T-1}\\left(\\sum_{t^{\\prime}=t}^{T-1} \\gamma^{t^{\\prime}-t}\nr\\left(s_t^{\\prime},\\left(\\omega_t^{\\prime},\nu_t^{\\prime}\\right)\\right)-Q\\left(s_t, \\omega_t ; \\theta\\right)\\right)^2\n\\end{align}$$\nRule selector. Given st[ωt]\nto be rewritten, the rule-picking policy predicts a probability\ndistribution πu(st[ωt])\nover the entire ruleset 𝒰, and selects\na rule ut ∈ 𝒰 to apply\naccordingly.\nIn lines 11-16, we will employ the Advantage Actor-Critic algorithm\nto train both the Rule-picking and Score-picking models. The primary\nnetwork we aim to obtain is the Rule-picking model, which will assist us\nin addressing subsequent problems.\n$$\\begin{align}\n\\Delta\\left(s_t,\\left(\\omega_t, u_t\\right)\\right) &amp;\\equiv\n\\sum_{t^{\\prime}=t}^{T-1} \\gamma^{t^{\\prime}-t}\nr\\left(s_t^{\\prime},\\left(\\omega_t^{\\prime},\nu_t^{\\prime}\\right)\\right)-Q\\left(s_t, \\omega_t ; \\theta\\right) \\\\\nL_u(\\phi)&amp;=-\\sum_{t=0}^{T-1} \\Delta\\left(s_t,\\left(\\omega_t,\nu_t\\right)\\right) \\log \\pi_u\\left(u_t \\mid s_t\\left[\\omega_t\\right] ;\n\\phi\\right) \\\\\nL(\\theta, \\phi)&amp;=L_u(\\phi)+\\alpha L_\\omega(\\theta)\n\\end{align}$$\nThe rewriting rule merely changes the description method; in fact, it\naddresses the same issue, similar to the gauge theory in the SK\nmodel.\n","categories":["Machine Learning"],"tags":["Spin Glass","Reinforcement Learning","Combinatorial Optimization Methods"]},{"title":"Pointer Networks","url":"/2024/06/05/DL/DRL_COM/PointerNetwork/","content":"Pointer Network(Ptr-Net) uses attention as a pointer to select a\nmember of the input sequence as the output. The author shows that\nPtr-Net could solve three challenging geometric problems - finding\nplanner convex hulls, computing Delunary triangulations, and the planner\nTravelling Salesman Problem.\nReference: * Pointer\nNetworks * Pointer\nNetworks简介及其应用 * TSP问题从DP算法到深度学习3：Pointer\nNetwork * 2022最新版-李宏毅机器学习深度学习课程\n\nIntuitively, using a sequence-to-sequence model, such as an RNN, to\nsolve combination optimization problems, we must address two issues: the\ninput size, which has been solved by straightforward technology, and the\nsolution size, which motivates the development of Ptr-Net.\n\n\nRNN vs Ptr-Net\n\nWe must set a fixed output dimension(Fig 1.a) to address the problem\nof finding planar convex hulls in an RNN. It means that if the size of\nthe solution exceeds this fixed dimension, we cannot obtain the correct\nanswer theoretically.\nTo solve the problem of solution dimensions, create a new network\nstructure (Ptr-Net) based on an attention-based model. Firstly, input\nthe problem into Ptr-Net to obtain the starting point of the solution.\nThen, use that starting point along with the problem as the new input\nfor Ptr-Net to generate a new answer, which serves as a new key. Repeat\nthis process until we receive an end signal where the site has\nappeared(Fig 1.b).\nIn each step, using a parametric model to estimate the terms of the\nprobability chain rule, i.e.\n$$\\begin{equation}\np\\left(\\mathcal{C}^{\\mathcal{P}} \\mid \\mathcal{P} ;\n\\theta\\right)=\\prod_{i=1}^{m(\\mathcal{P})} p_\\theta\\left(C_i \\mid C_1,\n\\ldots, C_{i-1}, \\mathcal{P} ; \\theta\\right)\n\\end{equation}$$\nHere (𝒫, 𝒞𝒫) is a\ntraining pair, 𝒫 = {P1, …, Pn}\nis a sequence of n vectors and\n𝒞𝒫 = {C1, …, Cm(𝒫)}\nis a sequence of m(𝒫) indices,\neach between 1 and n.\nThe parameters of the model are learnt by maximizing the conditional\nprobabilities for the training set, i.e.\n$$\\begin{equation}\n\\theta^*=\\underset{\\theta}{\\arg \\max } \\sum_{\\mathcal{P},\n\\mathcal{C}^{\\mathcal{P}}} \\log p\\left(\\mathcal{C}^{\\mathcal{P}} \\mid\n\\mathcal{P} ; \\theta\\right),\n\\end{equation}$$\nwhere the sum is over training examples.\nCompute the attention vector at each output time i as follows:\n$$\\begin{align}\nu_j^i&amp;=v^T \\tanh \\left(W_1 e_j+W_2 d_i\\right) \\quad j \\in(1, \\ldots,\nn) \\\\\np\\left(C_i \\mid C_1, \\ldots, C_{i-1},\n\\mathcal{P}\\right)&amp;=\\operatorname{softmax}\\left(u^i\\right)\n\\end{align}$$\nwhere ej is input\ndata(encoder state), di is output\ndata(decoder state), u is\nsoftmax normalized output distribution, and W1, W2\nare learnable parameters of model.\n\n\nstep1\n\nThen, select the site with the highest probability, 1 in the above\nfigure.\n\n\nstep2\n\nNext, choose site 1 data (x1, y1)\nas the key and input it into the network to obtain the distribution.\nContinue until we receive the end signal, identified as (x1, y0)\nin this example.\n","categories":["Machine Learning"],"tags":["Spin Glass","Reinforcement Learning","Combinatorial Optimization Methods"]},{"title":"Reinforcement Learning for Solving the Vehicle Routing Problem","url":"/2024/06/11/DL/DRL_COM/RLSVRP/","content":"Although the framework proposed by Bello at Neural Combiantorial Optimization with Reinforcement Learning works well\non TSP, it is not applicable to more complicated combinatorial\noptimization problems in which the system representation varies over\ntime, such as Vehicle Routing Problem(VRP). Thus, this paper propose a\nnew model to overcome drawback of previous.\nReference: * Reinforcement\nLearning for Solving the Vehicle Routing Problem * code\n\n\n\ndrawback of previous\n\nAs figure 1 have been show, once change a part of elements, we must\nupdate the whole input.\n\n\nnew model\n\nTherefore, in new model, thet just simply leave out the encoder RNN\nand directly use the embedded inputs instead of the RNN hidden states.\nBy this modification, many of the computational complications disappear,\nwithout decreasing the model’s efficiency.\n","categories":["Machine Learning"],"tags":["Spin Glass","Reinforcement Learning","Combinatorial Optimization Methods"]},{"title":"Loss of plasticity in deep continual learning","url":"/2024/08/26/DL/LossPlasticity/LossPlasticity/","content":"文章主要讨论在持续学习任务中，损失具有弹性是很关键，进而指出在深度学习中，仅仅依靠反向传播是不够的，需要结合随机、非梯度的优化方式（例如演化计算等）。\nLink: * Loss of\nplasticity in deep continual learning * Nature正刊（演化深度持续学习）Loss\nof plasticity in deep continual learning\n\nIntroduction\n讨论的问题是持续学习任务，以分类任务为例，首先将几个目标进行分类，然后将成功的分类器（神经网络），然后再添加一些其它的分类目标与训练样本。核心的概念损失弹性由此产生，可以发现随着目标的增加，反向传播训练分类器会降低其在测试集上的成功率，说明这样的网络是不具有弹性的，不能进行持续学习。\n\n\nPlasticity loss in Continual\nImageNet\n\n上图是以ImageNet进行的测试，a表示逐渐增加的任务，b是不同步长、不同任务数下的比较，c中包含了其它的改良。\n不具有弹性的原因在于激活函数的失效，意味着这些神经元失去单射性，对结果是没有作用的。\n\n\nOnline Permuted MNIST\n\n上图中c展示了随着任务的数量增加，失活的神经元数量增加（ReLU激活函数）。\n为了解决反向传播中没有弹性问题，文章提出了一种可持续反向传播的算法continual\nbackpropagation。\nContinual backpropagation\nContinual\nbackpropagation的核心思想就是将一些失活的激活函数进行初始化。如何衡量是否有效，提出了效用函数ul[i]，如果激活函数处于低效用的状况，这对其进行初始化。\n$$\n\\mathbf{u}_l[i]=\\eta \\times \\mathbf{u}_l[i]+(1-\\eta)\n\\times\\left|\\mathbf{h}_{l, i, t}\\right| \\times \\sum_{k=1}^{n_{l+1}} \\mid\n\\mathbf{w}_{l, i, k, t}\n$$\n其中ul[i]是对各种训练数据的积累量，hl, i, t是第l层第i个隐藏神经元第t次的输出，wl, i, k, t是权重参数，η是衰减率。\n对每一个神经元的效用函数从大到小进行排序，同时设置超参效用阈值m。在每一次反向传播结束，统计超过效用阈值m神经元数量neligible ，以比例ρ进行累计cl = cl + neligible\n × ρ。如果超过1，那么选取一个分界r，高效用的按照一个分布进行初始化，低效用置0。\n","categories":["Machine Learning"],"tags":["Evolution"]},{"title":"Injectivity of ReLU networks (perspectives from statistical physics)","url":"/2024/08/25/DL/Injectivity_ReLU/InjecReLU/","content":"对于ReLU激活层单向性的分析，得到变化的上下界。\nLink: * Injectivity of\nReLU networks: perspectives from statistical physics\n\nIntroduction\n在什么情况下，随机初始化的ReLU网络是单射性的？\n考虑一个单层的 ReLU 函数，这个映射为φW：\n$$\n\\varphi_{\\mathbf{W}}(\\mathbf{x})_\\mu=\\sigma\\left[\\left(\\frac{\\mathbf{W}\n\\mathbf{x}}{\\sqrt{n}}\\right)_\\mu\\right], \\quad \\mu=1, \\cdots, m\n$$\n其中 n, m ≥ 1\n，x ∈ ℝn\n，σ(x) := max (0, x)\n，ReLU参数满足正态分布 $W_{\\mu i}\n\\stackrel{\\text { i.i.d. }}{\\sim} \\mathcal{N}(0,1)$ 。\n已有研究指出在热力学极限下 n → ∞ 、 $\\frac{m}{n} \\rightarrow \\alpha&gt;0$\n，存在两个阈值 αl &lt; αh\n。当α &lt; αl，ReLU函数是非单射性的；当α &gt; αh，ReLU是单射性的。\n这篇文章的研究内容与之前的一致，采用统计物理方法（复本对称）。\nSolution\n研究思路是通过将单射性问题，通过一个能量模型描述，然后这个能量模型在波尔兹曼分布下研究。这样该问题就转为一个物理问题。\nInjectivity\n首先需要解决如何描述单射性。提出概率 pm, n\n用于表示映射φW\n是单射性的概率：\npm, n = ℙV[V ∩ Cm, n = {0}]\n其中 V 是 ℝm 的一个随即子空间，\nCm, n\n是 ℝm\n中一组向量，并且这组向量中每一个向量元素为正的个数要小于n 。\n通过这个操作，将描述单射性的问题，转化为数向量中为正的元素个数，可以定量描述了。\nStatistical\nphysics and the spherical perceptron\n接下来的任务就是通过设计能量函数，将数正数的个数，变成为能量的表述形式。\n通过能量表示总的正元素个数： $$\nE_{\\mathbf{W}}(\\mathbf{x}):=\\sum_{\\mu=1}^m \\theta\\left[(\\mathbf{W}\n\\mathbf{x})_\\mu\\right], \\quad\ne_{\\mathbf{W}}(\\mathbf{x}):=\\frac{E_{\\mathbf{W}}(\\mathbf{x})}{n}\n$$ 其中 θ(x) = 𝟙(x &gt; 0)\n， x ∈ 𝒮n − 1\n， 𝒮n − 1 是 ℝn\n上的单位球。根据之前的讨论V ∩ Cm, n = {0}可以得到\nWx ∈ Cm, n ⇔ EW(x) &lt; n，将\npm, n重新写为：\npm, n = ℙW[minx ∈ 𝒮n − 1EW(x) ≥ n]\nThermal\nrelaxation: the Gibbs–Boltzmann distribution\n有了能量，接下来将其写为波尔兹曼分布：\n$$\n\\mathrm{d} \\mathbb{P}_{\\beta,\n\\mathbf{W}}(\\mathbf{x}):=\\frac{1}{\\mathcal{Z}_n(\\mathbf{W}, \\beta)}\ne^{-\\beta E_{\\mathbf{W}}(\\mathbf{x})} \\mu_n(\\mathrm{~d} \\mathbf{x}) .\n\\quad\\left(\\mathbf{x} \\in \\mathcal{S}^{n-1}\\right)\n$$\n其中beta为逆温度，β = 0 那就是球面上的平均测量， β → ∞则是能量最小值部分。\n同时写出其自由能： $$\n\\Phi_n(\\mathbf{W}, \\beta):=\\frac{1}{n} \\log \\mathcal{Z}_n(\\mathbf{W},\n\\beta)=\\frac{1}{n} \\log \\int_{\\mathcal{S}^{n-1}} \\mu_n(\\mathrm{~d}\n\\mathbf{x}) e^{-\\beta E_{\\mathbf{W}}(\\mathbf{x})}\n$$\nResult\n这部分就是通过副本对称破缺讨论了。\n","categories":["Machine Learning"],"tags":["Spin Glass"]},{"title":"KAN: Kolmogorov–Arnold Networks","url":"/2024/05/08/DL/Kolmogorov%E2%80%93Arnold_Networks/Kolmogorov%E2%80%93Arnold_Networks/","content":"文献地址： * KAN:\nKolmogorov–Arnold Networks * GitHub地址\n传统的全连接神经网络用于拟合非线性函数，然而全连接网络真的是最好的架构了么？对于全连接网络有明显的缺点，显存开销大，可解释性差。\n本文作者提出了KAN网络架构，其基于 Kolmogorov-Arnold representation\ntheorem。该网络架构将“参数进行非线性激活”，然后通过全连接。\n\n\nMulti-Layer Perceptrons (MLPs)\nvs. Kolmogorov-Arnold Networks (KANs)\n\n\n有几个问题： 1. KAN的参数是如何确定的，架构和全连接的区别在哪里？ 2.\n他这个非线性过程是不是找到一组基，然后利用这个基进行表示？ 3.\n为什么它能够解决全连接的内存开销问题？ 4. 为什么说它具备可解释性？\nKolmogorov-Arnold\nRepresentation theorem\nMLP的有效性是因为万能近似定理，KAN的有效性是基于Kolmogorov-Arnold\nRepresentation theorem。该定理表明：如果一个函数f在一个区域上是多元连续函数，那么其可以写为多个单变量函数的和。例如对于平滑的函数f : [0, 1]n → ℝ：\n$$\\begin{align}\nf(\\mathbf{x})=f\\left(x_1, \\cdots, x_n\\right)=\\sum_{q=1}^{2 n+1}\n\\Phi_q\\left(\\sum_{p=1}^n \\phi_{q, p}\\left(x_p\\right)\\right)\n\\label{Kolmogorov-Arnold}\n\\end{align}$$\n其中 ϕq, p : [0, 1] → ℝ\n并且 Φq : ℝ → ℝ。但是不能简单的认为可以将任意的多元函数转化为1维函数函数相加，因为这样的1维函数可能是非平滑甚至是分形的。\nKAN architecture\n\n\nB-spline\n\n如上图右边所示，训练目标是ϕq, p，形如向基底展开，这里采用的基是\nB-spline curve，可训练的参数是对应系数c。左图为整体的流程，其中x0, 1与x0, 2为输入参数，输出参数为x2, 1。这样便构建了KAN的框架。\n$$\\begin{align}\n&amp;x_{l+1, j}=\\sum_{i=1}^{n_l} \\tilde{x}_{l, j, i}=\\sum_{i=1}^{n_l}\n\\phi_{l, j, i}\\left(x_{l, i}\\right), \\quad j=1, \\cdots, n_{l+1}\n\\label{KAN-layer}\\\\\n&amp;\\mathbf{x}_{l+1}=\\underbrace{\\left(\\begin{array}{cccc}\n\\phi_{l, 1,1}(\\cdot) &amp; \\phi_{l, 1,2}(\\cdot) &amp; \\cdots &amp;\n\\phi_{l, 1, n_l}(\\cdot) \\\\\n\\phi_{l, 2,1}(\\cdot) &amp; \\phi_{l, 2,2}(\\cdot) &amp; \\cdots &amp;\n\\phi_{l, 2, n_l}(\\cdot) \\\\\n\\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\\n\\phi_{l, n_{l+1}, 1}(\\cdot) &amp; \\phi_{l, n_{l+1}, 2}(\\cdot) &amp;\n\\cdots &amp; \\phi_{l, n_{l+1}, n_l}(\\cdot)\n\\end{array}\\right)}_{\\boldsymbol{\\Phi}_l} \\mathbf{x}_l \\\\\n&amp;\\operatorname{KAN}(\\mathbf{x})=\\left(\\boldsymbol{\\Phi}_{L-1} \\circ\n\\boldsymbol{\\Phi}_{L-2} \\circ \\cdots \\circ \\boldsymbol{\\Phi}_1 \\circ\n\\boldsymbol{\\Phi}_0\\right) \\mathbf{x}\n\\end{align}$$\n并且从 $\\eqref{Kolmogorov-Arnold}$\n可知，用深度为2的架构已经满足，第一隐藏层将维度从d提升到2d + 1，然后相加，再通过最后一层得出目标值。\n上图中还展示了样条插值函数的拓展，更多的基更大的范围。\nImplementation details\n虽然 $\\eqref{KAN-layer}$\n已经十分简单，但是还是有很多细节需要处理。\n$$\\begin{align}\n&amp; \\phi(x)=w(b(x)+\\operatorname{spline}(x))  \\\\\n&amp; b(x)=\\operatorname{silu}(x)=x /\\left(1+e^{-x}\\right) \\\\\n&amp;\\operatorname{spline}(x)=\\sum_i c_i B_i(x)\n\\end{align}$$\n用 Xavier 初始化参数。\nA toy example:\nhow humans can interact with KANs\n对于给定的数据(xi, yi, fi), i = 1, 2…N，如何得出其具体形式？假设以上形式来源于公式：\nf(x, y) = exp (sin (πx) + y2)\n\n\nAn example of how to do symbolic\nregression with KAN\n\n第一步，选取较大的网络进行离散化训练。第二步，减枝，截取大网络中的一部分，使得网络精简但是性能没有损失很多。第三步，用户自己猜测符号形式，或者利用给出的建议符号形式。\n$$\\begin{equation}\n\\begin{aligned}\n&amp; \\text { fix_symbolic(0,0,0,'sin') } \\\\\n&amp; \\text { fix_symbolic(0,1,0,'x^2') } \\\\\n&amp; \\text { fix_symbolic(1,0,0,'exp'). }\n\\end{aligned}\n\\end{equation}$$ 第四步，进一步训练，对目标符号进行拟合。\n后来在作者直播的分享中，这里面还有很多内容。虽然Kolmogorov-Arnold公式$\\eqref{Kolmogorov-Arnold}$中知道只需要两层足够，但是实际情况可能要叠加更多的层数。这是由于简单公式的嵌套，例如exp (x)与x2用2层可以很好的表示，但是对于exp (e2)在用三层，就相当于让样条函数分别拟合exp (x)与x2，相对容易；如果强制使用2层进行拟合，就会导致样条插值函数要拟合exp (e2)，在可解释与拟合效果来说都比较差。\n同时作者也解释了为什么这里其选用B样条插值函数，而非选用其它的函数。这是由于其课题组经常使用B样条函数。这里有很多值得思考的问题，B-spline对于怎样的函数形式不能很好的拟合，替换其它的基是否效果会更好，能否将不同的基进行组合。\nConclusion\n回答开头提出的几个问题： 1.\nKAN其实和MLP基本一致，差别在于KAN在过程中使用了展开的方式，学习的参数是一些非线性基的权重。这个和MLP是一致的，只是在MLP中参数对应的是线性的权重，然后通过更层完成对于复杂函数的拟合，换句话说，MLP在拟合拟合这些基。但是这样做有什么差别么？KAN的这种方式，更像是引入了人类经验，对于特定问题一些基底是更容易特征提取的，这样不仅能提升训练速度，同时还能够增强准确性。然而，代价就是如果选择的基并不适配这样的问题，训练慢、效果差。MLP的线性基更像是折中方案。\n2. 是的，和开篇的猜测一致，人为假定一组基，然后展开。 3.\n它比MLP开销少的原因在于两方面。一方面，Kolmogorov-Arnold Representation\ntheorem定理指出两层足够（如果目标函数较为复杂、嵌套较多，还是需要增加隐藏层），另一方面使用基可以将复杂的函数较为简单的表示。\n4.\n这个可解释性，就是规律的挖掘，很相之前AI-feynnman那种规则发现的程序。\nCode\n这里不由得感慨一下，原作者代码写的非常规范，可读性非常强。另一位厉害的人物，复现的也相当快FCN-KAN。优秀的人不只是一个方面优秀啊。\nAppend\nB-splines\n\n保姆级理解\nB-Spline\n深入理解贝塞尔曲线\n\n\nB-splines函数在物理学中是不常见的，这个函数更多的用在计算机图形学上。在计算机图形学上，最早使用的是贝塞尔曲线。\n\n上面是一个四阶贝塞尔曲线生成过程，通过固定的点（图中P0P1P2P3）连成线段然后按照长度比例生成图中绿线的三个端点，绿线同样按照比例，生成紫线的两个端点，紫色线段再按照比例生成红线上的点。初始的节点数越多，生成过程中产生的线段越多，图中共生成三种颜色的曲线（四个顶点），称为三阶贝塞尔曲线。\n一阶贝塞尔曲线，由两个端点，直接生成最终的曲线： $$\\begin{align}\nB_1(t)=&amp;P_0+\\left(P_1-P_0\\right) t \\\\\nB_1(t)=&amp;(1-t) P_0+t P_1 \\quad t \\in[0,1]\n\\end{align}$$\n二阶贝塞尔曲线，由三个端点，首先生成一个线段，然后生成最终的曲线。线段上的控制点为P0′P1′。\n$$\\begin{align}\n&amp;\\begin{aligned}\n&amp; P_0^{\\prime}=(1-t) P_0+t P_1 \\\\\n&amp; P_1^{\\prime}=(1-t) P_1+t P_2\n\\end{aligned} \\\\\n&amp;\\begin{aligned}\nB_2(t)&amp;=(1-t) P_0^{\\prime}+t P_1^{\\prime} \\\\\n&amp; =(1-t)\\left((1-t) P_0+t P_1\\right)+t\\left((1-t) P_1+t P_2\\right)\n\\\\\n&amp; =(1-t)^2 P_0+2 t(1-t) P_1+t^2 P_2 \\quad t \\in[0,1]\n\\end{aligned}\n\\end{align}$$\n直接给出三阶贝塞尔曲线表达式： $$\\begin{align}\nB_3(t)=(1-t)^3 P_0+3 t(1-t)^2 P_1+3 t^2(1-t) P_2+t^3 P_3, \\quad t\n\\in[0,1]\n\\end{align}$$\n多阶贝塞尔曲线： $$\\begin{align}\nB(t)&amp;=\\sum_{i=0}^n C_n^i P_i(1-t)^{n-i} t^i \\\\\n&amp;=\\sum_{i=0}^n P_i b_{i, n}(t), \\quad t \\in[0,1] \\\\\nC_n^i &amp;= \\frac{n!}{(n-i)!\\cdot i!} \\\\\nb_{i, n}(t) &amp;= C_n^i(1-t)^{n-i} t^i \\quad i=0,1, \\ldots, n \\quad t\n\\in[0,1] \\label{Bezier}\n\\end{align}$$\n通过点来生成整个曲线，这就是贝塞尔曲线的主要思想。但是其存在一些问题：\n* 给定点的数量，就确定了曲线的阶次 *\nBezier曲线拼接复杂（需要满足几何连续性，参数连续性等） *\nBezier曲线不能作局部修改（只能整体修改）\n因此，提出了B-spline曲线。核心思想是修改$\\eqref{Bezier}$中的bi, n(t)。根据之前的定义可以知道其中n是阶数为固定值，这里将其变为一个自由可以选择的值，对应的物理含义为：将固定点进行截断，只考虑几个特定的点的贝塞尔函数（即画出部分点的贝塞尔函数）。另一个改变点在于t，在原来的定义中这是一个遍历线段的点，这里也进行截断让其变为一个自由的值tmin ≤ t ≤ tmax，让其可以选择一部分。\n其实B-spline和贝塞尔同宗同源，就是在其基础上进行两种截断，一个是遍历线段的范围，另一个是选取的点数量。而且，这和选取的点没有关系，仅仅是点前面的系数进行变换。\n","categories":["Machine Learning"],"tags":["Physics","Kolmogorov–Arnold Networks"]},{"title":"Deconstructing Denoising Diffusion Models for Self-Supervised Learning","url":"/2024/03/15/DL/Deconstructing_Denoising_Diffusion_Models_for_Self_Supervised_Learning/Deconstructing_Denoising_Diffusion_Models_for_Self_Supervised_Learning/","content":"Abstract\n这篇文章分析了 Denoising Diffusion Models(DDM)\n在图像领域的表示能力。通过不断解构DDM，从而分析Transformer的性能。最终得出结论：仅仅有很少的几个参数是有用的，对最后的图像生成起到关键作用。\n这点和全连接神经网络十分相似，当层数过多的时候，只有输入层附近的几层与输出层附近的几层是关键的，中间几层处于液化状态（可以随意选取，不会影响最终的结果）。\n\n现有的预训练DDM在生成任务上表现十分优异，然而留下一个开放问题：这些用于生成任务的预训练模型，其是否同样获得表征能力。\nDeconstructing\nDenoising Diffusion Models\n作者发现主要的关键因素是tokenizer，其表现了低维的潜空间。但是不难发现，潜变量并不是tokenizer独有的，standard\nVAE, a patch-wise VAE, a patch-wise AE, and a patch-wise PCA encoder\n均有潜变量。\n\n\nfig1\n\n解构的路线分为三个步骤： * 首先将Diffusion\nTransformer(DiT)架构，变为自监督模型 * 逐步拆解toenizer *\n尽可能尝试还原模型，将其变为一个经典的Denoising Autoencoder(DAE)\nReorienting DDM\nfor Self-supervised Learning\nDDM的概念本质上是从DAE的概念上生成的，依旧是用于图像生成，一些设计并不适合自监督学习，一些是并不必要的（例如提升图像生成质量）。\n\n\nfig2\n\n\nRemove class-conditioning\n标签在图像生成上很重要，但是不符合自监督学习的要求，因此移除标签。此举使得准确性提升，但是图像质量（FID）下降。\nDeconstruct VQGAN\nReplace noise schedule\n不需要逐步添加噪声，可以一步直接加入噪声\n\n\n\nfig3\n\nDeconstructing the Tokenizer\n接下来解构tokenizer，将会用到下面四种自编码器，每一种自编码器都是前面一种的简化。\n\nConvolutional VAE\n损失函数如下： ∥x − g(f(x))∥2 + 𝕂𝕃[f(x) ∣ 𝒩]\n其中f(⋅)是编码函数g(⋅)是解码函数，x是输入值，VAE是深度卷积神经网络。\nPatch-wise VAE\n选用线性的函数作为编码解码器（全连接网络），损失函数设置如下： ∥x − UTVx∥2 + 𝕂𝕃[Vx ∣ 𝒩]\nU, V是矩阵。\nPatch-wise AE\n进一步简化，删除正则化项： ∥x − UTVx∥2\nPatch-wise PCA\nPCA 可以看成是一种特殊的 AE，损失函数为： ∥x − VTVx∥2\n\n\n\nfig4\n\n可以从上表中看出，表现性能都差不多，并且计算KL散度也不是很重要。甚至PCA工作的更好\nToward Classical\nDenoising Autoencoders\n逐步减去 PCA-based DDM 与经典DAE之间的差距。 \nConclusion\n\n\nfig6\n\n从最后的实验结果看出，对潜变量空间加入噪音对结果的影响更大。因此说明对模型训练起关键作用的是少数几个参数。\n应该是我没有读懂该文章的实验思路，在我的理解下，潜变量应该是浓缩了更多信息的空间，对其加噪音本来就会比对原像素空间其更大的影响。另一方面，这种论证方法，我并不认为十分研究，应该有更多的理论分析保证。\n","categories":["Machine Learning"],"tags":["Diffusion Models","Denoising Diffusion Models","Self-Supervised Learning"]},{"title":"Score matching model","url":"/2024/01/19/DL/Score_matching_model/Score_matching_model/","content":"简介\n这篇文章主要描述基于得分匹配（Score matching\nmodel）的想法，以及之后主要的修改思路。这种思路是生成模型的一种，与GAN、normal-flow等模型具备同样的功能。\n本篇文章大量借鉴棒棒生博客，推荐阅读原文博客。本文章在其基础上加入一些作者本人的思考，并且统一符号，增加阅读流畅性。\n\n得分匹配算法（Score matching\nmodel）\n得分匹配这种思想首先发表于论文–Estimation of Non-Normalized\nStatistical Models by Score Matching。\n拟合目标\n图像、声音、热力学过程等在数学形式上应该是一种概率分布，想要模仿生成相应的事物需要的就是能够得知这种概率分布。但是这种概率分布往往在一个高维空间，难以凭借人类的经验直接获得，因此此时借助神经网络的拟合能力，完成概率密度分布函数的拟合。\n利用 $\\bf{x}$\n生成一个随机的目标概率密度分布 $p_{\\bf{x}}(\\cdot)$，接下来尝试拟合该目标函数，拟合函数的概率密度分布记为p(⋅; θ)，其中θ是一个m维空间的向量。目标是从$\\bf{x}$中估计θ。\n将拟合函数p(⋅; θ)进一步分解开来：\n$$p(\\xi;\\theta)=\\frac{1}{Z(\\theta)}q(\\xi;\\theta)$$\n其中：Z(θ) = ∫ξ ∈ ℝnq(ξ; θ)dξ。这样只需要生成函数q(⋅; θ)，不需要关心归一化的问题。\n通常非归一化采样的方法是马尔科夫链蒙特卡洛模拟。典型的是Ising模型的模拟过程。在得到一系列数据{x1, x2, x3...}后，使用极大似然估计方法（Maximum\nLikelihood Estimation, MLE）估计θ： $$\\theta_{MLE}=\\text{argmax}_{\\theta}\\sum_{t=1}^T\n\\text{ln} p(x_t;\\theta)$$\n然而在实际中这种方案是行不通的，因为配分函数Z(θ)难以计算。计算配分函数是一块难啃的骨头，许多物理学上的困难本质就是来源于如何高效计算配分函数，因此很多方法例如高温展开、信念传播算法等本质就是在解决如何在牺牲一些精确性的条件下，高效计算配分函数。\n直接计算存在困难，并且配分函数作为一个仅仅为θ的函数存在，那就转而计算梯度，试图将配分函数在求梯度的过程中磨消。定义：\n$$\n\\psi(\\xi;\\theta)=\n    \\left(\n        \\begin{matrix}\n            \\frac{\\partial ln p(\\xi;\\theta)}{\\partial \\xi_1} \\\\\n            \\cdots \\\\\n            \\frac{\\partial ln p(\\xi;\\theta)}{\\partial \\xi_n}\n        \\end{matrix}\n    \\right)\n=\n    \\left(\n        \\begin{matrix}\n            \\psi_1 (\\xi;\\theta) \\\\\n            \\cdots \\\\\n            \\psi_n (\\xi;\\theta)\n        \\end{matrix}\n    \\right)\n=\\nabla_\\xi ln p(\\xi;\\theta)\n$$\n本质上求偏导并不依赖于Z(θ)，可以获得： ψ(ξ; θ) = ∇ξlnq(ξ; θ)\n\n\n梯度图片\n\n上方是一个分布的梯度图像，可以看出如果梯度方向大小均相同的情况下，两个应该是同一种分布。这里可以通过分析下面的函数得到，如果J(θ) = 0,由于px(ξ) ≥ 0，必然存在ψ(ξ; θ) − ψx(ξ) ≡ 0，则说明θ = θ*，成功学习到分布。这也证明了解的存在唯一性。\n直观的目标函数（Explicit\nScore Matching，ESM）\n将任务目标函数写为考虑两个函数的梯度的均方误差(MSE)： $$\\begin{equation} J_{ESM}(\\theta)=\\frac{1}{2}\n\\int_{\\xi\\in\\mathbb{R}^n}p_x(\\xi)||\\psi(\\xi;\\theta)-\\psi_x(\\xi)||^2\\mathrm{d}\\xi\n\\end{equation}$$ 其中ψx(ξ) = ∇ξlnpx(ξ)，为目标概率密度分布的梯度分布。优化目标为：\nθ̂ = argmaxθJ(θ)\n可以通过重要性采样得到T个数据点$\\bf{x}(1), \\bf{x}(2)\n\\cdots\\bf{x}(T)$，从而计算经验期望值： $$\\begin{equation}\n\\tilde{J}_{ESM}(\\theta)=\\frac{1}{T}\\sum_{t=1}^T\\sum_{i=1}^n[\\psi(\\xi;\\theta)-\\psi_x(\\xi)]^2\n\\end{equation}$$\n隐藏的目标函数（Implicit\nScore Matching，ISM）\n在计算均方误差的时候，需要知道ψx(ξ)，然而知道确切的目标函数形式是不可能的。因此，虽然以上逻辑是合理的，但是本质上是不计算实施的，需要进行一定的调整。\n$$\n\\begin{align*}\nJ(\\theta)&amp;=\\frac{1}{2}\n\\int_{\\xi\\in\\mathbb{R}^n}p_x(\\xi)||\\psi(\\xi;\\theta)-\\psi_x(\\xi)||^2\\mathrm{d}\\xi\n\\\\\n&amp;=\\int_{\\xi\\in\\mathbb{R}^n}p_x(\\xi)[\\frac{1}{2}\n\\psi(\\xi;\\theta)^2+\\frac{1}{2}\n\\psi_x(\\xi)^2-\\psi(\\xi;\\theta)\\psi_x(\\xi)]\\mathrm{d}\\xi \\\\\n\\end{align*}\n$$\n针对后一部分结果进行简化，将ψ展开为具体的第i部分： $$\n\\begin{align*}\n&amp;\\int_{\\xi\\in\\mathbb{R}^n}-p_x(\\xi)\\psi(\\xi;\\theta)\\psi_x(\\xi)\\mathrm{d}\\xi\n\\\\\n&amp;=\n-\\sum_i\\int_{\\xi\\in\\mathbb{R}^n}p_x(\\xi)\\psi_i(\\xi;\\theta)\\psi_{x,i}(\\xi)\\mathrm{d}\\xi\n\\\\\n&amp;=-\\sum_i\\int_{\\xi\\in\\mathbb{R}^n}p_x(\\xi)\\psi_i(\\xi;\\theta)\\frac{\\partial\\psi_{x}(\\xi)}{\\partial\n\\xi_i} \\mathrm{d}\\xi \\\\\n&amp;=-\\sum_i\\int_{\\xi\\in\\mathbb{R}^n}p_x(\\xi)\\psi_i(\\xi;\\theta)\\frac{\\partial\nln p_x(\\xi)}{\\partial \\xi_i} \\mathrm{d}\\xi \\\\\n&amp;=-\\sum_i\\int_{\\xi\\in\\mathbb{R}^n}\\psi_i(\\xi;\\theta)\\frac{\\partial\np_x(\\xi)}{\\partial \\xi_i} \\mathrm{d}\\xi \\\\\n&amp;=-\\sum_i\\left[ \\psi_i(\\xi;\\theta)p_x(\\xi)\n|_{\\xi_i=-\\infty}^{\\xi_i=\\infty} - \\int_{\\xi\\in\\mathbb{R}^n}\np_x(\\xi)\\frac{\\partial \\psi_i(\\xi;\\theta)}{\\partial \\xi_i} \\mathrm{d}\\xi\n\\right]\\\\\n\\end{align*}\n$$\n将其中第一部分进行更详细的展开： $$\n\\begin{align*}\n\\psi_1(\\xi;\\theta)p_x(\\xi) |_{\\xi_1=-\\infty}^{\\xi_1=\\infty}\n&amp;=  \\lim\\limits_{a\\to\n\\infty,b\\to\\infty}[\\psi(a,\\xi_2\\cdots\\xi_n;\\theta)p_x(a,\\xi_2\\cdots\\xi_n;\\theta)-\\psi(b,\\xi_2\\cdots\\xi_n;\\theta)p_x(b,\\xi_2\\cdots\\xi_n;\\theta)]\n\\\\\n&amp;= 0\n\\end{align*}\n$$ 后面的原因来源于一个简单的假设，当||ξ|| → ∞： px(ξ)ψ(ξ; θ) → 0\n可以这样理解该假设，当采样数量巨大或者分布为连续，单一采样所占概率分布很小，可以视为直接为0。因此得到最后的结果：\n$$\n\\begin{align*}\n\\int_{\\xi\\in\\mathbb{R}^n}-p_x(\\xi)\\psi(\\xi;\\theta)\\psi_x(\\xi)\\mathrm{d}\\xi\n&amp;=\\sum_i \\int_{\\xi\\in\\mathbb{R}^n} p_x(\\xi)\\frac{\\partial\n\\psi_i(\\xi;\\theta)}{\\partial \\xi_i} \\mathrm{d}\\xi\\\\\n&amp;=\\int_{\\xi\\in\\mathbb{R}^n} p_x(\\xi)\\partial_{i} \\psi_i(\\xi;\\theta)\n\\mathrm{d}\\xi\\\\\n\\end{align*}\n$$\n$$ $$\n其中第二项为目标函数的积分，结果应该为一个常数，对于优化目标函数来说一个常数并没有实际意义，因此可以直接消去：\n$$\n\\begin{align}\nJ_{ISM}(\\theta) &amp;= \\int_{\\xi\\in\\mathbb{R}^n}p_x(\\xi)[\\frac{1}{2}\n\\psi(\\xi;\\theta)^2+\\partial_{i} \\psi_i(\\xi;\\theta)]\\mathrm{d}\\xi \\\\\n&amp;= \\mathbb{E}_{p_x(\\xi)}[\\frac{1}{2}\n\\psi(\\xi;\\theta)^2+\\text{tr}(\\nabla_{\\xi} \\psi_{\\xi}(\\xi;\\theta))] \\\\\n\\tilde{J}_{ISM}(\\theta) &amp;=\n\\frac{1}{T}\\sum_{t=1}^T\\sum_{i=1}^n[\\frac{1}{2}\n\\psi(x_t;\\theta)^2+\\partial_{i} \\psi_i(x_t;\\theta)]\n\\end{align}\n$$\n总结\n首先通过概率密度分布拟合明确了任务目标，通过调节参数θ使得$p_{\\bf X}(\\cdot)$与p(⋅; θ)分布尽可能相同。但是直接计算p(⋅; θ)存在困难，因此将任务目标进行改变，转而寻求概率分布密度函数的梯度尽可能相似。然后求解公式中包含目标函数，无法直接求解，通过分布积分的方法转化为只需要拟合函数便可以求解。\n然而在计算ISM的时候存在两点问题： *\n需要计算二次导数，这会导致计算图大小升高 *\n当输入数据维度很大的时候很难处理\n噪声得分匹配（Denoising\nScore Matching，DSM）\n本算法的思想来源于A Connection Between Score Matching and Denoising\nAutoencoders。\nDSM的提出，可以很好的解决ISM存在的两个问题。\n噪声\n将目标函数加入噪声 pxσ，其中σ表示噪声，那么ESM与ISM可以改写为：\n$$\n\\begin{align}\nJ_{ESM,p_{\\sigma}}(\\theta) &amp;=\\mathbb{E}_{p_\\sigma(\\xi)}\\left[\n\\frac{1}{2} ||\\psi(\\xi;\\theta)-\\psi_{x_\\sigma}(\\xi)||^2\\right] \\\\\n&amp;= \\mathbb{E}_{p_\\sigma(\\xi)}\\left[ \\frac{1}{2}\n||\\psi(\\xi;\\theta)-\\frac{\\partial ln p_{\\sigma}(\\xi)}{\\partial\n\\xi}||^2\\right] \\\\\nJ_{ISM,p_\\sigma}(\\theta) &amp;= \\mathbb{E}_{p_\\sigma(\\xi)}\\left[\n\\frac{1}{2} \\psi(\\xi;\\theta)^2+\\text{tr}(\\nabla_{\\xi} \\psi\n(\\xi;\\theta))\\right] \\\\\n\\end{align}\n$$\n这两个式子在变化前后，形式基本一样。区别的地方那个在于学习的目标函数区别，后者学习的目标函数是包含噪音之后的目标函数。而且可以看出，在变化之后，同样计算二阶导数，计算难度依然没有发生改变。\n引入联合概率密度分布$p_\\sigma(\\tilde{\\bf\nx}, {\\bf x})=p_\\sigma(\\tilde{\\bf x}|{\\bf x})p_0({\\bf\nx})$，其中x̃是在准确分布x基础上的随机取值，定义噪音得分匹配(DSM)：\n$$\nJ_{DSM,p_{\\sigma}}(\\theta)=\\mathbb{E}_{p_\\sigma(\\tilde x,x)}\\left[\n\\frac{1}{2} ||\\psi(\\tilde x;\\theta)-\\frac{\\partial ln p_{\\sigma}(\\tilde\nx|x)}{\\partial \\tilde x}||^2\\right]\n$$\n假设为高斯核函数关系$p_\\sigma(\\tilde\nx|x)=e^{-\\frac{||x-\\tilde x||^2}{2\\sigma^2}}$：\n$$\n\\frac{\\partial p_{\\sigma}(\\tilde x|x)}{\\partial \\tilde x} =\n\\frac{x-\\tilde x}{\\sigma^2}\n$$\n因此： $$\n\\begin{equation}\nJ_{DSM,p_{\\sigma}}(\\theta)=\\mathbb{E}_{p_\\sigma(\\tilde x,x)}\\left[\n\\frac{1}{2} ||\\psi(\\tilde x;\\theta)-\\frac{x-\\tilde\nx}{\\sigma^2}||^2\\right]\n\\end{equation}\n$$\n可以发现，在通过引入噪声函数之后，成功避免了二次导数的计算。然而DSM的引入是直接定义，并没有证明ESM的等价性。\n等价性证明\n$$\n\\begin{align*}\nJ_{ESM,p_{\\sigma}}(\\theta) &amp;= \\mathbb{E}_{p_\\sigma(\\tilde x)}\\left[\n\\frac{1}{2} ||\\psi(\\tilde x;\\theta)-\\frac{\\partial ln p_{\\sigma}(\\tilde\nx)}{\\partial \\tilde x}||^2\\right] \\\\\n&amp;= \\mathbb{E}_{p_\\sigma(\\tilde x)}\\left[ \\frac{1}{2} ||\\psi(\\tilde\nx;\\theta)||^2\\right]-S(\\theta)+C_2\\\\\n\\end{align*}\n$$\n其中$C_2=\\mathbb{E}_{p_\\sigma(\\tilde\nx)}\\left[ \\frac{1}{2}||\\frac{\\partial ln p_{\\sigma}(\\tilde x)}{\\partial\n\\tilde x}||^2 \\right]$，并不依赖于参数θ，可以直接忽略。\n$$\n\\begin{align*}\nS(\\theta) &amp;= \\mathbb{E}_{p_\\sigma(\\tilde x)} \\left[\n&lt;\\psi(\\tilde{\\bf x};\\theta),\\frac{\\partial lnp_\\sigma(\\tilde{\\bf\nx})}{\\partial \\tilde{\\bf x}}&gt; \\right] \\\\\n&amp;= \\int_{\\tilde{\\bf x}} p_\\sigma(\\tilde{\\bf x})&lt;\\psi(\\tilde{\\bf\nx};\\theta),\\frac{\\partial lnp_\\sigma(\\tilde{\\bf x})}{\\partial \\tilde{\\bf\nx}}&gt; \\mathrm{d}\\tilde{\\bf x} \\\\\n&amp;= \\int_{\\tilde{\\bf x}} p_\\sigma(\\tilde{\\bf x})&lt;\\psi(\\tilde{\\bf\nx};\\theta),\\frac{1}{p_\\sigma(\\tilde{\\bf x})} \\frac{\\partial\np_\\sigma(\\tilde{\\bf x})}{\\partial \\tilde{\\bf x}}&gt;\n\\mathrm{d}\\tilde{\\bf x} \\\\\n&amp;= \\int_{\\tilde{\\bf x}} &lt;\\psi(\\tilde{\\bf x};\\theta),\n\\frac{\\partial p_\\sigma(\\tilde{\\bf x})}{\\partial \\tilde{\\bf x}}&gt;\n\\mathrm{d}\\tilde{\\bf x} \\\\\n&amp;= \\int_{\\tilde{\\bf x}} &lt;\\psi(\\tilde{\\bf x};\\theta),\n\\frac{\\partial \\int_{\\bf x} p_\\sigma(\\tilde{\\bf x}|{\\bf x})p_\\sigma({\\bf\nx})\\mathrm{d}{\\bf x}}{\\partial \\tilde{\\bf x}}&gt; \\mathrm{d}\\tilde{\\bf\nx} \\\\\n&amp;= \\int_{\\tilde{\\bf x}} \\int_{\\bf x} p_\\sigma({\\bf\nx})&lt;\\psi(\\tilde{\\bf x};\\theta), \\frac{\\partial p_\\sigma(\\tilde{\\bf\nx}|{\\bf x})}{\\partial \\tilde{\\bf x}}&gt; \\mathrm{d}{\\bf x}\n\\mathrm{d}\\tilde{\\bf x} \\\\\n&amp;= \\int_{\\tilde{\\bf x}} \\int_{\\bf x} p_\\sigma({\\bf\nx})p_\\sigma(\\tilde{\\bf x}|{\\bf x})&lt;\\psi(\\tilde{\\bf x};\\theta),\n\\frac{\\partial ln p_\\sigma(\\tilde{\\bf x}|{\\bf x})}{\\partial \\tilde{\\bf\nx}}&gt; \\mathrm{d}{\\bf x} \\mathrm{d}\\tilde{\\bf x} \\\\\n&amp;= \\int_{\\tilde{\\bf x}} \\int_{\\bf x} p_\\sigma(\\tilde{\\bf x},{\\bf\nx})&lt;\\psi(\\tilde{\\bf x};\\theta), \\frac{\\partial ln p_\\sigma(\\tilde{\\bf\nx}|{\\bf x})}{\\partial \\tilde{\\bf x}}&gt; \\mathrm{d}{\\bf x}\n\\mathrm{d}\\tilde{\\bf x} \\\\\n&amp;= \\mathbb{E}_{p_\\sigma(\\tilde x, x)} \\left[ &lt;\\psi(\\tilde{\\bf\nx};\\theta),\\frac{\\partial lnp_\\sigma(\\tilde{\\bf x}|{\\bf x})}{\\partial\n\\tilde{\\bf x}}&gt; \\right] \\\\\n\\end{align*}\n$$\n从而得到： $$\n\\begin{align*}\nJ_{ESM,p_{\\sigma}}(\\theta) &amp;= \\mathbb{E}_{p_\\sigma(\\tilde x)}\\left[\n\\frac{1}{2} ||\\psi(\\tilde\nx;\\theta)||^2\\right]-\\mathbb{E}_{p_\\sigma(\\tilde x, x)} \\left[\n&lt;\\psi(\\tilde{\\bf x};\\theta),\\frac{\\partial lnp_\\sigma(\\tilde{\\bf\nx}|{\\bf x})}{\\partial \\tilde{\\bf x}}&gt; \\right]+C_2\\\\\n\\end{align*}\n$$\n另一方面，针对DSM进行分解： $$\n\\begin{align*}\nJ_{DSM,p_{\\sigma}}(\\theta)&amp;=\\mathbb{E}_{p_\\sigma(\\tilde x,x)}\\left[\n\\frac{1}{2} ||\\psi(\\tilde x;\\theta)-\\frac{\\partial ln p_{\\sigma}(\\tilde\nx|x)}{\\partial \\tilde x}||^2\\right] \\\\\n&amp;= \\mathbb{E}_{p_\\sigma(\\tilde x)}\\left[ \\frac{1}{2} ||\\psi(\\tilde\nx;\\theta)||^2 \\right]-\\mathbb{E}_{p_\\sigma(\\tilde x, x)} \\left[\n&lt;\\psi(\\tilde{\\bf x};\\theta),\\frac{\\partial lnp_\\sigma(\\tilde{\\bf\nx}|{\\bf x})}{\\partial \\tilde{\\bf x}}&gt; \\right]+C_3\n\\end{align*}\n$$\n其中$C_3=\\mathbb{E}_{p_\\sigma(\\tilde x,\nx)}\\left[\\frac{1}{2}||\\frac{\\partial ln p_{\\sigma}(\\tilde x|x)}{\\partial\n\\tilde x}||^2\\right]$，同样不依赖于θ参数，可以认为是一个常量。因此可以得到DSM与ESM的关系：\n$$\n\\begin{align}\nJ_{DSM,p_{\\sigma}}(\\theta) = J_{ESM,p_{\\sigma}}(\\theta)-C_3+C_2\n\\end{align}\n$$\n其中C2, C3与优化目标θ无关，因此可以直接忽略。因此可以证明两者是等价的。\n总结与分析\n相对于ESM方法，引入噪音简化二阶偏导为一个关于方差σ的函数。并且成功证明，两者等价。\n然而这个方法存在一些问题： * 学习到的是加上噪音之后的分布，不是原分布\n* 加入的方差σ很难控制调整\n切片匹配得分（Sliced Score\nMatching，SSM）\n来源于文章——Sliced Score Matching: A Scalable Approach to Density and\nScore Estimation。\n降维思想\n直接对梯度进行比较，会因为维度较高产生问题，可以尝试通过一个函数V，将高维度映射到低纬度上。\n$$\n\\begin{align*}\nJ_{SSM}(\\theta)&amp;=\\mathbb{E}_{\\xi}\\left[\\frac{1}{2}||{\\bf v}^T\n\\psi(\\xi;\\theta)- {\\bf v}^T\\psi_x(\\xi)||^2\\right]\\\\\n&amp;= \\mathbb{E}_{p_x(\\xi)}[\\frac{1}{2} {\\bf v}^T \\psi(\\xi;\\theta)^2\n{\\bf v}+\\text{tr}({\\bf v}^T\\nabla_{\\xi} \\psi_{\\xi}(\\xi;\\theta){\\bf v})]\n\\\\\n\\end{align*}\n$$\n要求${\\bf v}\\sim p_v, \\mathbb{E}_{p_v}[{\\bf\nv}{\\bf v}^T]&gt;0, \\mathbb{E}_{p_v}[||{\\bf\nv}||^2_2]&lt;\\infty$，这是因为需要最后出一个与θ无关的常数。这种分布也是容易找到的，例如正态分布、均匀分布等。\n\n","categories":["Machine Learning"],"tags":["Score matching model","Explicit Score Matching","Implicit Score Matching","Denoising Score Matching","Sliced Score Matching"]},{"title":"Neural Network Diffusion","url":"/2024/03/04/DL/Neural_Network_Diffusion/Neural_Network_Diffusion/","content":"Introduction\n这篇文章的主要任务是，利用Diffusion\nModel生成具备高表现能力的神经网络参数。\n利用 autoencoder 和 laten diffusion model\n两个主要部件，其中autoencoder将网络参数进行提取，diffusion\nmodel再进行训练，然后再将训练好的模型进行解码。\n\n将神经网络的训练与扩散逆过程进行对比： 1.\n都是从随机到一个特定的分布。 2.\n高质量的图像与具备很好表现的网络参数，可以退化为一个简单分布。\n\n\ndiffusion model VS model\nparameters\n\n本文提出parameter generation, 叫做 neural network diffusion (p-diff,\np stands for parameter)。\n首先用已经训练好的模型参数，训练自编码器。 然后用标准latent diffusion\nmodel 从随机噪声中合成编码后的表示。最后，利用训练完的diffusion\nmodel，通过已经训练过的自编码器去生成新的参数。\nNerual Network Diffusion\nPreliminaries of diffusion\nmodels\n\n\nTrain LDM\n\n前向过程在不断的增加噪声，后向过程在猜测噪声分布。训练目标是计算分布的KL散度，尽可能的小。\n上图中，LDM表示latent diffusion\nmodel，训练编码后的表示。前向过程为：从已经表示的分布增加噪声，逐步成为随机噪声分布；后向过程为，从随机噪声出发逐步预测噪声进行去噪，得到原始的表达。\nParameter autoencoder\n\n\nAutoEncoder\n\n利用训练好的数据，进行编码训练。\nInference\n\n\nInference\n\n使用DDPM进行优化。\nResult\n\n\nresult\n\n从结果来看部分数据集上最优，其它大部分也与最优表现持平。\n该模型是否仅仅记住了训练好的模型参数，而非生成了新的模型参数？从结果来看，生成的模型要高于输入训练的模型，可见其是学习到了一些内容。\n","categories":["Machine Learning"],"tags":["Diffusion Model"]},{"title":"A Survey of Monte Carlo Tree Search Methods","url":"/2024/04/17/DL/Survey_MCTS/Survey_MCTS/","content":"本文为蒙特卡洛树搜索综述节选。\n蒙特卡洛树搜索（Monte Carlo Tree\nSearch，简称MCTS）是一种用于决策过程的模拟和搜索算法，特别适用于解决复杂的顺序决策问题。以下是MCTS的几个核心步骤：\n\n选择（Selection）：从根节点开始，根据某种策略（如UCB1公式），选择一条路径直到达到一个未扩展的节点。\n拓展（Expansion）：在当前选中的节点上添加一个新的子节点。\n模拟（Simulation）：从新扩展的节点开始进行随机模拟（即走子），直到游戏结束，并记录结果。\n反向传播（Backpropagation）：将模拟的结果回传，更新沿途节点的统计信息。\n\n值得一提的是，MCTS通过不断重复上述过程，逐渐构建出一个代表不同行动及其结果概率的搜索树。最终，算法会选择具有最高胜率的行动作为推荐的行动。\n此外，MCTS与传统的博弈树搜索相比，它不需要构建整个博弈树，而是通过模拟来评估局面，这使得它能够处理更大规模的搜索空间。然而，MCTS也存在一些局限性，比如对于非零和游戏的适应性、在面对随机性或不完全信息时的表现等问题。尽管如此，MCTS仍然是现代人工智能领域的一个重要工具，尤其是在棋类游戏中的应用，如AlphaGo/Zero等著名程序就是基于MCTS的变体。\n\nBackground\n包含决策过程（decision theory）、博弈论（game theory）、Monte Carlo\n以及 bandit-based methods。\nDecision Theory\n本质是马尔可夫决策决策过程（Markov Decision Processes，简记为\nMDPs），通过一系列 状态-动作-回报 系列完成对于决策过程的刻画。\n部分观测的MDP（Partially Observable\nMDPs，简记为POMDP），每次获得的状态只是整体状态的一部。\nGame Theory\nMonte Carlo Methods\nBandit-Based Methods\n多臂老虎机问题（Multi-armed Bandit\nproblems）是知名的系列决策问题。该问题的难点在于平衡探索与开发（Exploration\nand\nExploitation），以推荐系统为例，在已经知道用户兴趣点之后需要进行“开发”，但是现有的兴趣点可能不是用户最感兴趣的，或者该兴趣点会随着时间改变，因此需要进行“探索”，不断试探用户新的感兴趣内容。在Spin\nGlass求基态问题中，表现为是在这个结构中继续降低能量，还是选择升高温度跳出当前局域范围进行探索。Bandit\n算法用于解决该问题。\n一种有效的方案是基于上置信界（upper confidence bound\n简记UCB）。最简单的UCB算法为UCB1。\n细致平衡和这个感觉类似，这两者是否有关系？\nMonte Carlo Tree Search\nMCTS依靠于两个基本概念：动作的真实回报，可以依靠随机模拟近似；这些回报可以有效的调整策略去接近最优策略。\nAlgorithm\n基础算法通过迭代构建树，从根节点出发搜索子节点，然后选取最好的子节点作为下一次搜索的根节点。在这个迭代过程中有4个典型步骤：\n1)\n选择：从根节点开始递归应用子节点选择策略遍历整个树，直到达到收敛节点。\n2) 探索：产生动作，将更多节点添加进树中。 3)\n模拟评估：通过策略模拟给出一个节点的评估分数。 4)\n反向传播：通树结构反向传播模拟评估结果。\n采用以下两个直接的策略： 1) Tree policy:\n从搜索树中选择或者探索一个叶子节点。如何平衡探索与贪心选择，是这个算法的关键。\n2) Default policy:\n模拟评估非终止状态的分数。这里一直没有明白，算法并没有对该模型的知识，如何评估一个局面的好坏呢？如果已经对这个问题已经有了很好的了解，那直接贪心就可以了，为什么还要有MCTS？\n伪代码为： \nv0是根节点s0的评分，其中vl是叶子节点sl的评分，Δ是从探索节点返回的值。\n\n\ngeneral MCTS approach\n\n上面展示了一次过程的示意图。\nDevelopment\n\n\ndevelopment of MCTS\n\nTree policy\nUpper Confidence Bound for Trees (UCT)算法是Tree\npolicy中的一种，用于解决exploration–exploitation dilemma.\n在子节点j去选择最大化：\n$$\\begin{align}\n\\mathrm{UCT}=\\bar{X}_j+2 C_p \\sqrt{\\frac{2 \\ln n}{n_j}} \\label{UCB}\n\\end{align}$$\n其中 n\n是当前节点被遍历过的次数，nj是子节点j被遍历过的次数，并且限制Cp &gt; 0。如果超过一个子节点有相同的最大值，通常随机选择。Xi, t和X̄j是选择j的平均回报，值在范围[0, 1]上。通常设置nj = 0用于鼓励探索未曾探索过的区域。Cp可以用来调节探索的倾向，有很多文献对这个的选择有很多讨论。\n$\\eqref{UCB}$存在这样的一种思想，如果子节点都探索过，倾向于选择收益高的节点；如果子节点存在没有探索过的节点，倾向于选择没有探索过的节点。\nDefault policy\n\nIn the simplest case, this default policy is uniformly random.\n\n最简单的处理方案是随机产生。\n看这部分算法原本目的是想要了解这部分内容，但是现在发现MCTS的核心思想在于如何平衡探索和开发。这部分策略本质上是评价函数，如何构建评价函数，从而可以对状态进行评分。这其实是强化学习的任务。MCTS的任务是在知道这部分内容的前提下，将评估函数很好的与实际应用结合。\n该函数的设计本质上是一个很难的问题。综述中给出了如下的设计提升方案：\n* Rule-Based Simulation Policy * Contextual Monte Carlo Search * Fill\nthe Board * Learning a Simulation Policy * Using History Heuristics *\nEvaluation Function * Simulation Balancing * Last Good Reply *\nPatterns\nCode\n  以上式算法的伪代码。\n下面分析GitHub上关于MCTS的实现，代码地址。\n首先导入相关的包：\nimport loggingimport mathimport numpy as npEPS = 1e-8log = logging.getLogger(__name__)\n接下来创建名为MCTS的类：\nclass MCTS():    &quot;&quot;&quot;    This class handles the MCTS tree.    &quot;&quot;&quot;    def __init__(self, game, nnet, args):        self.game = game        self.nnet = nnet        self.args = args        # 以下内容全部用字典表示，key是状态对应的字符串        # 存储状态的Q值        self.Qsa = &#123;&#125;  # stores Q values for s,a (as defined in the paper)        # 存储已经探索过状态-动作对的次数        self.Nsa = &#123;&#125;  # stores #times edge s,a was visited        # 存储已经探索过状态的次数        self.Ns = &#123;&#125;  # stores #times board s was visited        # 存储初始策略        self.Ps = &#123;&#125;  # stores initial policy (returned by neural net)        # 存储游戏终止状态        self.Es = &#123;&#125;  # stores game.getGameEnded ended for board s        # 存储该状态下接下来合法移动        self.Vs = &#123;&#125;  # stores game.getValidMoves for board s\n以下search与getActionProb函数，均是MCTS类中的函数。\nsearch函数执行一次搜索过程，从一个节点开始，不断探索子节点，直到达到终态。每一步选择最大UCB的过程。\nclass MCTS():    def __init__(self, game, nnet, args):        ...    def search(self, canonicalBoard):        &quot;&quot;&quot;        This function performs one iteration of MCTS. It is recursively called        till a leaf node is found. The action chosen at each node is one that        has the maximum upper confidence bound as in the paper.        Once a leaf node is found, the neural network is called to return an        initial policy P and a value v for the state. This value is propagated        up the search path. In case the leaf node is a terminal state, the        outcome is propagated up the search path. The values of Ns, Nsa, Qsa are        updated.        NOTE: the return values are the negative of the value of the current        state. This is done since v is in [-1,1] and if v is the value of a        state for the current player, then its value is -v for the other player.        Returns:            v: the negative of the value of the current canonicalBoard        &quot;&quot;&quot;        # 将状态转化为字符串的形式        s = self.game.stringRepresentation(canonicalBoard)        # 如果状态不在之前是否记录表中，则重新检测是否为终态。        if s not in self.Es:            # 是终态返回 1 or -1（表示胜负结果），不是终态返回 0            self.Es[s] = self.game.getGameEnded(canonicalBoard, 1)        # 如果已经终止，直接返回结果        if self.Es[s] != 0:            # terminal node            return -self.Es[s]        # 如果不在策略的记录表中，产生初始策略        if s not in self.Ps:            # leaf node            # 神经网络评估该状态价值            self.Ps[s], v = self.nnet.predict(canonicalBoard)            # 产生所有合法移动            valids = self.game.getValidMoves(canonicalBoard, 1)            # 遮盖不合法移动            self.Ps[s] = self.Ps[s] * valids  # masking invalid moves            sum_Ps_s = np.sum(self.Ps[s])            if sum_Ps_s &gt; 0:                self.Ps[s] /= sum_Ps_s  # renormalize            else:                # if all valid moves were masked make all valid moves equally probable                # NB! All valid moves may be masked if either your NNet architecture is insufficient or you&#x27;ve get overfitting or something else.                # If you have got dozens or hundreds of these messages you should pay attention to your NNet and/or training process.                   log.error(&quot;All valid moves were masked, doing a workaround.&quot;)                self.Ps[s] = self.Ps[s] + valids                self.Ps[s] /= np.sum(self.Ps[s])            self.Vs[s] = valids            self.Ns[s] = 0            return -v        # 给予当前状态的合法移动        valids = self.Vs[s]        # 初始化当前最好UCB，当前最好选择        cur_best = -float(&#x27;inf&#x27;)        best_act = -1        # pick the action with the highest upper confidence bound        # 选择UCB最高的动作，返回所有可能的动作状态数        for a in range(self.game.getActionSize()):            if valids[a]:   #检测是否合法                # 计算UCB                if (s, a) in self.Qsa:                    u = self.Qsa[(s, a)] + self.args.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s]) / (                            1 + self.Nsa[(s, a)])                else:                    u = self.args.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s] + EPS)  # Q = 0 ?                if u &gt; cur_best:                    cur_best = u                    best_act = a        # 选择子节点并更新状态        a = best_act        next_s, next_player = self.game.getNextState(canonicalBoard, 1, a)        next_s = self.game.getCanonicalForm(next_s, next_player)        # 子节点进行迭代        v = self.search(next_s)        # 更新X与Nsa        if (s, a) in self.Qsa:            self.Qsa[(s, a)] = (self.Nsa[(s, a)] * self.Qsa[(s, a)] + v) / (self.Nsa[(s, a)] + 1)            self.Nsa[(s, a)] += 1        else:            self.Qsa[(s, a)] = v            self.Nsa[(s, a)] = 1        self.Ns[s] += 1        return -v\ngetActionProb为MCTS的每一步搜索\nclass MCTS():    def __init__(self, game, nnet, args):        ...    # 温度相当于给予不同动作一个概率，如果temp=1则直接贪心选择     def getActionProb(self, canonicalBoard, temp=1):        &quot;&quot;&quot;        This function performs numMCTSSims simulations of MCTS starting from        canonicalBoard.        Returns:            probs: a policy vector where the probability of the ith action is                   proportional to Nsa[(s,a)]**(1./temp)        &quot;&quot;&quot;        # 进行多次模拟        for i in range(self.args.numMCTSSims):            self.search(canonicalBoard)        # 将状态编码为字符串        s = self.game.stringRepresentation(canonicalBoard)        # 遍历当前状态下，所有合法动作已经探索过的次数        counts = [self.Nsa[(s, a)] if (s, a) in self.Nsa else 0 for a in range(self.game.getActionSize())]        # 如果温度为0则贪心的返回        if temp == 0:            bestAs = np.array(np.argwhere(counts == np.max(counts))).flatten()            bestA = np.random.choice(bestAs)            probs = [0] * len(counts)            probs[bestA] = 1            return probs        # 温度非0,给予每个动作一个归一化的被选择几率值        counts = [x ** (1. / temp) for x in counts]        counts_sum = float(sum(counts))        probs = [x / counts_sum for x in counts]        return probs\n","categories":["Machine Learning"],"tags":["Reinforcement Learning","Monte Carlo","Monte Carlo Tree Search"]},{"title":"ViT and ViViT","url":"/2024/02/29/DL/ViT_ViViT/ViT_ViViT/","content":"简介\n将 Transformer\n架构加入视觉领域，ViT与ViViT是分别是将该架构加入图片分类与视频分类领域，是该方向的两篇代表作。\n\nViT: AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE\nRECOGNITION AT SCALE\nViViT: ViViT: A Video Vision Transformer\n\n\nVision Transformer(ViT)\nViT尽可能的遵循原始Transformer。\n\n\nViT structure\n\n标准的 Transformer\n的输入是一维序列，因此首先需要将二维的图像整形为一维的序列。将其作为整体，称作patch，输入到Transformer进行\nembedding。\n位置编码直接相加进path embedding。\nTrandformer Encoder架构为：\n\n\nTrandformer Encoder\n\n数学公式总结为： $$\\begin{align}\nz_0 &amp;= [x_\\text{class}; x_p^1 E;x_p^2 E;\\cdots ;x_p^N\nE]+E_\\text{pos}\\quad E\\in \\mathcal R^{(p^2\\cdot C)\\times D},E_{pos}\\in\n\\mathcal R^{(N+1)\\times D} \\\\\nz'_l &amp;= MSA(LN(z_{l-1}))+z_{l-1} \\quad l=1\\cdots L \\\\\nz_l &amp;= MLP(LN(z'_l))+z'_l \\quad l=1\\cdots L \\\\\ny &amp;= LN(z_L^0)\n\\end{align}$$\n其中C是通道数，D是样本数，p2是分块之后的数量，MSA是multiheaded\nselfattention，MLP是多层感知机，LN是 Layernorm，并且z00 = xclass\nVideo Vision\nTransformer(ViViT)\n基于图像，进一步整合时空的Transformer结构。能够对视频进行有效的处理。\n\n\nViViT\n\n除了ViT提出的patch embedding，在处理时空信息上本文提出了Tubelet\nembedding。\n\n\nTubelet embedding\n\n其在时间信息上同样进行编码，组成一个包含部分时间与部分空间信息的embedding。这样就成功让Transformer可以输入时间与空间信息，接下来需要处理的是patch\nembedding 与 tubelet embedding 两部分信息如何输入进\ntransformer。虽然其同为编码信息，但是时间和空间的信息如何有效的耦合就是新的问题。这篇文章提出了四种架构。\nSpation-temporal attendtion\n直接认为两者地位等价，作为相同的token进行输入。显然则会导致输入的信息过于庞大，这是最吃资源的一种。\nFactorised encoder\n\n\nFactorised\n\n这种方案包含两层encoder，第一层将在同一个tubelet 附近的\npatch进行encoder，然后下一步将其在时间上进行encoder。\nFactorised self-attention\n\n\nFactorised self-attention\n\n与第一种方案一样，同样认为等价的地位，但只进行self-attention操作。首先先处理空间，然后是时间。\nFactorised dot-product\nattention\n\n\nFactorised dot-product\nattention\n\n分别处理时间与空间上的embedding，然后拼接再作为一个整体。\n","categories":["Machine Learning"],"tags":["ViT","ViViT","Transform"]},{"title":"Sora原理分析","url":"/2024/02/28/DL/sora/sora/","content":"简介\nsora完成了文本生成视频的任务，其中视频的时长与连贯性都有非常惊艳的效果，不仅将视频时长拓展到了60S的水平，而且即使视频中发生物品遮挡，在之后也能成功接上，视频整体非常连贯。\n感谢Datawhale开源社区提供相关资源。\n\nVision Transformer\n基于官网的介绍： &gt; We leverage a transformer architecture that\noperates on spacetime patches of video and image latent codes.\n可见sora的基本架构来源于Transform，这里需要先介绍该领域的经典模型Vision\nTransformer(ViT)。\nTransform 是广泛应用于 NLP 的架构，会将不同的 token\n以序列方式进行处理。在 CV 上，也有很多将 Transform 引入的尝试，ViT\n基本将原生的架构引入视觉领域。\n\n\nViT\n\n首先图片不能直接将像素作为一个基本单位作为一个token，这样输入规模将会过大。需要进行分割，将整张图片进行分割，左下角将整张图片分为9个部分，每个部分作为基本的单位，然后将位置信息直接相加，称为\nPatch ，接下来将其线性化，输入到Transform Encoder。\nVideo Vision Transformer\n\nAt a high level, we turn videos into patches by first compressing\nvideos into a lower-dimensional latent space, and subsequently\ndecomposing the representation into spacetime patches.\n\n将视频同样进行切块的技术，考虑之前的文章ViViT: A Video Vision\nTransformer(ViViT)\n\n\nTurning visual data into\npatches\n\n针对于时间部分，同样是划分为小部分块，称为\ntuplet。然后以一定序列的方式进行编码，一维化输入到 Transform。\n\n\nTuplet\n\n训练过程为：\n\n\nViViT\n\nScaling transformers\nfor video generation\n整个训练过称为 diffusion model\n\n\ndiffusion_model\n\n","categories":["Machine Learning"],"tags":["Transform","Sora"]},{"title":"Bayesian Optimization","url":"/2024/11/08/Math/BayesianOpt/BayesianOpt/","content":"贝叶斯优化（Bayesian Optimization）是一种基于贝叶斯定理:\n$$\nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n$$\n的全局优化方法，通常用于在计算代价高昂的情况下优化黑箱函数。它主要用于高效地寻找目标函数的最优解，尤其在函数不可微、函数形状复杂、或者评估函数代价昂贵（如深度学习模型的超参数优化）时特别有效。\n\n贝叶斯优化基本思想\n贝叶斯优化的核心是利用已有的观测数据，构建目标函数的近似模型（通常是高斯过程或其他代理模型），然后在这个近似模型上寻找最优解。具体来说，贝叶斯优化通过以下步骤进行：\n\n构建代理模型：使用已有的观测数据构建一个代理模型（如高斯过程回归），该模型可以近似目标函数。这个代理模型既能预测目标函数的输出，也能量化预测的不确定性。\n选择采样点：基于代理模型的输出和不确定性，使用一种称为采集函数（Acquisition\nFunction）的策略，确定下一步要评估的采样点。采集函数在模型不确定性大的区域更倾向于采样，确保探索性。\n更新代理模型：在新的采样点上评估目标函数并获取真实值，将新数据加入已有数据中，以更新代理模型。\n迭代进行：重复采样、更新代理模型和优化采集函数，直到满足预设的停止条件（如达到指定次数或精度要求）。\n\n通过上述步骤，贝叶斯优化逐步将代理模型拟合得更加精准，以更少的评估次数找到目标函数的最优解。\n采集函数（Acquisition\nFunction）\n采集函数用于在当前代理模型的基础上选择下一步的采样点，它平衡了探索（探索不确定区域）和开发（在最优点附近深入搜索）的需求。常见的采集函数有：\n\n期望提升（Expected Improvement,\nEI）：在当前最优解的基础上，期望获得提升的采样点。\n置信上限（Upper Confidence Bound,\nUCB）：考虑模型预测的均值和不确定性，选择具有高置信上限的采样点。\n概率提升（Probability of Improvement,\nPI）：选择在当前最优值基础上改进概率最大的采样点。\n\n不同的采集函数适用于不同的应用场景，可根据具体需求选择。\n示例\n使用 sklearn\n中的高斯过程（GaussianProcessRegressor）作为代理模型。使用基本的库为：\nimport numpy as npfrom scipy.stats import normfrom sklearn.gaussian_process import GaussianProcessRegressorfrom sklearn.gaussian_process.kernels import Matern\n定义目标函数，为简单起见，使用一个一维抛物线函数。实际应用中，这个目标函数可以是昂贵的黑箱函数。\ndef objective_function(x):    return (x - 2) ** 2 + 1\n使用期望提升（Expected Improvement,\nEI）采集函数来选择下一个评估点。EI 采集函数的公式如下：\nEI(x) = max (0, μ(x) − f(x+) − ξ) × Φ(z) + σ(x)ϕ(z)\n其中 μ(x) 和 σ(x) 是代理模型在 x 处的预测均值和标准差，f(x+)\n是当前最优值，ξ\n是平衡探索和开发的参数（通常设为 0.01）。\ndef expected_improvement(X, X_sample, Y_sample, model, xi=0.01):    mu, sigma = model.predict(X, return_std=True)    mu_sample_opt = np.min(Y_sample)    with np.errstate(divide=&#x27;warn&#x27;):        imp = mu_sample_opt - mu - xi        Z = imp / sigma        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)        ei[sigma == 0.0] = 0.0    return ei\nΦ(Z)\n是标准正态分布的累积分布函数，ϕ(Z)\n是标准正态分布的概率密度函数。\n根据 EI\n值找到最优的候选点，我们在定义的搜索空间内对采集函数进行最大化。\ndef propose_location(acquisition, X_sample, Y_sample, model, bounds, n_restarts=25):    dim = X_sample.shape[1]    min_val = 1    min_x = None    for x0 in np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_restarts, dim)):        res = minimize(lambda x: -acquisition(x.reshape(-1, dim), X_sample, Y_sample, model),                        x0=x0, bounds=bounds, method=&#x27;L-BFGS-B&#x27;)        if res.fun &lt; min_val:            min_val = res.fun            min_x = res.x    return min_x.reshape(-1, 1)\n在初始化采样点后，我们不断进行以下循环：更新代理模型、选择新的评估点、更新数据，直到达到预设条件。\n# 定义搜索空间bounds = np.array([[-5.0, 5.0]])# 初始化样本点X_sample = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(5, 1))Y_sample = objective_function(X_sample)# 设置高斯过程代理模型kernel = Matern(length_scale=1.0)model = GaussianProcessRegressor(kernel=kernel, alpha=1e-6)# 优化主循环n_iterations = 10for i in range(n_iterations):    # 更新代理模型    model.fit(X_sample, Y_sample)    # 选择下一个评估点    X_next = propose_location(expected_improvement, X_sample, Y_sample, model, bounds)    # 评估目标函数    Y_next = objective_function(X_next)    # 更新样本集合    X_sample = np.vstack((X_sample, X_next))    Y_sample = np.vstack((Y_sample, Y_next))# 输出找到的最优解best_index = np.argmin(Y_sample)print(&quot;最佳输入点:&quot;, X_sample[best_index])print(&quot;最佳输出值:&quot;, Y_sample[best_index])\n采集函数与Active\nLearning和MCTS的异同\n贝叶斯优化中的采集函数、主动学习（Active\nLearning）、蒙特卡洛树搜索（MCTS）中的探索与利用策略，这三者确实在概念和策略上有很多相似之处，但它们的目标和应用场景有所不同。它们共享的核心思想是\n平衡探索和利用，即在信息不足的情况下找到最佳的选择。然而，三者的具体实现方式、关注点和目标存在一些差异。\n1. 共同点：探索与利用的平衡\n贝叶斯优化、主动学习和 MCTS\n都试图在有限资源下（如计算次数、样本数量、计算成本）高效地做出最优决策。为此，它们都需要在\n探索（了解更多新的信息）和\n利用（利用已有信息获得最优解）之间找到平衡。具体来说：\n\n探索：在不确定性较高的地方进行采样、选点或扩展，使得对系统（目标函数、分类边界、搜索树）的了解更全面。\n利用：集中在已知效果较好的地方进行进一步优化，尽快找到最佳解或正确答案。\n\n2. 三者的区别\n1) 贝叶斯优化\n\n目标：贝叶斯优化的目标是\n优化复杂且代价高昂的黑箱函数。它通过少量采样逐步找到目标函数的最优值。\n采集函数：通过代理模型（如高斯过程）预测函数的均值和不确定性，并通过采集函数（如期望提升、置信上限）选择最优采样点。\n探索与利用的平衡：采集函数的设计考虑了对最优解改进的潜力和不确定性，使得采样点既能优化当前最优值又能探索未观测区域。\n\n2) 主动学习（Active Learning）\n\n目标：主动学习的目标是\n在标签代价高昂的情况下，通过有选择地标注数据提升模型性能。它在机器学习场景中选择对模型改进最有效的未标注样本，从而用最少的标注成本提升模型准确性。\n策略：主动学习的策略往往基于样本的\n不确定性 或\n信息量，例如选择模型预测最不确定的样本（最大熵、最小置信度）或对决策边界贡献最大的样本。\n探索与利用的平衡：在主动学习中，探索和利用的平衡意味着在选择样本时既要减少模型的不确定性，也要选择对决策边界有贡献的样本，使模型尽快准确地覆盖数据分布。\n\n3) 蒙特卡洛树搜索（MCTS）\n\n目标：MCTS 主要用于\n决策问题中的路径选择，如在游戏中找到最优策略。MCTS\n是一种\n树搜索算法，通过模拟和采样在巨大搜索空间中找到最优行动路径。\n策略：MCTS 的策略在于对节点进行扩展和选择，常用\n上置信上限（UCB） 来决定探索和利用。UCB\n通过平衡节点的获胜概率和探索价值，决定是否深入已有路径或探索新路径。\n探索与利用的平衡：MCTS\n的探索利用平衡在于确保既不会忽略高潜力的节点，也不会在当前优节点过度深入。它动态地在不同节点之间分配模拟次数，逐步找到全局最优路径。\n\n3. 关系与差异总结\n\n\n\n\n\n\n\n\n\n方法\n应用场景\n主要目标\n探索/利用实现\n\n\n\n\n贝叶斯优化\n黑箱函数优化\n最小化评估代价，找最优值\n采集函数（EI、UCB、PI等）\n\n\n主动学习\n样本选择、模型训练\n最少样本提升模型准确性\n不确定性采样、信息量最大化\n\n\nMCTS\n决策、路径规划\n找到最优路径\n上置信上限（UCB）\n\n\n\n三者是否是同样的东西？\n尽管三者具有相似的探索-利用平衡机制，它们\n不是完全相同的。具体来说：\n\n贝叶斯优化\n是一个基于概率模型的黑箱优化方法，目的是在复杂函数中找到全局最优解。\n主动学习\n是一种选择性采样策略，用于通过最少标注数据训练出高性能模型。\nMCTS\n是一种决策树搜索算法，用于路径和策略选择。\n\n三者共享的思想是\n在信息不完全或资源有限的情况下，通过探索-利用平衡来找到最优解。这使得它们在本质上有相通之处，但因目标和应用场景不同，它们的实现细节和关注点各不相同。\n","categories":["Math"],"tags":["Bayesian Optimization"]},{"title":"Ising formulations of many NP problems","url":"/2024/04/15/Math/Ising_formulations_of_many_NP_problems/Ising_formulations_of_many_NP_problems/","content":"为许多NP-complete和NP-hard问题提供了Ising形式，包括Karp的21个NP完全问题中的所有问题。这收集并扩展了从分区、覆盖和可满足性到Ising模型的映射。在每种情况下，所需的自旋数最多是问题大小的三次方。这项工作可能对设计绝热量子优化算法有用。别的优化算法同样有用。\n文献： * 本文Ising\nformulations of many NP problems * On\nthe computational complexity of Ising spin glass models * E.\nBoros and P.L. Hammer. “Pseudo-Boolean optimization”, Discrete Applied\nMathematics 123 155 (2002). * Reducibility\namong Combinatorial Problems * M. Me ́zard and A.\nMontanari. Information, Physics and Computation (2009) * Y.\nFu and P.W. Anderson. “Application of statistical mechanics to\nNP-complete problems in combinatorial optimisation”, Journal of Physics\nA19 1605 (1986).\n\n名词解释： * adiabatic quantum optimization (AQO) * NP problem\n(Nondeterministic Polynomial)\nNP问题是指可以在多项式时间内验证一个解的问题。换句话说，如果给定一个问题的解，存在一个多项式时间的算法来验证这个解是否正确。NP问题是决定性问题的复杂度类，它包含所有那些解可以在多项式时间内被验证的问题。\n* NP-hard problem\nNP-hard问题是指至少和NP中的最困难问题一样困难的问题。更严格地说，NP-hard问题是指不可能在多项式时间内解决的所有问题，除非P=NP（目前还未知是否成立）。所有的NP-hard问题也属于NP问题，因为你可以在多项式时间内验证一个假想的解（尽管找到解本身非常困难）。\n* NP-complete\nNP-complete问题既是NP问题又是NP-hard问题。这意味着NP-complete问题在NP中是“最难”的问题，并且很难找到这些问题的确切解，但是如果给出了解，可以在多项式时间内验证它。NP-complete问题在计算复杂性理论中非常重要，因为它们可能是P问题（能够在多项式时间内解决的问题）之外的最难问题类别。\n* NP-complete decision problem NP-complete decision\nproblem是一类特殊的NP-complete问题，它们只要求回答“是”或“否”。也就是说，这类问题是决策问题，其解答为真或假，而不是提供一个具体的解。例如，在一个图中寻找哈密顿路径是一个NP-complete问题，但判断一个图是否含有哈密顿路径就是一个NP-complete\ndecision problem。 * Chimera graph Chimera\ngraph是量子计算中一个非常重要的概念，它通常与二次无约束二值优化问题（QUBOs）和量子退火算法相关联。在Chimera图中，节点代表目标函数的变量，边则表示变量之间的相互作用。这种图结构允许我们将问题的解映射到量子处理器上，其中节点映射为量子位，边映射为耦合器。通过这样的映射，可以解决如旅行商优化问题等复杂的组合优化问题。\n* Complete graph 完全图\nIntroduction\n众所周知Ising自旋模型是NP-hard模型，因此自然相让其余的NP问题映射到Ising自旋模型上。从数学上讲，如果一个问题是NP完全的，意味着总是能在多项式时间内将其映射到一个Ising问题上。这个映射过程被重新定义为pseudo-Boolean\noptimization problem。\n这篇文章主要目的是展示Ising模型Hamilton的一些精巧构造，这些构造如何帮助映射其它的NP问题。同时还将回顾一下，之前如何将覆盖、满足问题映射到Ising自旋模型上，特别是包括如何将所有的NP问题转化为Ising问题，但Ising模型的自旋数目将会是问题的多项式，并且不低于N3。\n在量子计算中利用模拟退火算法的求解优化问题，是通过嵌合图（chimera\ngraph）完成，然而将完全图（complete\ngraph）转化为嵌合图是低效的，参考文献1和2。\nPartitioning Problems\n分割问题是将一个集合分为两个或者多个子集。这里回顾了分割问题到自旋玻璃的映射，并提出了一个新的基于类似思想（团问题）的映射。\nNumber Partitioning\nNumber partitioning 问题描述如下：\n在一个包含N个正数的集合S = {n1, …, nN}，将该集合分为两个不互相包含的集合\nR 和 S − R。是否能够使得两子集元素之和相等？\n该问题已经知道是一个NP-complete问题，将该问题转化为一个Ising模型：\n令ni(i = 1, …, N = |S|)\n描述集合S中的元素，然后定义Hamilton： $$\\begin{align}\nH=A\\left(\\sum_{i=1}^N n_i s_i\\right)^2\n\\end{align}$$ 其中si = ±1\n是自旋取值，其中A &gt; 0是正约束条件，通常会被取为1,但是保留这个参数可以区分不同能量尺度，参考文献。\n该Hamilton的描述是显然的，s用于区分两类，n表示值，如果两类值相等，那么H = 0。同时也说明，H越低划分越好。\nGraph Partitioning\n图分割是最初进行统计物理与NP问题关联的例子。问题描述如下：\n考虑图G = (V, E)，有偶数个节点N = |V|，需要解决如何将集合V分割成大小相等的两个子集，每个子集的大小为N/2，同时使得连接这两个子集的边数最小化？\n将这个问题转化为Ising模型，放置自旋sv = ±1在节点v ∈ V，并且±1表示两类。设计Hamilton为：\n$$\\begin{align}\nH=&amp;H_A+H_B \\\\\nH_A=&amp;A\\left(\\sum_{n=1}^N s_i\\right)^2 \\\\\nH_B=&amp;B \\sum_{(u v) \\in E} \\frac{1-s_u s_v}{2}\n\\end{align}$$\n当A &gt; 0时候，HA是对两个集合数量不相等惩罚项目，相差越大HA越大；当B &gt; 0时候，HB是对边数量的惩罚，连接数量越多HB越大。\nCliques\nCliques 问题描述如下：\n在无向图G = (V, E)中，大小为K的团簇（clique）是一个顶点子集W ⊆ V，其大小为|W| = K，使得子图(W, EW)（其中EW是将边集E限制在W中节点之间的边上）是一个完全图。即图中所有可能的$\\frac{K(K -\n1)}{2}$条边都存在，因为团簇中的每个顶点都与其他每个顶点相连。简单描述为给定图G和顶点数K，能否从G中选取K个顶点构成完全图。\n将这个问题转化为Ising模型，放置自旋sv = ±1在节点v ∈ V。通常将sα修改取值范围为xα： $$\nx_\\alpha \\equiv \\frac{s_\\alpha+1}{2}\n$$ 将Hamliton写为： $$\\begin{align}\nH=A\\left(K-\\sum_v x_v\\right)^2+B\\left[\\frac{K(K-1)}{2}-\\sum_{(u v) \\in\nE} x_u x_v\\right]\n\\end{align}$$ 其中A, B &gt; 0，在基态的时候H = 0。第一项要求满足节点数量为K，第二项要求这些节点构成完全图。\n对于H ≠ 0的其他情况，该问题可以转化为：\n$$\\begin{align}\nH_{\\min }(n)=&amp;A(n-K)^2+B \\frac{K(K-1)-n(n-1)}{2} \\\\\n=&amp;(n-K)\\left[A(n-K)-B \\frac{n+K-1}{2}\\right]\n\\end{align}$$\n另一方面，需要寻找最大的\nCliques。同时原文中也提出了将该问题规模从N 减少到 log N的方案。\nBinary Integer Linear\nProgramming\n令x1, …, xN\n是 N 个二值变量，表示为x。The binary integer linear\nprogramming (ILP) 问题定义为： $$\n\\begin{aligned}\n&amp; \\max _x \\sum_{j=1}^n c_j x_j \\\\\n&amp; \\text { s.t. } \\sum_{j=1}^n a_j x_j = b \\\\\n&amp; x \\in\\{0,1\\}^n \\\\\n&amp;\n\\end{aligned}\n$$\nIsing Hamiltonian H = HA + HB，可写为：\n$$\\begin{align}\nH_A=&amp;A \\sum_{j=1}^m\\left[b_j-\\sum_{i=1}^N S_{j i} x_i\\right]^2 \\\\\nH_B=&amp;-B \\sum_{i=1}^N c_i x_i\n\\end{align}$$ 其中 A &gt; 0，HA将约束转化为惩项；\n0 &lt; B ≪ A，为优化目标。\nCovering and Packing\nProblems\nProblems with Inequalities\nColoring Problems\nHamiltonian Cycles\nTree Problems\nGraph Isomorphisms\nConclusions\n这篇文章聚焦于如何将 NP-complete/hard problems\n转化为可以利用Ising类型Hamilton可表示的形式。\n","categories":["Math"],"tags":["NP problems","Ising"]},{"title":"Annealing approach to root finding","url":"/2024/08/27/Phys/Annealing_root_finding/Annealing_root_finding/","content":"在数值分析和科学计算中，Newton-Raphson方法是一个非常重要的工具，它被广泛用于求解方程的根。然而，经典的Newton-Raphson方法在面对复杂的非线性方程和多个根的情况下，可能会出现收敛性差、振荡或发散的情况。为了解决这些问题，研究者们提出了一种基于物理学启发的新方法，该方法在保留Newton-Raphson方法优点的同时，通过引入一个新的参数β，有效提升了算法的收敛速度和稳定性。\nLink: * Annealing\napproach to root finding\n\n这项改进的灵感来源于物理学中的退火过程。退火是指材料在高温下加热，然后缓慢冷却，以达到其最低能量状态的过程。通过这种逐渐降温的方法，材料可以在高温下探索更多的状态空间，而在低温下则集中于更稳定的状态。\n这种物理过程被引入到数值计算中，特别是用于求解非线性方程的根。传统的Newton-Raphson方法可以看作是高温下的大幅跳跃，能够快速找到接近根的位置，但在接近根时可能会失去效率。通过引入一个类似“温度”的参数β，算法在初期可以进行广泛的搜索，而在接近根时逐渐收敛，使得算法既能快速搜索，又能稳定逼近根。\n在经典的Newton-Raphson方法中，新的迭代点是通过以下公式计算的：\n$$\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\n$$\n这种方法在接近根时会快速收敛，但远离根时可能会跳过根或收敛到错误的解。为了改进这一点，本文提出了一个改进的更新公式：\n$$\\begin{aligned}\n&amp;\n\\hat{x}_{n+1}=x_n-\\frac{f\\left(x_n\\right)}{f^{\\prime}\\left(x_n\\right)}\n\\\\ &amp; x_{n+1}=\\hat{x}_{n+1}-\\beta\n\\frac{f\\left(\\hat{x}_{n+1}\\right)}{f^{\\prime}\\left(x_n\\right)}\n\\end{aligned}$$\n其中，xn + 1(NR)是经典Newton-Raphson方法计算的中间值。通过引入参数β，算法能够在早期（类似高温状态）进行较大的跳跃搜索，而在后期（类似低温状态）逐步逼近根。这种方法与Adomian’s\nmethod有一定关联。\n这个改进方法的核心在于β值的动态调整。通过调整β，算法可以在迭代过程中逐步从“高温”过渡到“低温”，从而实现从全局搜索到局部收敛的平衡。当β = 0时，算法等同于经典的Newton-Raphson方法，具有快速的搜索能力；当β = 1时，算法更精确地逼近根，收敛速度显著提高。\n\n\nImproved convergence to\nroots\n\n从上图中可以发现收敛性得到提升。尤其对于右图这种具有振荡性质函数，通过加入β利用函数本身的性质进行收敛。\n\n\nImproved convergence to\nroots\n\n提升迭代速度。\n这里能否联系Loss of plasticity in deep continual learning文章中修改反向传播的想法。通过β的退火机制，通过对一些参数遗忘从而实现连续学习，一个简单的想法是当学习新的内容时，意味着温度升高，一些参数可以重新调整，然后学习的过程伴随着温度的下降，当完后学习之后，收敛到一个基态。\n","categories":["Physics"],"tags":["Computer Physics"]},{"title":"KL散度在VAE中的代码实现","url":"/2024/04/08/Math/KL_divergence_in_code/KL_divergence_in_code/","content":"\n能否使用除Gauss分布外的其他分布？为什么一定要选取Gauss分布呢？\n\n这篇笔记用于记录在VAE计算过程中，KL散度计算的实现方式，以及背后的原理分析。\n参考资料： * KL散度的推导过程\n\n在VAE中，为了解决随机采样无法求梯度的问题，假设潜变量空间的参数满足Gauss分布（一维情况）：\n$$\\begin{align}\n\\mathcal{N}(\\mu, \\sigma)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2}}\ne^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}\n\\end{align}$$\n然后利用均值和方差进行抽样。这种技巧称为重参数化（reparameterization）。\n在应用重参数化技巧后，需要计算两个分布的差距，因此引入KL散度计算：\n$$\\begin{align}\n\\text{KL}\\left(p_1(x) \\| p_2(x)\\right)=\\int_x p_1(x) \\ln\n\\frac{p_1(x)}{p_2(x)} d x\n\\end{align}$$\n针对两个一维高斯分布: p1 = 𝒩1(μ1, σ1), p2 = 𝒩2(μ2, σ2),\n可以计算他们的KL散度如下: $$\n\\begin{align}\n\\text{KL}\\left(p_1 \\| p_2\\right) &amp; =\\int_x p_1(x) \\ln\n\\frac{p_1(x)}{q_1(x)} d x \\\\\n&amp; =\\int_x p_1(x) \\left[\\ln p_1(x) - \\ln q_1(x)\\right] d x \\\\\n&amp; =\\int_x p_1(x) \\left[\\ln\\left( \\frac{1}{\\sqrt{2 \\pi \\sigma_1^2}}\ne^{-\\frac{(x-\\mu_1)^2}{2 \\sigma_1^2}}\\right) - \\ln\\left(\n\\frac{1}{\\sqrt{2 \\pi \\sigma_2^2}} e^{-\\frac{(x-\\mu_2)^2}{2\n\\sigma_2^2}}\\right)\\right] d x \\\\\n&amp; =\\int_x p_1(x) \\left[-\\ln \\sigma_1 -\\frac{(x-\\mu_1)^2}{2\n\\sigma_1^2} + \\ln\\sigma_2 +\\frac{(x-\\mu_2)^2}{2 \\sigma_2^2}\\right] d x\n\\\\\n&amp; =\\int_x p_1(x) \\left[\\ln \\frac{\\sigma_2}{\\sigma_1}\n-\\frac{(x-\\mu_1)^2}{2 \\sigma_1^2} +\\frac{(x-\\mu_2)^2}{2\n\\sigma_2^2}\\right] d x \\\\\n&amp; =\\log \\frac{\\sigma_2}{\\sigma_1}+\\underbrace{\\int_x p_1(x)\n\\frac{\\left(x-\\mu_2\\right)^2}{2 \\sigma_2^2} d\nx}_{\\mathrm{B}}-\\frac{1}{2}\\\\\n\\end{align}\n$$\n关注较为复杂的第二项, 即下标 B\n这一项。接下来要用的并不是带入 p1(x),\n而是较为巧妙的使用 x − μ2 = (x − μ1) + (μ1 − μ2),\n重新使用常数、方差等性质。 $$\n\\begin{align}\nB &amp; =\\frac{1}{2 \\sigma_2^2}\\int_x p_1(x)\\left(x-\\mu_2\\right)^2 d x\n\\\\\n&amp; =\\frac{1}{2 \\sigma_2^2}\\int_x\np_1(x)\\left[\\left(x-\\mu_1\\right)+\\left(\\mu_1-\\mu_2\\right)\\right]^2 d x\n\\\\\n&amp; =\\frac{1}{2 \\sigma_2^2}\\int_x p_1(x)\\left(x-\\mu_1\\right)^2 d\nx+\\frac{2\\left(\\mu_1-\\mu_2\\right) }{2 \\sigma_2^2}\\int_x\np_1(x)\\left(x-\\mu_1\\right) d x+\\left(\\mu_1-\\mu_2\\right)^2 \\\\\n&amp; =\\frac{1}{2\n\\sigma_2^2}\\left[\\sigma_1^2+0+\\left(\\mu_1-\\mu_2\\right)^2\\right] \\\\\n&amp; =\\frac{1}{2\n\\sigma_2^2}\\left[\\sigma_1^2+\\left(\\mu_1-\\mu_2\\right)^2\\right]\n\\end{align}\n$$\n综合以上结果, 我们有: $$\n\\text{KL}\\left(p_1 \\| p_2\\right)=\\log\n\\frac{\\sigma_2}{\\sigma_1}+\\frac{1}{2\n\\sigma_2^2}\\left(\\sigma_1^2+\\left(\\mu_1-\\mu_2\\right)^2\\right)-\\frac{1}{2}\n$$\n接下来, 回到VAE中, 由于我们将自由变量从标准正态分布中采样, 即 p2 = 𝒩2(0, 1);\n$$\n\\text{KL}\\left(p_1|| p_2\\right)=-\\frac{1}{2} \\times\\left[2 \\log\n\\sigma_1+1-\\sigma_1^2-\\mu_1^2\\right]\n$$\n大多数的VAE代码中间学习并不是 μ 与 σ, 而是 μ 与logvar = log σ2，因此在代码中需要进行变换\n。\n代码如下： KL = -0.5*torch.sum(logvar + 1 - mu.pow() - logvar.exp())\n","categories":["Machine Learning"],"tags":["Kullback Leibler Divergence","KL Divergence"]},{"title":"Boltzmann Machine","url":"/2022/11/30/Phys/Boltzmann_machine_phy/Boltzmann_machine_phy/","content":"波尔兹曼机是物理模型，同时也是早期的机器学习模型。\nReference: * 神经网络的统计力学 –\n受限制玻尔兹曼机的统计力学\n\nBoltzmann Machine\n\n\n\nBM with RBM\n\n上图(a)为玻尔兹曼机，类似于Ising模型，但是任意两个节点之间均含有连接。\n$$\\begin{align}\nE(\\boldsymbol{\\sigma})=-\\sum_i h_i \\sigma_i-\\sum_{i&lt;j} w_{i j}\n\\sigma_i \\sigma_j \\label{Ising}\n\\end{align}$$\n其中σi = ±1是节点i的取值，wij是任意两个节点之间的链接权重，hi为外磁场项（可以理解为偏置项）。构型的波尔兹曼分布为：\n$$\\begin{align}\np(\\boldsymbol{\\sigma})=\\frac{1}{Z} e^{-\\beta E(\\sigma)}\n\\end{align}$$ 其中Z = ∑σe−βE(σ)为配分函数。给定数据，数据表现形式通过σ表现，目标是设计权重wij，使得对应构型的概率分布（波尔兹曼分布）较大；类似与Hopfield模型，可以通过输入部分构型，还原出整体的构型。这个任务本质上就是逆\nIsing 问题（Inverse Ising Problem）。\n为了讨论方便，这里假设 hi = 0  ∀i。当然，比较直接的权重设计方案是\nHebbian rule，但是这个并不是最优的结果。以下使用极大似然估计方法。\n$$\n\\begin{align}\nL(\\boldsymbol{\\theta} \\mid\\{\\boldsymbol{\\sigma}\\}) &amp;\n=\\left\\langle\\log\n\\left(p_{\\boldsymbol{\\theta}}(\\boldsymbol{\\sigma})\\right)\\right\\rangle_{\\text\n{data }} \\\\\n&amp; =-\\langle E(\\boldsymbol{\\sigma},\n\\boldsymbol{\\theta})\\rangle_{\\text {data }}-\\log Z(\\boldsymbol{\\theta})\n\\\\\n&amp; =\\sum_{i=1}^N h_i\\left\\langle\\sigma_i\\right\\rangle_{\\text {data\n}}+\\sum_{i&lt;j} w_{i j}\\left\\langle\\sigma_i\n\\sigma_j\\right\\rangle_{\\text {data }}-\\log Z(\\boldsymbol{\\theta})\n\\end{align}\n$$\n其中⟨…⟩data \n表示对数据求平均，θ\n表示模型参数 {W, h}，计算L(θ ∣ {σ})\n梯度：\n$$\n\\begin{align}\n\\frac{\\partial L}{\\partial h_i} &amp;\n=\\left\\langle\\sigma_i\\right\\rangle_{\\text {data\n}}-\\left\\langle\\sigma_i\\right\\rangle_{\\text {model }}  \\\\\n\\frac{\\partial L}{\\partial w_{i j}} &amp; =\\left\\langle\\sigma_i\n\\sigma_j\\right\\rangle_{\\text {data }}-\\left\\langle\\sigma_i\n\\sigma_j\\right\\rangle_{\\text {model }}\n\\end{align}\n$$\n其中⟨…⟩model \n表示模型平均，表示的模型的热力学平均，是一个加权平均，穷举计算法耗时太长，直接计算是不现实的，可以认为是一个重要性抽样，从而使用蒙卡的方案计算。模型参数的梯度更新可以写为：\n$$\\begin{align}\n\\Delta h_i &amp; =\\eta \\frac{\\partial L}{\\partial\nh_i}=\\eta\\left(\\left\\langle\\sigma_i\\right\\rangle_{\\text {data\n}}-\\left\\langle\\sigma_i\\right\\rangle_{\\mathrm{model}}\\right)  \\\\\n\\Delta w_{i j} &amp; =\\eta \\frac{\\partial L}{\\partial w_{i\nj}}=\\eta\\left(\\left\\langle\\sigma_i \\sigma_j\\right\\rangle_{\\text {data\n}}-\\left\\langle\\sigma_i \\sigma_j\\right\\rangle_{\\mathrm{model}}\\right)\n\\end{align}$$\n其中η表示学习率。第一部分是数据的平均值，可以通过对数据进行平均计算；第二部分是模型的平均值，这部分计算如之前的描述，只能采用MCMC方法等重要性抽样方法才能计算（两点关联可以转化为点$\\frac{\\partial\\left\\langle\\sigma_i\\right\\rangle_{\\text\n{model }}}{\\partial h_j}=\\left\\langle\\sigma_i\n\\sigma_j\\right\\rangle_{\\text {model\n}}-\\left\\langle\\sigma_i\\right\\rangle_{\\text {model\n}}\\left\\langle\\sigma_j\\right\\rangle_{\\text {model\n}}$），然而由于模型的hj与wij每一步都会发生变化，意味着每一次更新参数就需要重新进行一次重要性抽样，这显然是不能接受的。\n如果存在更高关联，例如三阶：\n$$\\begin{align}\nE(\\boldsymbol{\\sigma})=-\\sum_i h_i \\sigma_i-\\sum_{i&lt;j} w_{i j}\n\\sigma_i \\sigma_j-\\sum_{i&lt;j&lt;k}\\kappa_{ijk}\\sigma_i\\sigma_j\\sigma_k\n\\end{align}$$\n如何将这些关联以另一种形式展现，从而避免计算上的复杂性，这里引入一个隐变量s。\n\n\n\nHidden\n\n$$\\begin{align}\nE(\\boldsymbol{\\sigma},s)=-\\sum_i h_i \\sigma_i-\\sum_{i&lt;j} w_{i j}\n\\sigma_i \\sigma_j-s\\sum_{i}\\sigma_i k_i\n\\end{align}$$\n其中ki表示σi与隐变量之间的强度。可知其波尔兹曼分布为：\n$$\\begin{align}\nP(\\boldsymbol{\\sigma},s) &amp;\\sim\n\\exp\\left(E(\\boldsymbol{\\sigma},s)\\right) \\\\\nP(\\boldsymbol{\\sigma})\n&amp;=\\sum_{s}\\exp\\left(E(\\boldsymbol{\\sigma},s)\\right) \\\\\n&amp;\\sim \\exp\\left(-\\sum_i h_i \\sigma_i-\\sum_{i&lt;j} w_{i j} \\sigma_i\n\\sigma_j\\right)2\\cosh\\left(\\sum_i\\sigma_i k_i\\right) \\\\\n&amp;= \\exp\\left(-\\sum_i h_i \\sigma_i-\\sum_{i&lt;j} w_{i j} \\sigma_i\n\\sigma_j\\right)\\exp\\left( \\ln\\left[ 2\\cosh\\left(\\sum_i\\sigma_i\nk_i\\right) \\right] \\right)\n\\end{align}$$\n可以将ln [2cosh (∑iσiki)]展开，从而得到高阶项:\n$$\n\\log (2 \\cosh (x))=\\log\n   (2)+\\frac{x^2}{2}-\\frac{x^4}{12}+O\\left(x^6\\right)\n$$\n上面只是引入一个隐变量，更普遍的是具有更多隐变量图中(b)，这样会使得模型表达能力提升。对应的能量为：\n$$\\begin{align}\nE(\\boldsymbol{\\sigma},s)=-\\sum_i h_i \\sigma_i-\\sum_{i&lt;j} w_{i j}\n\\sigma_i \\sigma_j-\\sum_{i,a}k_{ia}\\sigma_i\ns_a-\\sum_{a&lt;b}\\gamma_{ab}s_a s_b\n\\end{align}$$\n需要学习的模型参数除了$\\eqref{Ising}$中提到的w与h以外，还需要学习kab与γab两个参数：\n$\\begin{aligned}\n&amp; \\Delta k_{a b}=\\eta\\left(\\left\\langle\\sigma_i\ns_a\\right\\rangle_{\\text {data }}-\\left\\langle\\sigma_i\ns_a\\right\\rangle_{\\text {model }}\\right) \\\\\n&amp; \\Delta \\gamma_{a b}=\\eta\\left(\\left\\langle s_a\ns_b\\right\\rangle_{\\text {data }}-\\left\\langle s_a\ns_b\\right\\rangle_{\\text {model }}\\right)\n\\end{aligned}$\n由于s是隐变量，并不能直接直接得到，但是可以得到其概率值，例如通过\nSigmoid 函数： $$\\begin{align}\nP(s_a=1|\\mathbf{\\sigma})=\\text{sigmoid}\\left(\n-\\sum_{i,a}k_{ia}\\sigma_i-\\sum_{a&lt;b}\\gamma_{ab}s_b \\right)\n\\end{align}$$\n可以看到上面的计算过程中使用到了其它隐变量s，这里不得不进行近似，使用伯努力采样赋予s值；依据这个过程将所有的隐变量概率以及具体的值计算出来。\n可以看到在加入隐变量值后，计算CD散度需要更多的蒙卡模拟从而得到模型平均。这是一个十分费时的过程。\nRestricted Boltzmann Machine\n为了解决计算模型平均花费很多时间，将一些关联项进行省略，包含可见变量之间的相互作用以及隐变量之间的相互作用项，将这个模型称之为受限玻尔兹曼机。\n\n\n\nBM with RBM\n\n$$\\begin{align}\nE(\\boldsymbol{\\sigma}, \\boldsymbol{s})=-\\sum_{i, a} \\sigma_i w_{i a}\ns_a-\\sum_i \\phi_i \\sigma_i-\\sum_a h_a s_a\n\\end{align}$$\n其中σ与s为可见变量与隐变量，其余参数为相互作用强度与偏置项。波尔兹曼分布为：\n$$\\begin{align}\np(\\boldsymbol{\\sigma}, \\boldsymbol{s})=\\frac{1}{Z} e^{-\\beta\nE(\\boldsymbol{\\sigma}, s)}\n\\end{align}$$\n其中Z = ∑σ, se−βE(σ, s)，并且假设β = 1，将其作用吸收进相互作用参数中。\n将相同类型的节点之间的相互作用断开，好处在于可以实现近独立分布。只需要知道可见节点（隐藏节点）就可以推断出隐藏节点（可见节点）的概率分布，相同类型节点之间是独立的。\n$$\n\\begin{align}\np\\left(\\sigma_i \\mid \\boldsymbol{s}\\right) &amp;\n=\\frac{\\sum_{\\left\\{\\sigma_j: j \\neq i\\right\\}} p(\\boldsymbol{\\sigma},\n\\boldsymbol{s})}{\\sum_\\sigma p(\\boldsymbol{\\sigma}, \\boldsymbol{s})} \\\\\n&amp; =\\frac{e^{\\sigma_i\\left(\\phi_i+\\sum_a w_{i a}\ns_a\\right)}}{e^{\\sigma_i\\left(\\phi_i+\\sum_a w_{i a}\ns_a\\right)}+e^{-\\sigma_i\\left(\\phi_i+\\sum_a w_{i a} s_a\\right)}} \\\\\n&amp; =\\frac{1}{1+e^{-2 \\sigma_i\\left(\\phi_i+\\sum_a w_{i a} s_a\\right)}}\n\\\\\np\\left(s_a \\mid \\boldsymbol{\\sigma}\\right) &amp;\n=\\frac{\\sum_{\\left\\{s_b: b \\neq a\\right\\}} p(\\boldsymbol{\\sigma},\n\\boldsymbol{s})}{\\sum_s p(\\boldsymbol{\\sigma}, \\boldsymbol{s})} \\\\\n&amp; =\\frac{e^{s_a\\left(h_a+\\sum_i w_{i a}\n\\sigma_i\\right)}}{e^{s_a\\left(h_a+\\sum_i w_{i a}\n\\sigma_i\\right)}+e^{-s_a\\left(h_a+\\sum_i w_{i a} \\sigma_i\\right)}} \\\\\n&amp; =\\frac{1}{1+e^{-2 s_a\\left(h_a+\\sum_i w_{i a} \\sigma_i\\right)}}\n\\end{align}\n$$\n计算权重的方法与玻尔兹曼机类似，同样使用极大似然估计。\n$$\\begin{align}\n\\mathcal{L}(\\boldsymbol{\\theta} \\mid\\{\\boldsymbol{\\sigma}\\}) &amp;\n=\\left\\langle\\log\n\\left(p_{\\boldsymbol{\\theta}}(\\boldsymbol{\\sigma})\\right)\\right\\rangle_{\\text\n{data }} \\\\\n&amp; =-\\langle E(\\boldsymbol{\\sigma},\n\\boldsymbol{\\theta})\\rangle_{\\text {data }}-\\log\nZ(\\{\\boldsymbol{\\theta}\\})\n\\end{align}$$\nθ 表示参数 {W, ϕ, h}，\n参数的梯度为：\n$$\n\\begin{align}\n&amp; \\frac{\\partial \\mathcal{L}\\left(\\left\\{w_{i a}, \\phi_i,\nh_a\\right\\}\\right)}{\\partial w_{i a}}=\\left\\langle\\sigma_i\ns_a\\right\\rangle_{\\text {data }}-\\left\\langle\\sigma_i\ns_a\\right\\rangle_{\\text {model }} \\\\\n&amp; \\frac{\\partial \\mathcal{L}\\left(\\left\\{w_{i a}, \\phi_i,\nh_a\\right\\}\\right)}{\\partial\n\\phi_i}=\\left\\langle\\sigma_i\\right\\rangle_{\\text {data\n}}-\\left\\langle\\sigma_i\\right\\rangle_{\\text {model }} \\\\\n&amp; \\frac{\\partial \\mathcal{L}\\left(\\left\\{w_{i a}, \\phi_i,\nh_a\\right\\}\\right)}{\\partial h_a}=\\left\\langle s_a\\right\\rangle_{\\text\n{data }}-\\left\\langle s_a\\right\\rangle_{\\text {model }}\n\\end{align}\n$$\nFree Energy Calculation\n$$\\begin{align}\np(\\boldsymbol{\\sigma}) &amp; =\\sum_s p(\\boldsymbol{\\sigma},\n\\boldsymbol{s}) \\\\\n&amp; =\\frac{1}{Z} \\sum_s e^{\\sum_a\\left(\\sum_i \\beta \\sigma_i w_{i\na}+\\beta h_a\\right) s_a+\\sum_i \\beta \\sigma_i \\phi_i} \\\\\n&amp; =\\frac{1}{Z} e^{\\sum_i \\beta \\sigma_i \\phi_i} \\sum_s \\prod_a\ne^{\\left(\\sum_i \\beta \\sigma_i w_{i a}+\\beta h_a\\right) s_a} \\\\\n&amp; =\\frac{1}{Z} \\prod_i e^{\\beta \\sigma_i \\phi_i} \\prod_a \\sum_{s_a}\ne^{\\left(\\sum_i \\beta \\sigma_i w_{i a}+\\beta h_a\\right) s_a} \\\\\n&amp; =\\frac{1}{Z} \\prod_i e^{\\beta \\sigma_i \\phi_i} \\prod_a\\left[2\n\\cosh \\left(\\beta \\boldsymbol{w}_a \\boldsymbol{\\sigma}+\\beta\nh_a\\right)\\right],\n\\end{align}$$\n可见cavity\n计算是将复杂计算转化为因子图迭代的过程，这是一种巧妙的近似，它的适用范围不限于计算自由能。\n画出因子图： \nfactor node表示2cosh (βwaσ + βha)，variable\nnode 表示σi。可以得到cavity迭代方程为：\n$$\n\\begin{align}\n&amp; P_{i \\rightarrow a}\\left(\\sigma_i\\right)=\\frac{1}{Z_{i \\rightarrow\na}} e^{\\phi_i \\sigma_i} \\prod_{b \\in \\partial i \\backslash a} \\mu_{b\n\\rightarrow i}\\left(\\sigma_i\\right) ; \\\\\n&amp; \\mu_{b \\rightarrow i}\\left(\\sigma_i\\right)=\\sum_{\\left\\{\\sigma_j\n\\mid j \\in \\partial b \\backslash i\\right\\}} 2 \\cosh\n\\left(\\boldsymbol{w}_b \\sigma+h_b\\right) \\prod_{j \\in \\partial b\n\\backslash i} P_{j \\rightarrow b}\\left(\\sigma_j\\right),\n\\end{align}\n$$\n其中 Zi → a = eϕi∏b ∈ ∂i ∖ aμb → i(+1) + e−ϕi∏b ∈ ∂i ∖ aμb → i(−1)，虽然已经近似处理，但是求解这个迭代方程需要O(2N − 1)的时间复杂度，因此还需要进一步近似。\n定义 𝒰b → i ≡ ∑j ∈ ∂b ∖ iwjbσj，根据中心极限定理（central\nlimit theorem (CLT)）在N\n较大的情况下 𝒰b → i应该服从高斯分布，因此𝒰b → i的均值和方差写为：\n$$\n\\begin{align}\nG_{b \\rightarrow i} &amp; =\\left\\langle\\mathcal{U}_{b \\rightarrow\ni}\\right\\rangle_{\\left\\{\\sigma_j \\mid j \\in \\partial b \\backslash\ni\\right\\}}=\\sum_{j \\in \\partial b \\backslash i} w_{j b} m_{j \\rightarrow\nb}  \\label{G}\\\\\n\\Xi_{b \\rightarrow i}^2 &amp; =\\left\\langle\\mathcal{U}_{b \\rightarrow\ni}^2\\right\\rangle_{\\left\\{\\sigma_j \\mid j \\in \\partial b \\backslash\ni\\right\\}}-\\left\\langle\\mathcal{U}_{b \\rightarrow\ni}\\right\\rangle_{\\left\\{\\sigma_j \\mid j \\in \\partial b \\backslash\ni\\right\\}}^2 \\\\\n&amp; \\simeq \\sum_{j \\in \\partial b \\backslash i} w_{j b}^2\\left(1-m_{j\n\\rightarrow b}^2\\right)\\\\\nm_{j \\rightarrow b} &amp;\\equiv \\sum_{\\sigma_j} \\sigma_j P_{j\n\\rightarrow b}\\left(\\sigma_j\\right)\n\\end{align}\n$$\n因此 μb → i(σi)\n利用高斯积分可以近似写为：\n$$\n\\begin{aligned}\n\\mu_{b \\rightarrow i}\\left(\\sigma_i\\right) &amp; =2 \\int D t \\cosh\n\\left(G_{b \\rightarrow i}+\\sqrt{\\Xi_{b \\rightarrow i}^2} t+h_b+w_{i b}\n\\sigma_i\\right) \\\\\n&amp; =2 e^{\\frac{\\Xi_{b \\rightarrow i}^2}{2}} \\cosh \\left(G_{b\n\\rightarrow i}+h_b+w_{i b} \\sigma_i\\right),\n\\end{aligned}\n$$\n其中 $D t \\equiv e^{-t^2 / 2} / \\sqrt{2\n\\pi} d t$。接下来计算mj → b即变量节点的概率：\n$$\n\\begin{align}\nm_{j \\rightarrow b} &amp; =\\sum_{\\sigma_j} \\sigma_j P_{j \\rightarrow\nb}\\left(\\sigma_j\\right) \\\\\n&amp; =\\frac{\\sum_{\\sigma_i} \\sigma_i e^{\\phi_i \\sigma_i} \\prod_{b \\in\n\\partial i \\backslash a} \\mu_{b \\rightarrow\ni}\\left(\\sigma_i\\right)}{\\sum_{\\sigma_i} e^{\\phi_i \\sigma_i} \\prod_{b\n\\in \\partial i \\backslash a} \\mu_{b \\rightarrow i}\\left(\\sigma_i\\right)}\n\\label{10.15}\\\\\n&amp; =\\tanh \\left(\\phi_i+\\sum_{b \\in \\partial i \\backslash a} u_{b\n\\rightarrow i}\\right) ; \\\\\nu_{b \\rightarrow i} &amp; =\\frac{1}{2} \\ln \\frac{\\mu_{b \\rightarrow\ni}(+1)}{\\mu_{b \\rightarrow i}(-1)}=\\frac{1}{2} \\ln \\frac{\\cosh\n\\left(h_b+G_{b \\rightarrow i}+w_{i b}\\right)}{\\cosh \\left(h_b+G_{b\n\\rightarrow i}-w_{i b}\\right)}\\label{u}\n\\end{align}\n$$\n从$\\eqref{G},\\eqref{10.15},\\eqref{u}$得到自洽迭代方程。\n对于自由能为：\n$$\n\\begin{align}\nF &amp; =\\sum_i F_i-(N-1) \\sum_a F_a \\\\\nF_i &amp; =-\\ln Z_i=-\\ln \\left(e^{\\phi_i} \\prod_{b \\in \\partial i}\n\\mu_{b \\rightarrow i}(+1)+e^{-\\phi_i} \\prod_{b \\in \\partial i} \\mu_{b\n\\rightarrow i}(-1)\\right) \\\\\nF_a &amp; =-\\ln Z_a=-\\ln \\left(2 e^{\\frac{\\Xi_a^2}{2}} \\cosh\n\\left(G_a+h_a\\right)\\right)\n\\end{align}\n$$\nend\nwhere . Inserting this result into the cavity probability Pi → a(σi),\nwe obtain the cavity magnetization\nwhere ub → i\nis the cavity bias (see Chap. 2). mi → a\nrepresents the massage passing from variable node i to factor node a, and ub → i\ndenotes the massage passing from factor node b to variable node i. Iterating Eq. (10.15) can reach\nthe fixed point. Then, the Bethe free energy can be calculated as\nfollows:\nwhere Fi and Fa are local\nfree energies of variable node i and factor node a, respectively, Ξa = ∑j ∈ ∂awja2(1 − mj → a2),\nand Ga = ∑j ∈ ∂awjamj → a.\nThe computation of Fa is similar to\nthat of μa → i.\nHere, we show an experiment result of the free energy computation via\nthe Bethe approximation (Fig. 10.4).\n","categories":["Physics"],"tags":["Spin Glass","Boltzmann Machine","Replica Method","Energy-based Model"]},{"title":"Boltzmann Machine Append","url":"/2022/11/30/Phys/Boltzmann_machine_phy/append/","content":"逆Ising问题及其求解方法\n引言\n逆Ising问题涉及从观测数据中推断Ising模型的参数。Ising模型是一种简单的数学模型，用于描述磁性材料中的自旋系统。解决逆Ising问题的方法包括极大似然估计（MLE）、蒙特卡罗方法（MCMC）、平均场近似、伪似然估计（PLE）以及对比散度（CD）。\n极大似然估计（MLE）\n步骤\n\n定义Hamiltonian: H(s) = −∑i &lt; jJijsisj\n定义配分函数: Z = ∑se−H(s)\n定义似然函数: $$\nL(J) = \\prod_{k=1}^{N} P(\\mathbf{s}^{(k)}|J) = \\prod_{k=1}^{N}\n\\frac{e^{-H(\\mathbf{s}^{(k)})}}{Z}\n$$\n取对数似然函数: $$\n\\log L(J) = -\\sum_{k=1}^{N} H(\\mathbf{s}^{(k)}) - N \\log Z\n$$\n优化对数似然函数:\n使用数值优化方法（如梯度下降）最大化对数似然函数。\n\n示例代码\nimport numpy as npfrom scipy.optimize import minimize# 观测数据data = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]])# 定义Hamiltoniandef hamiltonian(J, s):    return -J * s[0] * s[1]# 定义配分函数def partition_function(J):    return 2 * (np.exp(J) + np.exp(-J))# 定义对数似然函数def log_likelihood(J, data):    logL = 0    for s in data:        logL += -hamiltonian(J, s)    logL -= len(data) * np.log(partition_function(J))    return -logL  # 最小化负对数似然# 初始猜测initial_J = 0.1# 优化参数result = minimize(log_likelihood, initial_J, args=(data,))optimal_J = result.x[0]print(f&#x27;MLE Estimated J: &#123;optimal_J&#125;&#x27;)\n蒙特卡罗方法（MCMC）\n步骤\n\n初始化模型参数。\n生成样本：\n使用MCMC方法（如Metropolis-Hastings或Gibbs采样）生成自旋配置样本。\n计算统计量：\n基于生成的样本，计算系统的期望统计量。\n更新参数：\n使用梯度方法或其他优化技术调整模型参数。\n重复步骤2-4，直到参数收敛。\n\n示例代码\nimport numpy as np# 观测数据data = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]])# 初始化参数J = 0.1# 吉布斯采样函数def gibbs_sample(J, num_samples, burn_in):    samples = []    s = np.random.choice([-1, 1], size=2)    for _ in range(num_samples + burn_in):        for i in range(2):            prob = 1 / (1 + np.exp(-2 * J * s[1 - i]))            s[i] = 1 if np.random.rand() &lt; prob else -1        if _ &gt;= burn_in:            samples.append(s.copy())    return np.array(samples)# 计算期望统计量def calculate_statistics(samples):    correlations = np.mean(samples[:, 0] * samples[:, 1])    return correlations# 更新参数def update_parameters(J, samples, data):    data_corr = np.mean(data[:, 0] * data[:, 1])    sample_corr = calculate_statistics(samples)    learning_rate = 0.1    J += learning_rate * (data_corr - sample_corr)    return J# 蒙特卡罗迭代num_iterations = 100num_samples = 1000burn_in = 100for _ in range(num_iterations):    samples = gibbs_sample(J, num_samples, burn_in)    J = update_parameters(J, samples, data)    print(f&#x27;Iteration &#123;_&#125;: J = &#123;J&#125;&#x27;)print(f&#x27;Estimated J: &#123;J&#125;&#x27;)\n平均场近似（Mean Field\nApproximation）\n步骤\n\n定义Hamiltonian。\n引入平均场近似：\n每个自旋的影响被近似为一个平均场。\n计算自旋期望值： 根据平均场计算自旋的期望值。\n迭代求解：\n通过迭代更新每个自旋的期望值和相互作用参数。\n更新相互作用参数：\n调整相互作用参数使得模型生成的期望值与观测数据的期望值匹配。\n\n示例代码\nimport numpy as np# 观测数据data = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]])# 初始化参数J = 0.1# 计算观测数据的期望值mean_s1 = np.mean(data[:, 0])mean_s2 = np.mean(data[:, 1])# 定义迭代函数def mean_field_iteration(J, mean_s1, mean_s2, max_iter=100, tol=1e-5):    for _ in range(max_iter):        h1 = J * mean_s2        h2 = J * mean_s1        new_mean_s1 = np.tanh(h1)        new_mean_s2 = np.tanh(h2)        if np.abs(new_mean_s1 - mean_s1) &lt; tol and np.abs(new_mean_s2 - mean_s2) &lt; tol:            break        mean_s1, mean_s2 = new_mean_s1, new_mean_s2    return mean_s1, mean_s2# 迭代求解期望值mean_s1, mean_s2 = mean_field_iteration(J, mean_s1, mean_s2)# 更新相互作用参数def update_parameters(J, mean_s1, mean_s2, data):    observed_corr = np.mean(data[:, 0] * data[:, 1])    model_corr = mean_s1 * mean_s2    learning_rate = 0.1    J += learning_rate * (observed_corr - model_corr)    return J# 更新参数J = update_parameters(J, mean_s1, mean_s2, data)print(f&#x27;Estimated J: &#123;J&#125;&#x27;)\n伪似然估计（PLE）\n步骤\n\n定义条件概率： $$\\begin{align}\nP(s_i | \\mathbf{s}_{\\setminus i}) = \\frac{e^{s_i h_i}}{e^{h_i} +\ne^{-h_i}}\n\\end{align}$$\n定义伪似然函数： $$\\begin{align}\nPL(J) = \\prod_{i=1}^n \\prod_{k=1}^N P(s_i^{(k)} | \\mathbf{s}_{\\setminus\ni}^{(k)})\n\\end{align}$$\n取对数伪似然函数： $$\\begin{align}\n\\log PL(J) = \\sum_{i=1}^n \\sum_{k=1}^N \\log P(s_i^{(k)} |\n\\mathbf{s}_{\\setminus i}^{(k)})\n\\end{align}$$\n优化对数伪似然函数：\n使用数值优化方法（如梯度下降）最大化对数伪似然函数。\n\n示例代码\nimport numpy as npfrom scipy.optimize import minimize# 观测数据data = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]])# 定义条件概率def conditional_probability(s_i, s_j, J):    return 1 / (1 + np.exp(-2 * J * s_i * s_j))# 定义对数伪似然函数def log_pseudolikelihood(J, data):    logPL = 0    for s in data:        logPL += np.log(conditional_probability(s[0], s[1], J)) + np.log(conditional_probability(s[1], s[0], J))    return -logPL  # 最小化负对数伪似然# 初始猜测initial_J = 0.1# 优化参数result = minimize(log_pseudolikelihood, initial_J, args=(data,))optimal_J = result.x[0]print(f&#x27;Optimal J: &#123;optimal_J&#125;&#x27;)\n对比散度（CD）\n步骤\n\n定义能量函数： $$\\begin{align}\nE(\\mathbf{s}) = -\\sum_{i&lt;j} J_{ij} s_i s_j\n\\end{align}$$\n初始化模型参数。\n正向采样（Positive Phase）：\n从观测数据中采样，计算数据分布下的期望值。\n负向采样（Negative Phase）：\n使用Gibbs采样从模型分布中生成样本，计算模型分布下的期望值。\n更新参数：\n根据正向采样和负向采样的期望值差异，更新相互作用参数。\n迭代，直到参数收敛。\n\n示例代码\nimport numpy as np# 观测数据data = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]])# 初始化参数J = 0.1learning_rate = 0.1num_iterations = 100num_samples = 1000burn_in = 100# 计算观测数据的期望值mean_s1s2_data = np.mean(data[:, 0] * data[:, 1])# 吉布斯采样函数def gibbs_sample(J, num_samples, burn_in):    samples = []    s = np.random.choice([-1, 1], size=2)  # 初始自旋配置    for _ in range(num_samples + burn_in):        for i in range(2):            prob = 1 / (1 + np.exp(-2 * J * s[1 - i]))            s[i] = 1 if np.random.rand() &lt; prob else -1        if _ &gt;= burn_in:            samples.append(s.copy())    return np.array(samples)# 计算模型分布的期望值def calculate_model_expectation(J, num_samples, burn_in):    samples = gibbs_sample(J, num_samples, burn_in)    mean_s1s2_model = np.mean(samples[:, 0] * samples[:, 1])    return mean_s1s2_model# 对比散度更新for _ in range(num_iterations):    mean_s1s2_model = calculate_model_expectation(J, num_samples, burn_in)    J += learning_rate * (mean_s1s2_data - mean_s1s2_model)    print(f&#x27;Iteration &#123;_&#125;: J = &#123;J&#125;&#x27;)print(f&#x27;CD Estimated J: &#123;J&#125;&#x27;)\n总结\n逆Ising问题涉及从观测数据中推断Ising模型的相互作用参数。本文介绍了五种求解方法：极大似然估计（MLE）、蒙特卡罗方法（MCMC）、平均场近似、伪似然估计（PLE）以及对比散度（CD）。每种方法都有其优缺点，选择合适的方法取决于具体问题的规模、数据特性和计算资源。\n","categories":["Physics"],"tags":["Spin Glass","Boltzmann Machine","Replica Method","Energy-based Model"]},{"title":"Deep Unsupervised Learning using Nonequilibrium Thermodynamics","url":"/2024/01/22/DL/diffusion_process/diffusion_process/","content":"简介\n本篇文章来自于： Deep Unsupervised Learning using Nonequilibrium\nThermodynamics，arXiv:1503.03585v8 [cs.LG] 18 Nov 2015\n该篇文章为首次提出Deffusion\nModel的概念。算法的主要目标是构造一个前向传播、扩散的过程，通过这个过程可以将复杂的分布逐渐变为一个简单的分布。\n\n\n生成图片\n\n\n其中第一行是 swiss roll\n数据，通过扩散过程，从左到右，逐渐变为一个高斯分布。第二行是训练的模型，从右到左逐步从高斯分布生成原始的数据分布。\nForward Trajectory\n数据分布为q(x(0))，最终分布π(y)，其中利用马尔科夫扩散核Tπ(y|y′; β)，β为扩散率。\n$$\n\\begin{align}\n\\pi(y) &amp;= \\int \\mathrm{d}y' T_{\\pi}(y|y';\\beta)\\pi (y') \\\\\nq(x^{(t)}|x^{(t-1)}) &amp;= T_{\\pi}(x^{(t)}|x^{(t-1)};\\beta_t) \\\\\nq(x^{(0\\dots T)}) &amp;= q(x^{(0)})\\prod_{t=1}^{T} q(x^{(t)}|x^{(t-1)})\n\\\\\n\\end{align}\n$$\nReverse Trajectory\np为逆向使用数据的过程。\n$$\n\\begin{align}\np(x^{(T)}) &amp;= \\pi(x^{(T)}) \\\\\np(x^{(0\\dots T)}) &amp;= p(x^{(T)})\\prod_{t=T}^{1} p(x^{(t-1)}|x^{(t)})\n\\\\\n\\end{align}\n$$\nModel Probability\np(x(0)) = ∫dx(1⋯T)p(x(0⋯T))\n但是，事实上逆向轨迹几乎不可能被追踪，因此需要借助前向过程。 $$\n\\begin{align}\np(x^{(0)})&amp;=\\int \\mathrm{d}x^{(1\\cdots T)}p(x^{(0\\cdots\nT)})\\frac{q(x^{(1\\cdots T)|x^{(0)}})}{q(x^{(1\\cdots T)|x^{(0)}})} \\\\\n&amp;=\\int \\mathrm{d}x^{(1\\cdots T)}q(x^{(1\\cdots\nT)}|x^{(0)})\\frac{p(x^{(0\\cdots T)})}{q(x^{(1\\cdots T)}|x^{(0)})} \\\\\n&amp;=\\int \\mathrm{d}x^{(1\\cdots T)}q(x^{(1\\cdots\nT)}|x^{(0)})p(x^{(T)})\\prod_{t=T}^{1}\\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t)}|x^{(t-1)})}\n\\\\\n\\end{align}\n$$\n训练\n目标是为了最小化模型似然估计。\n$$\n\\begin{align}\nL &amp;= \\int \\mathrm{d}x^{(0)}q(x^{(0)})\\ln p(x^{(0)}) \\\\\n&amp;= \\int \\mathrm{d}x^{(0)}q(x^{(0)})\\ln \\left( \\int\n\\mathrm{d}x^{(1\\cdots T)}q(x^{(1\\cdots\nT)}|x^{(0)})p(x^{(T)})\\prod_{t=T}^{1}\\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t)}|x^{(t-1)})}\\right)\n\\\\\n&amp;\\geq \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\\ln \\left(\np(x^{(T)})\\prod_{t=T}^{1}\\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t)}|x^{(t-1)})}\\right)\n\\\\\n&amp;= \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\\ln  p(x^{(T)}) +\n\\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)}) \\sum_{t=T}^{1}\\ln\\left(\n\\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t)}|x^{(t-1)})}\\right)\\\\\n&amp;= \\int \\mathrm{d}x^{(T)}q(x^{(T)})\\ln  \\pi(x^{(T)}) + \\int\n\\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)}) \\sum_{t=T}^{1}\\ln\\left(\n\\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t)}|x^{(t-1)})}\\right)\\\\\n&amp;= \\int \\mathrm{d}x^{(T)}q(x^{(T)})\\ln  \\pi(x^{(T)}) +\n\\sum_{t=1}^{T} \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\n\\ln\\left( \\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t)}|x^{(t-1)})}\\right)\\\\\n&amp;= \\sum_{t=1}^{T} \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\n\\ln\\left( \\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t)}|x^{(t-1)})}\\right)-H_p\n(x^{T})\\\\\n&amp;= \\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\n\\ln\\left( \\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t)}|x^{(t-1)})}\\right)-H_p\n(x^{T})+\\int \\mathrm{d}x^{(0,1)}q(x^{(0, 1)}) \\ln\\left(\n\\frac{p(x^{(0)}|x^{(1)})}{q(x^{(1)}|x^{(0)})}\\right)\\\\\n&amp;= \\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\n\\ln\\left( \\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t)}|x^{(t-1)})}\\right)-H_p\n(x^{T})+\\int \\mathrm{d}x^{(0,1)}q(x^{(0, 1)}) \\ln\\left(\n\\frac{\\pi(x^{(0)})}{\\pi(x^{(1)})}\\right)\\\\\n&amp;= \\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\n\\ln\\left( \\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t)}|x^{(t-1)})}\\right)-H_p\n(x^{T})\\\\\n&amp;= \\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\n\\ln\\left( \\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t)}|x^{(t-1)},\nx^{(0)})}\\right)-H_p (x^{T})\\\\\n&amp;= \\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\n\\ln\\left( \\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t-1)}|x^{(t)},\nx^{(0)})}  \\frac{q(x^{(t-1)}|x^{(0)})}{q(x^{(t)}|x^{(0)})}  \\right)-H_p\n(x^{T})\\\\\n&amp;= \\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\n\\ln\\left( \\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t-1)}|x^{(t)},\nx^{(0)})}\\right)+\\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0\\cdots\nT)}q(x^{(0\\cdots T)}) \\ln \\left(\n\\frac{q(x^{(t-1)}|x^{(0)})}{q(x^{(t)}|x^{(0)})}\\right) -H_p (x^{T})\\\\\n&amp;= \\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\n\\ln\\left( \\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t-1)}|x^{(t)},\nx^{(0)})}\\right)+\\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0\\cdots\nT)}q(x^{(0\\cdots T)})  \\left( \\ln\nq(x^{(t-1)}|x^{(0)})-\\ln{q(x^{(t)}|x^{(0)})}\\right) -H_p (x^{T})\\\\\n&amp;= \\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\n\\ln\\left( \\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t-1)}|x^{(t)},\nx^{(0)})}\\right)+\\sum_{t=2}^{T}  \\left(\nH_q(x^{(t)}|x^{(0)})-H_q(x^{(t-1)}|x^{(0)})\\right) -H_p (x^{T})\\\\\n&amp;= \\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0\\cdots T)}q(x^{(0\\cdots T)})\n\\ln\\left( \\frac{p(x^{(t-1)}|x^{(t)})}{q(x^{(t-1)}|x^{(t)},\nx^{(0)})}\\right)+  H_q(x^{(T)}|x^{(0)})-H_q(x^{(1)}|x^{(0)})-H_p\n(x^{T})\\\\\n&amp;= -\\sum_{t=2}^{T} \\int \\mathrm{d}x^{(0, t)}q(x^{(0, t)})\n\\text{D}_{KL}\\left( {q(x^{(t-1)}|x^{(t)},\nx^{(0)})}||{p(x^{(t-1)}|x^{(t)})}\n\\right)+  H_q(x^{(T)}|x^{(0)})-H_q(x^{(1)}|x^{(0)})-H_p (x^{T})\\\\\n&amp;=K\n\\end{align}\n$$\n其中公式（16）定义Hp(xT) = −∫dx(T)q(x(T))ln π(x(T))；公式（20）因为这个过程是马尔科夫过程，只与前一个状态有关；公式（21）为贝叶斯公式。经过以上的变换，成功找到下界，任务目标变为:\np̂(x(t − 1)|x(t)) = argmaxp(x(t − 1)|x(t))K \n","categories":["Machine Learning"],"tags":["Nonequilibrium Thermodynamics","Unsupervised Learning"]},{"title":"Loss Functions for Discriminative Training of Energy-Based Models","url":"/2025/12/29/Phys/Energy_base_model/EBM/","content":"通过能量模型(Energy-based model,\nEBM)，将模型预测概率，转换为能量值。模型预测倾向于高概率结果，物体运动倾向于低能量区域，将高概率的预测映射到低能量区域，这样非常自然的将机器学习与物理相联系。\nReference: * Loss Functions for Discriminative Training of Energy-Based\nModels\n\n这种映射是非常重要的，将机器学习的问题天然的转移到物理框架中，从而可以借助之前的已有的物理工具分析信息流动的问题。很自然地会想到如下的一些问题：\n1. 这个映射过程是如何构建的？ 2. 映射限制是什么？适用于什么损失函数？ 3.\n这种映射的代价是什么？或者说局限性是什么？\nEnergy-Based Models\n经典的机器学习流程是通过输入数据X来预测其标签Y，表示为P(Y|X)，训练的目标是通过调整恰当的权重W以最大化P(YTrue|X)。在这个过程中设计三个关键的量W, Y, X，EBM将能量与关键量相关联构造E(W, X, Y)，预测结果表示为$Y=\\argmin_Y E(W,Y,X)$。\n通过构造函数E，将概率预测与能量极值相关联。可以发现，概率模型给出的是归一化之后的概率分布，EBM给出的结果是一个值，需要转化过程将EBM输出的值转化为概率分布：\n$$\\begin{align}\nP（Y|X,W）=\\frac{\\exp{(-\\beta E(W,Y,X))}}{\\int_y \\exp{(-\\beta\nE(W,y,X))}}.\n\\end{align}$$\n因为EBM形式与格点模型一致，这里直接采用波尔兹曼分布。由于采用了波尔兹曼分布，我们将面对积分∫yexp (−βE(W, y, X))即配分函数，因此这里必须限制可积性。\n通过以上两步，可以很顺畅的将监督学习损失函数直接改写为能量模型，之后分析各种性质与行为。例如对于MSE，可以定义E(W, Y, X) = ∑y, x(y − G(W, x))2，其中G为数据通过神经网络给出的结果。\n从这里来看映射是很直接的，限制条件只需要是有监督，并且可积分。\nExamples of EBMs\nEBM不局限于特定任务，在分类、回归和有约束的任务上上有广泛的应用。\n\n\n(a)分类任务，(b)回归任务，(c)约束任务\n\n对于分类任务，可以将模型根据不同的类别写出能量函数类型： $$ E(W,Y,X)=\\sum_i^k \\delta(Y-i)G(W,X),$$\n其中i表示类别，k是总类别数。\n对于回归任务，直接给出能量函数类型： $$\nE(W,Y,X)=\\frac{1}{2}||G(W,X)-Y||^2.$$\n对于约束任务，例如学习X2 + Y2 = 1，没有直接的映射关系，因此通过两个能量模型组合：\nE(W, Y, X) = C(Gx(Wx, X), Gy(Wy, Y)),\n其中C衡量差距。\nAppend\n也可以考虑在模型中加入隐变量Z，模型的形式改写为： $$\\begin{align}\nE(W,X,Y)=\\min_{z\\in {Z}}E(W,X,Y,Z).\n\\end{align}$$\n这里的隐变量可以表示一些模型的操作。以下是一个加入隐变量训练额过程：\n\n文章还有另一个问题值的讨论，什么是好的能量面？从能量的绝对值来看，分类正确的能量应该是最低的，同时不同类别最低的能量值之间应该有间隔(margin)；从能量的相对值看来，能量的梯度是决定网络能否寻找到最低的值关键因素，因此相对值变化需要平滑。\n","categories":["Machine Learning","Physics"],"tags":["Physics"]},{"title":"Machine-learning-assisted Monte Carlo fails at sampling computationally hard problems","url":"/2024/04/19/Phys/BoostMC_fail/BoostMC_fail/","content":"展示利用机器学习提升的MC在一些模型中的失败： *\n为什么说失败？哪些指标说明失败？ *\n在怎样的模型中？这种模型具有什么样的特点？ * 实验条件是什么？\n参考文献： * Machine-learning-assisted\nMonte Carlo fails at sampling computationally hard problems\n配套代码10.5281/zenodo.7567683 *\nNeural Annealing and\nVisualization of Autoregressive Neural Networks in the Newman–Moore\nModel * Glassy\ndynamics and aging in an exactly solvable spin model * Boundary\nconditions dependence of the phase transition in the quantum\nNewman-Moore mode * Visualizing the Loss Landscape\nof Neural Nets\n\nBackground\n经典MC的问题在于使用细致平衡条件进行局部更新，无法处理临界慢化、关联长度长问题；一些改进的措施是将局部更新改为全局更新，但是这种方案与模型的结构直接相关。\n最近利用机器学习诞生了一些高效的方案，通过近似分布P(σ)来获得目标分布，并且进行高效采样。\n现在面临的困境本质与90年代修改MC方案是一样的，两种都是在进行采样。在当时已经提出了一些benchmark对不同方案进行检验。但是现在机器学习策略大多聚焦于解决MC之前的困境，并没有测试之前的benchmark。\n接下来考虑一些难以采样的随机问题。\nFails at\nsampling computationally hard problems\n在采样问题中通常会遇到mode-collapse in learning the auxiliary\nmodel，这是由于在多峰分布情况下模型只学习到其中的一个峰分布。\n模型是否准确学到分布，作者提出了三个重要的判断指标： *\n其采样的接受概率是否足够高 $$\n  \\operatorname{Acc}\\left[\\sigma_{\\text {old }} \\rightarrow\n\\sigma_{\\text {new }}\\right]=\\min \\left[1,\n\\frac{\\mathrm{e}^{-(\\beta+\\delta \\beta) H\\left(\\sigma_{\\text {new\n}}\\right)} P_{\\mathrm{AR}}\\left(\\sigma_{\\text {old\n}}\\right)}{\\mathrm{e}^{-(\\beta+\\delta \\beta) H\\left(\\sigma_{\\text {old\n}}\\right) }P_{\\mathrm{AR}}\\left(\\sigma_{\\text {new }}\\right)}\\right]\n  $$ *\n全局MCMC动态初始化于由AR模型生成的配置接近静止状态（即，像能量这样的单时间数量在时间上是恒定的，而像相关性这样的双时间数量只依赖于时间差）。不一定吧？\n* 时间依赖的关联项消失。\n这个作者提出的benchmark主要针对VAN这种直接生成下一步分布的模型，但是如果模型只是估计分布概率，这个benchmark并不有效。\nColoring\n该模型本质就是随机图上的Potts Model。\n关于这个模型有一些参考资料：\n\nrandom\nfirst order transition universality class\nStatistical\nphysics of inference: thresholds and algorithms Adv. Phys\n\nThe hard-to-sample coloring problem: N个变量σi ∈ {0, …, q − 1}，每一个有q概率染色，节点位于Erdős-Rényi随机图𝒢上，每条边以相同的概率进行采样，连通概率为c。将模型的Hamiltonian 写为： $$\\begin{align}\nH(\\sigma)=\\sum_{\\langle i, j\\rangle \\in \\mathcal{G}} \\delta_{\\sigma_i,\n\\sigma_j}\n\\end{align}$$ 对于一个q态的Potts模型，这是一反铁磁模型，在这样的随机图的基态下如何选取使得能量最低，等价于随机图着色问题。\n\nTd线是玻璃相转变，在其之下关联时间随尺寸变大指数增加，Tk是凝聚线，在其之下不存在平坦的基态。其中小图表示在c = 40的情况，利用MCMC模拟不同体系尺寸的关联时间，横坐标为T − Td.关联函数为$C(t, \\tau)=\\frac{1}{N} \\sum_{i=1}^N\n\\delta_{\\sigma_i(t), \\sigma_i(t+\\tau)}$.\n\n\n模型实验结果，用于选取最好的模型进行下一步测试\n\n每幅图中两条水平的线表示MCMC采样的值（橙色），或者空腔采样的值（蓝色）。横坐标表示不同的模型。可以看到能量和熵在均值附近，考虑涨落影响是正常的。考虑到温度较高，不在基态也合理。接下来再看，随着模型的表现能力增强（网络复杂、regularization、dropout），能量下降熵也下降，作者认为这里发生这种因素的原因是过拟合（非常主观的猜测，但这个猜测却是文章的重要转折点）。接下来作者认为评判的参数维度是更低的能量于更高的熵，最好的模型是shallow\nMADE (ColoredMADE)。\n接下来将用表现最好的网络进行测试，演示其为什么失败。\n 其中 variational 和\nmaximum likelihood\n代表模型训练的两种方式，前者是wu等提出的方案，后者是基于前者方案加入极大似然估计（即进一步使用细致平衡挑选样本）。\na、b表明在高温下利用AR与传统算法没有区别高温本来关联就弱；在低温情况下利用AR系统转变的更快这个算法能解决关联问题，不是很好么？综上，AR失败的，因为不能在低温情况下采到能量更低的样本。以上讨论在T &gt; 0.3的情况下，更低传统方法也会失效。\n在d图中可以看出 maximum likelihood\n策略在低温情况下能量较高，温度升高逐渐接近MCMC采样值。从e图中能够发现，熵的值接近。但是从f图看熵-能量关系，可以立刻看出与传统方案的区别。\n从e图中看 variational\n方案，可以发现，熵在低温情况下很低，这是由于发生了mode-collapsed，模型聚集在其中的一个峰上。\n 其中the Boltzmann ratio\nPB(σnew\n)/PB(σold\n) and the model ratio PAR(σold\n)/PAR (σnew ).\n通过实验发现，接受率随着步数（与旧模型的相差程度）的增多，在剧烈下降，这意味着\nmaximum likelihood 方案在低温情况基本不能探索，能量无法下降。\n\n上图想要说明，因为在低温情况，传统采样关联性很强，而AR模型关联性下降很快，因此认为能量依旧很高。为什么不直接放能量图呢？我怀疑是因为AR模型在几个能量相近局域最小值之间跳，传统方法陷在一个局域最小值点中了。\nNeural\nAnnealing and Visualization in the Newman–Moore Model\nThe classical triangular plaquette model (TPM), introduced by Newman\nand Moore, also named Newman–Moore\nModel.\nThe classical triangular plaquette model\n是一个用于描述磁性系统中的自旋冰态（spin ice\nstate）的简化模型。在这个模型中，磁性离子位于三角形stop的顶点上，形成一个由三角形组成的格子（plaquette）。每个三角形代表一个“空位”，其中的磁性离子可以有向上或向下的磁矩。在自旋冰态中，由于几何限制和磁相互作用的特定规则，每个三角形内部的磁矩配置必须是两个向上，一个向下，或者两个向下，一个向上。这种配置被称为“two-in,\none-out”规则。\n这篇文章有一个问题，其使用了RNN进行训练。而且并没有说明该网络在非阻措问题上的表现能力。\n\n\n模型实验结果4\n\n在Newman–Moore\nModel上，可以观察到在小尺寸下符合的很好，但是随着晶格尺寸的变大，基态自由能突然发生改变（我更怀疑是由于计算失误），有一个突然的上升，这可能由于陷入到了一种局域解中。\n\n\n模型实验结果6\n\n除了变分自由能的最小值现在已接近T0 =\n10时的确切值。随着温度的降低，景观形状变得更加崎岖，出现了相当大的高能量平台和快速变化的障碍，最终导致局部最小值消失，退火结束时变成了完全混乱的景观。因此，从这个角度来看，很明显这里存在训练问题，阻碍了变分神经退火的成功应用。\n这篇文章需要更多的实验\nA\nmethod for quantifying the generalization capabilities of generative\nmodels for solving Ising models\n\nHamming\nDistance Metric Learning\n漫谈-Distance\nMetric Learning那些事儿\n\nHere we design a Hamming distance\n(一种用于衡量字符串之间差距的距离判定方法，将字符编码为二进制，通过记数差异位数，得到距离)\nregularizer in the framework of a class of generative models,\nvariational autoregressive networks (VANs), to quantify the\ngeneralization capabilities of various network architectures combined\nwith VAN.\n$$\\begin{align}\n\\mathcal{L}=&amp;F_q+R_h \\\\\nF_q=&amp;\\sum_{\\mathbf{s}}\nq_\\theta(\\mathbf{s})\\left[E(\\mathbf{s})+\\frac{1}{\\beta} \\ln\nq_\\theta(\\mathbf{s})\\right] \\\\\nR_h=&amp;\\sum_{\\mathbf{s}}\\left|h m_{\\mathbf{g}}(\\mathbf{s})-z\\right| \\\\\n\\nabla_\\theta \\mathcal{L}=&amp;\\mathbb{E}_{\\mathbf{s} \\sim\nq_\\theta(\\mathbf{s})}\\left\\{\\left[E(\\mathbf{s})+\\frac{1}{\\beta} \\ln\nq_\\theta(\\mathbf{s})\\right] \\nabla_\\theta \\ln\nq_\\theta(\\mathbf{s})\\right\\} \\\\\n\\end{align}$$ 其中hmg(s)衡量与基态的距离。\n最后一项目有问题，因为Rh采样方式是通过qθ。不过不会对训练产生影响，毕竟反向传播是准确的。\n\n\n模型实验结果6\n\n上图演示了收敛到正确基态的过程。\n该模型有效的原因就是因为加入了Hamming\ndistance，但是需要知道正确的基态，这个正确基态是这样来的： &gt; The\nprevious researches have illustrated that only by containing the\nconfigurations in the training datasets that are close to the ground\nstate, measured by Hamming distance, to train the neural networks, may\nwe obtain the ground state after training [4–7]. Therefore, we design\nthis regularizer to explore the relationship between the Hamming\ndistance and the success rates of finding the ground state for different\nnetwork architectures combined with VAN.\n不得不说，度量学习（distance metric\nlearning）是提升表现力的好手段。\nMessage\nPassing Variational Autoregressive Network for Solving Intractable Ising\nModels\n通过加入消息传递机制，提升了模型的表现能力。\n\n\n模型实验结果D_1\n\n上图基于Wishart planted\nensemble\n(WPE)模型，分别对比了不同算法在基态时候能量差分布图。说明文章中所提到的算法是有其优越性的。\n\n\n模型实验结果D_2\n\n消息传递层，主要增加了不同节点之间相互作用的耦合。文章同时还论证了为什么增加这样的网络结构能够降低能量、自由能，从而提升模型能力。\n文章中如何从(21)得到(18)，我觉得这里有问题。同样的对于(22)的论证同样存在问题，非凸函数qθ最外层加一个ln 并不会变成凸函数。\n\n\n模型实验结果D_6\n\n实验结果说明，在具有阻锉的结构下，文章所提到的方法确实能够得到更好的基态。\n这篇文章加入了消息传递层，使得最终能探索到更低的能量状态。消息传递的方案本身，是在处理具有弱阻锉情况下的模型自由能，而文章中用到的模型属于弱耦合的模型，是消息传递算法可以处理的。\nVariational Neural Annealing\n主要探讨在RNN的基础上，利用模拟退火方式采样，结合变分方式训练，最后在基态问题上的优秀表现。\n文章中采用的变分退火公式： Fλ(t) = ⟨Htarget\n⟩λ − T(t)Sclassical\n(pλ),\n\n从红色到蓝色代表了温度的下降，其中黄线是Boltamann\n分布，红线和绿线代表模拟和变分的结果，可见最后变分的结果更靠近真实分布\n\n\nVNA\n\n模拟退火算法在经典和量子状态下的演示图。\n接下来，文章展示了在random Ising chains、Edwards-Anderson\nmodel、SherringtonKirkpatrick (SK) model、Wishart planted ensemble\n(WPE)下的实验结果，均展示了该方案能够很好的探索到模型基态。\n  \n","categories":["Machine Learning"],"tags":["Physics"]},{"title":"Hopfield Model","url":"/2022/11/12/Phys/Hopfield/Hopfield/","content":"讨论Hopfield Model\n的相关内容，包含其本身的一些性值以及其在组合优化问题中的应用。\nReference: * Neural networks\nand physical systems with emergent collective computational\nabilities * “Neural”\nComputation of Decisions in Optimization Problems * 神经网络的统计力学 *\nNeural\nNetworks for Combinatorial Optimization: A Review of More Than a Decade\nof Research\nLink: * Hopfield 自由能求解\n\nHopfield Model\n\n由上图所示网络，格点s取分立的−1, +1两个值，任意两个格点之间都有连接权重为ω. 假定一种二进制的状态ξ，利用Hebbian rule设定权重ω为：\n$$\\begin{equation}\n\\begin{aligned}\n\\omega_{ij}&amp;=\\frac{1}{N}\\xi_i\\xi_j \\quad i\\neq j\\\\\n\\omega_{ii}&amp;=0\n\\end{aligned} \\label{omega}\n\\end{equation}\n$$\n其中N总格点数。这种状态ξ就是一个吸引子，是能量最低点（由于对称性，反号也是最低点）。也可以设定多个状态ξ，通过平均将其结合在一起：\n$$\\begin{align}\n\\omega_{ij}&amp;=\\frac{1}{N}\\sum_{l}^{P}\\xi_i^{(l)}\\xi_j^{(l)} \\quad\ni\\neq j\\\\\n\\omega_{ii}&amp;=0\n\\end{align}$$\n其中M吸引子的数量。\n如何从任意初始状态转变到吸引子的状态呢？接下来设计动力学过程：\n$$\\begin{align}\nS_i(t+1) \\leftarrow \\operatorname{sgn}\\left(\\sum_j w_{i j}\nS_j(t)-\\theta_i\\right)\n\\end{align}$$\n其中θi是一个偏置项。这个过程本质就是一个零温的蒙特卡洛模拟过程。\n\n\nlandscape\n\nHamiltonian写为： $$\\begin{equation}\nH=-\\frac{1}{2} \\sum_{i, j}^N w_{i j} S_i S_j \\label{hamiltonian}\n\\end{equation}$$\n接下来的讨论假设每一个模式都是完全随机选取的，即P(ξ = ±1) = 1/2。则是一个很强的设定。\n组合优化问题中的应用\n旅行商问题是给出一些地点，以及这些地点两两之间的距离，从一个点出发走完所有点，要求花费的路层最短。\n难点在于如何将旅行商问题转化为 hopfield\n形式。以五个城市ABCDE为例，将每一个城市由五位二进制编码，例如B对应01000、D对应00010。这样履行路径可以表示为： $$\n\\begin{array}{l|lllll}\n&amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\\\\n\\hline A &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\\nB &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\\nC &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\\nD &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\\nE &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\n\\end{array}\n$$\n一个由n个城市组成的问题，可以利用n2个节点组成的Hopfield网络表示。\n首先这样的表示有一些约束，约束的能量项表示为： $$\\begin{align}\nE_{c}=  A / 2 \\sum_X \\sum_i \\sum_{j \\neq i} V_{X i} V_{X j}+B / 2 \\sum_i\n\\sum_X \\sum_{X \\neq Y} V_{X i} V_{Y i}+C / 2\\left(\\sum_X \\sum_i V_{X\ni}-n\\right)^2\n\\end{align}$$ 其中VXi表示Hopfield网络中节点，代表城市X以旅行位置i。在这个能量项中，第一项约束在旅行中每次只能访问一个城市，第二项表示每个城市只能被访问一次，第三项表示每个城市都应该被访问一次。如果所有的约束条件都满足Ec = 0。\n用于计算路程的项写为：\n$$\\begin{align}\nE_l = \\frac{1}{2} D \\sum_X \\sum_{Y \\neq X} \\sum_i d_{X Y} V_{X\ni}\\left(V_{Y, i+1}+V_{Y, i-1}\\right)\n\\end{align}$$\n总能量项目为: $$\\begin{align}\nE=E_c+E_l\n\\end{align}$$\n至此已经将旅行商问题转化为Hopfield网络上，只需要迭代求解即可。此时的参数其实十分关键，并且作者对动力学更新方程有新的参数加入。\n这样就构建了一个桥梁，将组合优化问题转移到Spin\nGlass中，怎么更加清晰的分析这个问题就十分有趣了。\n\n\nTSP1\n\nHopfield 自由能求解\n","categories":["Physics"],"tags":["Spin Glass","Combinatorial Optimization Methods","Hopfield Model"]},{"title":"Hopfield 自由能求解","url":"/2022/11/14/Phys/Hopfield/Hopfield1/","content":"占位内容：本篇将整理 Hopfield\n模型的自由能推导与相关结论，稍后补充完整内容。\n","categories":["Physics"],"tags":["Spin Glass","Replica Method","Hopfield Model"]},{"title":"Hopfield Model","url":"/2022/11/14/Phys/Hopfield/Hopfield2/","content":"$$\\begin{align}\nF\\left(r_{\\rho \\sigma}, q_{\\rho \\sigma}, m_\\rho^1\\right)= &amp;\n-\\frac{\\alpha \\beta^2}{2} \\sum_{\\rho, \\sigma} r_{\\rho \\sigma} q_{\\rho\n\\sigma}-\\frac{\\alpha}{2} \\operatorname{Tr} \\ln [\\mathbf{I}-\\beta\n\\mathbf{Q}] -\\frac{\\beta}{2}\n\\sum_\\rho\\left(m_\\rho^1\\right)^2+\\left\\langle\\ln \\operatorname{Tr}\ne^{\\beta H_{\\xi^1}}\\right\\rangle_{\\xi^1} \\label{freeenergy1}\n\\end{align}$$\n$$\\begin{align}\nr_{\\rho \\sigma}&amp;=\\frac{1}{\\alpha} \\sum_{\\mu \\geq 2} m_\\rho^\\mu\nm_\\sigma^\\mu \\\\\nm_\\rho^\\mu&amp;=\\frac{1}{N} \\sum_i \\xi_i^\\mu S_i^\\rho \\\\\nq_{\\rho \\sigma}&amp;=\\frac{1}{N} \\sum_i S_i^\\rho S_i^\\sigma\n\\end{align}$$\n$$\\begin{align}\n\\langle\\ln Z\\rangle=\\lim _{n \\rightarrow 0} \\frac{\\ln \\left\\langle\nZ^n\\right\\rangle}{n}=\\lim _{n \\rightarrow 0} \\frac{\\ln e^{N\nF\\left(\\theta^*\\right)}}{n}=N \\lim _{n \\rightarrow 0}\n\\frac{F\\left(\\theta^*\\right)}{n} \\label{847}\n\\end{align}$$\nReplica-Symmetric Ansätz\n讨论到以上的情形，为了继续分析，需要对重叠矩阵做一个近似（考虑最简单的形式）：任意两个纯态应该是对称的。这被称为副本对称（RS）假设。\n$$\\begin{align}\n\\left\\{\\begin{array}{l}\nr_{\\rho \\sigma}=r, \\forall \\rho, \\sigma \\\\\nm_\\rho^1=m, \\forall \\rho \\\\\nq_{\\rho \\sigma}=q, \\forall \\rho \\neq \\sigma\n\\end{array} \\right.\n\\end{align}$$\n将$\\eqref{freeenergy1}$改写为：\n$$\n\\begin{aligned}\nF(r, q, m)= &amp; -\\frac{\\alpha \\beta^2}{2} r\nq\\left(n^2-n\\right)-\\frac{\\alpha \\beta^2}{2} n r-\\frac{\\alpha}{2}\n\\operatorname{Tr} \\ln [\\mathbf{I}-\\beta \\mathbf{Q}] \\\\\n&amp; -\\frac{\\beta}{2} n m^2+\\left\\langle\\ln \\operatorname{Tr} e^{\\beta\nH_{\\xi}}\\right\\rangle\n\\end{aligned}\n$$\n结合$\\eqref{847}$: $$\\begin{align}\n\\langle\\ln Z\\rangle= &amp; \\frac{N \\alpha \\beta^2 r q}{2}-\\frac{N \\alpha\n\\beta^2 r}{2}-\\frac{\\alpha N}{2} \\lim _{n \\rightarrow 0}\n\\frac{\\operatorname{Tr} \\ln [\\mathbf{I}-\\beta\n\\mathbf{Q}]}{n}-\\frac{\\beta N m^2}{2}+N \\lim _{n \\rightarrow 0}\n\\frac{\\left\\langle\\ln \\operatorname{Tr} e^{\\beta\nH_{\\xi^1}}\\right\\rangle}{n} \\label{zn3}\\\\\n\\beta H_{\\xi^1}=&amp;\\beta m \\xi^1 \\sum_\\rho S^\\rho+\\frac{1}{2} \\alpha\n\\beta^2 r \\sum_{\\rho, \\sigma} S^\\rho S^\\sigma\n\\end{align}$$\n首先计算$\\eqref{zn3}$中最后一项：\n$$\\begin{align}\n\\operatorname{Tr} e^{\\beta H_{\\xi} 1} &amp; =\\operatorname{Tr} e^{\\beta\nm \\xi^1 \\Sigma_\\rho S^\\rho+\\frac{1}{2} \\alpha \\beta^2 r\\left(\\sum_\\rho\nS^\\rho\\right)^2} \\\\\n&amp; :=\\operatorname{Tr} e^{A\\left(\\Sigma_\\rho S^\\rho\\right)^2+B\n\\Sigma_\\rho S^\\rho} \\\\\n&amp; =\\operatorname{Tr} \\sqrt{\\frac{A}{\\pi}} \\int d z e^{-A z^2+2 A z\n\\sum_\\rho S^\\rho+B \\Sigma_\\rho S^\\rho} \\\\\n&amp; =\\sqrt{\\frac{A}{\\pi}} \\int d z e^{-A z^2} \\operatorname{Tr}\n\\prod_\\rho e^{(2 A z+B) S^\\rho} \\\\\n&amp; =\\sqrt{\\frac{\\alpha \\beta^2 r}{2 \\pi}} \\int d z e^{-\\frac{1}{2}\n\\alpha \\beta^2 r z^2}\\left[2 \\cosh \\left(\\alpha \\beta^2 r z+\\beta m\n\\xi^1\\right)\\right]^n \\\\\n&amp; =\\sqrt{\\frac{\\alpha \\beta^2 r}{2 \\pi}} \\int d z e^{-\\frac{1}{2}\n\\alpha \\beta^2 r z^2+n \\ln \\left[2 \\cosh \\left(\\alpha \\beta^2 r z+\\beta\nm \\xi^1\\right)\\right]} \\\\\n&amp; =\\sqrt{\\frac{1}{2 \\pi}} \\int d z e^{-\\frac{1}{2} z^2+n \\ln \\left[2\n\\cosh \\left(\\beta \\sqrt{\\alpha r} z+\\beta m \\xi^1\\right)\\right]} .\n\\end{align}$$\n并且可知其极限为： $$\\begin{align}\n\\lim _{n \\rightarrow 0} \\operatorname{Tr} e^{\\beta H_{\\xi}\n1}=\\sqrt{\\frac{1}{2 \\pi}} \\int d z e^{-\\frac{1}{2} z^2}=1\n\\end{align}$$\n由此可获得最后一项为： $$\\begin{align}\n&amp; \\lim _{n \\rightarrow 0} \\frac{\\left\\langle\\ln \\operatorname{Tr}\ne^{\\beta H_{\\xi}}\\right\\rangle}{n} \\\\\n&amp; =\\left\\langle\\lim _{n \\rightarrow 0} \\frac{\\frac{d}{d n}\n\\operatorname{Tr} e^{\\beta H_{\\xi} 1}}{\\operatorname{Tr} e^{\\beta\nH_{\\xi} 1}}\\right\\rangle \\\\\n&amp; =\\left\\langle\\sqrt{\\frac{1}{2 \\pi}} \\lim _{n \\rightarrow 0}\n\\frac{d}{d n} \\int d z e^{-\\frac{1}{2} z^2+n \\ln \\left[2 \\cosh\n\\left(\\beta \\sqrt{a r} z+\\beta m \\xi^1\\right)\\right]}\\right\\rangle \\\\\n&amp; =\\left\\langle\\sqrt{\\frac{1}{2 \\pi}} \\lim _{n \\rightarrow 0} \\int d\nz e^{-\\frac{1}{2} z^2} \\frac{d}{d n}\\left[2 \\cosh \\left(\\beta\n\\sqrt{\\alpha r} z+\\beta m \\xi^1\\right)\\right]^n\\right\\rangle \\\\\n&amp; =\\left\\langle\\sqrt{\\frac{1}{2 \\pi}} \\lim _{n \\rightarrow 0} \\int d\nz e^{-\\frac{1}{2} z^2}\\left[2 \\cosh \\left(\\beta \\sqrt{\\alpha r} z+\\beta\nm \\xi^1\\right)\\right]^n \\ln \\left[2 \\cosh \\left(\\beta \\sqrt{\\alpha r}\nz+\\beta m \\xi^1\\right)\\right]\\right\\rangle \\\\\n&amp; =\\left\\langle\\sqrt{\\frac{1}{2 \\pi}} \\int d z e^{-\\frac{1}{2} z^2}\n\\lim _{n \\rightarrow 0}\\left[2 \\cosh \\left(\\beta \\sqrt{\\alpha r} z+\\beta\nm \\xi^1\\right)\\right]^n \\ln \\left[2 \\cosh \\left(\\beta \\sqrt{\\alpha r}\nz+\\beta m \\xi^1\\right)\\right]\\right\\rangle \\\\\n&amp; =\\left\\langle\\sqrt{\\frac{1}{2 \\pi}} \\int d z e^{-\\frac{1}{2} z^2}\n\\ln \\left[2 \\cosh \\left(\\beta \\sqrt{\\alpha r} z+\\beta m\n\\xi^1\\right)\\right]\\right\\rangle \\\\\n&amp; =\\int D z\\left\\langle\\ln \\left[2 \\cosh \\left(\\beta \\sqrt{\\alpha r}\nz+\\beta m \\xi^1\\right)\\right]\\right\\rangle\n\\end{align}$$\n此时用Dz表示对z的高斯积分。\n然后计算$\\eqref{zn3}$中第三项。由于Q是对称矩阵，将其对角化：\n$$\\begin{align}\n\\mathbf{A Q A}^{-1}=\\Lambda=\\operatorname{diag}\\left(\\lambda_1,\n\\lambda_2, \\ldots, \\lambda_n\\right)\n\\end{align}$$\n将ln [I − βQ]进行指数展开$\\ln (1-x)=-\\sum_{n=1}^{\\infty}\n\\frac{x^n}{n}$，得到： $$\\begin{align}\n\\operatorname{Tr} \\ln [\\mathbf{I}-\\beta \\mathbf{Q}] &amp;\n=\\operatorname{Tr}\\left\\{\\mathbf{A} \\cdot \\ln [\\mathbf{I}-\\beta\n\\mathbf{Q}] \\cdot \\mathbf{A}^{-1}\\right\\} \\\\\n&amp; =-\\operatorname{Tr}\\left\\{\\sum_{l=1}^{\\infty}\n\\frac{\\beta^l\\left(\\mathbf{A Q A}^{-1}\\right)^l}{l}\\right\\} \\\\\n&amp; =-\\operatorname{Tr}\\left\\{\\sum_{l=1}^{\\infty}\n\\frac{\\beta^l(\\Lambda)^l}{l}\\right\\} \\\\\n&amp; =-\\sum_{l=1}^{\\infty} \\frac{\\beta^l}{l} \\sum_{i=1}^n\n\\lambda_i^l=\\sum_{i=1}^n \\ln \\left[1-\\beta \\lambda_i\\right]\n\\end{align}$$\n再结合矩阵恒等式Tr ln K = ln det K，可以计算Q的本征值： $$\\begin{align}\n&amp; \\left|\\begin{array}{cccc}\n1-\\lambda &amp; q &amp; \\cdots &amp; q \\\\\nq &amp; 1-\\lambda &amp; \\cdots &amp; q \\\\\n\\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\\nq &amp; q &amp; \\cdots &amp; 1-\\lambda\n\\end{array}\\right| \\\\\n&amp; =\\left|\\begin{array}{cccc}\n1-\\lambda+(n-1) q &amp; 1-\\lambda+(n-1) q &amp; \\cdots &amp;\n1-\\lambda+(n-1) q \\\\\nq &amp; 1-\\lambda &amp; \\cdots &amp; q \\\\\n\\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\\nq &amp; q &amp; \\cdots &amp; 1-\\lambda\n\\end{array}\\right| \\\\\n&amp; =[1-\\lambda+(n-1) q]\\left|\\begin{array}{cccc}\n1 &amp; 1 &amp; \\cdots &amp; 1 \\\\\nq &amp; 1-\\lambda &amp; \\cdots &amp; q \\\\\n\\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\\nq &amp; q &amp; \\cdots &amp; 1-\\lambda\n\\end{array}\\right| \\\\\n&amp; =[1-\\lambda+(n-1) q]\\left|\\begin{array}{cccc}\n1 &amp; 1 &amp; \\cdots &amp; 1 \\\\\n0 &amp; 1-\\lambda-q &amp; 0 \\\\\n\\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\\n0 &amp; 0 &amp; \\cdots 1-\\lambda-q\n\\end{array}\\right| \\\\\n&amp; =[1-\\lambda+(n-1) q](1-q-\\lambda)^{n-1}=0\n\\end{align}$$\n可以得到1个本征值(1 + (n − 1)q)与n − 1个本征值(1 − q)，可以将迹写为： $$\\begin{align}\n\\operatorname{Tr} \\ln [\\mathbf{I}-\\beta \\mathbf{Q}]=\\ln (1-\\beta+\\beta\nq-n \\beta q)+(n-1) \\ln (1-\\beta+\\beta q)\n\\end{align}$$ 从而;\n$$\\begin{align}\n\\lim _{n \\rightarrow 0} \\frac{\\operatorname{Tr} \\ln [\\mathbf{I}-\\beta\n\\mathbf{Q}]}{n} &amp; =\\lim _{n \\rightarrow 0}\\left[\\frac{\\ln\n\\left(\\frac{1-\\beta+\\beta q-n \\beta q}{1-\\beta+\\beta q}\\right)}{n}+\\ln\n(1-\\beta+\\beta q)\\right] \\\\\n&amp; =-\\frac{\\beta q}{1-\\beta+\\beta q}+\\ln (1-\\beta+\\beta q)\n\\end{align}$$\n得到自由能为：\n$$\\begin{align}\n-\\beta f &amp; =\\frac{1}{N}\\langle\\ln Z\\rangle \\\\\n&amp; =\\frac{\\alpha \\beta^2}{2} r(q-1)-\\frac{\\alpha}{2}\\left[\\ln\n(1-\\beta+\\beta q)-\\frac{\\beta q}{1-\\beta+\\beta q}\\right]-\\frac{\\beta}{2}\nm^2 +\\int D z\\left\\langle\\ln \\left[2 \\cosh \\left(\\beta \\sqrt{\\alpha r}\nz+\\beta m \\xi^1\\right)\\right]\\right\\rangle\n\\end{align}$$\n求解其极值： $$\\begin{align}\n\\left\\{\\begin{array}{l}\n\\frac{\\partial(-\\beta f)}{\\partial r}=0 \\\\\n\\frac{\\partial(-\\beta f)}{\\partial m}=0 \\\\\n\\frac{\\partial(-\\beta f)}{\\partial q}=0\n\\end{array}\\right.\n\\end{align}$$\n$$\\begin{align}\nq= &amp; -\\frac{1}{\\beta \\sqrt{2 \\pi \\alpha r}} \\int d z e^{-\\frac{1}{2}\nz^2} z\\left\\langle\\tanh \\left(\\beta \\sqrt{\\alpha r} z+\\beta m\n\\xi^1\\right)\\right\\rangle+1 \\\\\n= &amp; \\frac{1}{\\beta \\sqrt{2 \\pi \\alpha r}} \\int d z \\frac{d\ne^{-\\frac{1}{2} z^2}}{d z}\\left\\langle\\tanh \\left(\\beta \\sqrt{\\alpha r}\nz+\\beta m \\xi^1\\right)\\right\\rangle+1 \\\\\n= &amp; \\left.\\frac{1}{\\beta \\sqrt{2 \\pi \\alpha r}} e^{-\\frac{1}{2}\nz^2}\\left\\langle\\tanh \\left(\\beta \\sqrt{\\alpha r} z+\\beta m\n\\xi^1\\right)\\right\\rangle\\right|_{-\\infty} ^{+\\infty} -\\int D\nz\\left\\langle 1-\\tanh ^2\\left(\\beta \\sqrt{\\alpha r} z+\\beta m\n\\xi^1\\right)\\right\\rangle+1 \\\\\n= &amp; \\int D z\\left\\langle\\tanh ^2\\left(\\beta \\sqrt{\\alpha r} z+\\beta\nm \\xi^1\\right)\\right\\rangle \\\\\n= &amp; \\int D z \\tanh ^2 \\beta(\\sqrt{\\alpha r} z+m)\n\\end{align}$$\n可以得到联想记忆模型的鞍点方程： $$\\begin{align}\n&amp; q=\\int D z \\tanh ^2 \\beta(\\sqrt{\\alpha r} z+m) \\label{860} \\\\\n&amp; m=\\int D z\\langle\\xi \\tanh \\beta(\\sqrt{\\alpha r} z+m\n\\xi)\\rangle=\\int D z \\tanh \\beta(\\sqrt{\\alpha r} z+m) \\label{861} \\\\\n&amp; r=\\frac{q}{(1-\\beta+\\beta q)^2} \\label{862}\\\\\n\\end{align}$$\n可以从以上的内容分析相变点。\nZero-Temperature Limit\n当T → 0(β → ∞)时候，有：\n$$\\tanh (\\beta x) \\rightarrow\n\\operatorname{sign}(x)=\\left\\{ \\begin{array}{ll}\n1 &amp; x&gt;0 \\\\\n0 &amp; x=0 \\\\\n-1 &amp; x&lt;0\n\\end{array} \\right.$$\n$\\eqref{861}$为：\n$$\\begin{align}\nm&amp;=\\int D z\\operatorname{sign}(\\sqrt{\\alpha r} z+m)+O(T) \\\\\n&amp; =\\operatorname{erf}\\left( \\frac{m}{\\sqrt{2 \\alpha r}} \\right)+O(T)\n\\end{align}$$\n上面这个变换利用正态分布与误差函数之间的关系完成。\n另一方面，当β → ∞：\n$$\\begin{align}\n1-q &amp; =\\int \\frac{d z}{\\sqrt{2 \\pi}} e^{-\\frac{z^2}{2}}\\left(1-\\tanh\n^2 \\beta(\\sqrt{\\alpha r} z+m)\\right) \\\\\n&amp; \\left.\\simeq \\frac{1}{\\sqrt{2 \\pi}}\ne^{-\\frac{z^2}{2}}\\right|_{\\tanh ^2 \\beta(\\sqrt{\\alpha r} z+m)=0} \\int d\nz\\left(1-\\tanh ^2 \\beta(\\sqrt{\\alpha r} z+m)\\right) \\\\\n&amp; =\\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{m^2}{2 \\alpha r}} \\frac{1}{\\beta\n\\sqrt{\\alpha r}} \\int d z \\frac{\\partial}{\\partial z} \\tanh\n\\beta(\\sqrt{\\alpha r} z+m) \\\\\n&amp; =\\frac{2}{\\sqrt{2 \\pi}} \\frac{1}{\\beta \\sqrt{\\alpha r}}\ne^{-\\frac{m^2}{2 \\alpha r}}\n\\end{align}$$\n$\\eqref{860}$产生q = 1 − CT，其中\n$$\\begin{align}\nC \\stackrel{\\text { def }}{=} \\sqrt{\\frac{2}{\\pi r \\alpha}}\ne^{-\\frac{m^2}{2 \\alpha r}}\n\\end{align}$$ 将$\\eqref{862}$变为r = (1 − C)−2。\n通过定义辅助变量$y=m / \\sqrt{2 \\alpha\nr}$将m 和 r 减少为一个方程： $$\\begin{align}\n\\operatorname{erf}(y)=y\\left(\\sqrt{2 \\alpha}+\\frac{2}{\\sqrt{\\pi}}\ne^{-y^2}\\right) .\n\\end{align}$$\n\n\nequation\n\n其中的一个恒定解为y = m = 0。对于α ≥ αc = 0.138只有为0的唯一解；当a &lt; αc时,m ≠ 0的解出现；当α = αc时，m = 0.967。\n\n\nerror probability\n\n通过求解m = erf (y)可以得到m的值。图中纵坐标表示误差$P_{\\text{error}}=\\frac{1-m}{2}$，横坐标表述存储的比例。可以发现，在图中存在一个跃变的点，当α——c = 0.138的时候，误差跳至0.5，这是一个不连续的转变，此时代表跳转至玻璃相；当α &lt; αc时，误差很小，表示此时网络可以从之前学习的模式中“恢复”；当α &gt; αc时，误差为0.5，为瞎猜的几率，可以认为此时网络不能恢复之前学习的模式。\nHopfield 相图\nAppend\n高斯积分和误差函数之间的关系\n高斯函数（Gaussian\nfunction）与误差函数（erf）之间的关系主要通过正态分布的累积分布函数（CDF）来体现。为了详细说明这一点，我们从标准正态分布及其累积分布函数出发。\n标准正态分布\n标准正态分布的概率密度函数（PDF）定义为：\n$$f(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2 /\n2}$$\n标准正态分布的累积分布函数\n累积分布函数（CDF）是从负无穷到某个值 x\n的概率密度函数的积分。对于标准正态分布，CDF 通常记作 Φ(x)：\n$$\\Phi(x) = \\int_{-\\infty}^x\n\\frac{1}{\\sqrt{2\\pi}} e^{-t^2 / 2} \\, dt$$\n误差函数的定义\n误差函数（erf）定义为：\n$$\\text{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\n\\int_0^x e^{-t^2} \\, dt$$\n高斯函数与误差函数的关系\n我们可以通过一些变换将标准正态分布的 CDF\n表示为误差函数。首先，考虑累积分布函数从负无穷大积分到某个值 x：\n$$\\Phi(x) = \\int_{-\\infty}^x\n\\frac{1}{\\sqrt{2\\pi}} e^{-t^2 / 2} \\, dt$$\n通过代换 $u =\n\\frac{t}{\\sqrt{2}}$，我们得到：\n$$du = \\frac{dt}{\\sqrt{2}} \\quad\n\\Rightarrow \\quad dt = \\sqrt{2} \\, du$$\n因此，积分变为：\n$$\\Phi(x) = \\int_{-\\infty}^{x}\n\\frac{1}{\\sqrt{2\\pi}} e^{-t^2 / 2} \\, dt = \\int_{-\\infty}^{x/\\sqrt{2}}\n\\frac{1}{\\sqrt{2\\pi}} e^{-2u^2 / 2} \\cdot \\sqrt{2} \\, du$$\n简化后，我们得到：\n$$\\Phi(x) = \\frac{1}{2} \\left(1 +\n\\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)$$\n因此，标准正态分布的累积分布函数与误差函数之间的关系为：\n$$\\Phi(x) = \\frac{1}{2} \\left(1 +\n\\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)$$\n逆误差函数\n误差函数的反函数（逆误差函数）是一个重要工具，用于将累积分布函数反转：\n$$x = \\sqrt{2} \\, \\text{erf}^{-1}(2\\Phi(x)\n- 1)$$\n示例\n假设我们想计算标准正态分布 𝒩(0, 1)\n的某个值 x\n的累积分布函数。使用 Python，我们可以如下计算：\nimport scipy.special as spx = 1.0Phi_x = 0.5 * (1 + sp.erf(x / np.sqrt(2)))print(Phi_x)\n这个示例计算了 x = 1\n时的累积分布函数值。\n总结\n高斯函数（正态分布）与误差函数之间的关系通过正态分布的累积分布函数（CDF）体现。正态分布的累积分布函数可以表示为误差函数的形式：\n$$\\Phi(x) = \\frac{1}{2} \\left(1 +\n\\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)$$\n这使得误差函数成为研究正态分布及其相关问题的一个重要工具。\n","categories":["Physics"],"tags":["Spin Glass","Replica Method","Hopfield Model"]},{"title":"Hopfield Model 相图","url":"/2022/11/15/Phys/Hopfield/Hopfield3/","content":"Phase Diagram\n根据“Hopfield 自由能”中的讨论，可知：\n$$\\begin{align}\n&amp; q=\\int D z \\tanh ^2 \\beta(\\sqrt{\\alpha r} z+m) \\label{860} \\\\\n&amp; m=\\int D z\\langle\\xi \\tanh \\beta(\\sqrt{\\alpha r} z+m\n\\xi)\\rangle=\\int D z \\tanh \\beta(\\sqrt{\\alpha r} z+m) \\label{861} \\\\\n&amp; r=\\frac{q}{(1-\\beta+\\beta q)^2} \\label{862}\\\\\n\\end{align}$$\n通过数值求解 $\\eqref{860},\\eqref{861},\\eqref{862}$\n可以得到Hopfield的相图：\n\n\ndiagram\n\n在高温的情况下，热噪音阻碍了模式恢复的过程，因此m = 0, q = 0, r = 0；当温度下降，参数开始在临界线Tg不稳定，可以通过$\\eqref{860}$分析得到；随着温度继续下降，Spin\nGlass相变成亚稳定态，相变线TM，恢复的模式是局域稳定的，这个相变是一阶相变。当记忆率下降，转变为稳定的态，对应相变线为Tc。\n在温度T = 0的时候，每个自旋的平均熵值为$S=-\\left.\\frac{\\partial f}{\\partial T}\\right|_{T\n\\rightarrow 0}=-\\frac{1}{2} \\alpha[\\ln (1-C)+C\n/(1-C)]$，其中C = β(1 − q)，可知自旋平均值是负数，这是非物理的。\nHopfield Model\nwith Arbitrary Hebbian Length\nHebbian learning\n是一种学习算法和理论，用于解释神经网络中的突触可塑性。其核心思想可以用一句话概括，即“同步触发的神经元会连线在一起”（“Cells\nthat fire together, wire together”）。这个概念最早由加拿大心理学家Donald\nHebb在1949年提出，故称为Hebbian学习。\n具体来说，Hebbian学习的基本原则如下：\n\n联结权重的更新：如果一个神经元A经常且重复地激活神经元B，那么神经元A和神经元B之间的突触连接会变得更强。这意味着两个神经元之间的联结权重会增加。\n时间一致性：为了使联结权重增加，神经元A的发火必须在神经元B的发火之前或同时发生。这种时间上的一致性被认为是形成记忆和学习的基础。\n局部性：Hebbian学习是一种局部学习规则，即每个突触的权重更新只依赖于连接的两个神经元的活动，而不依赖于整个网络的状态。\n\n在数学上，Hebbian学习规则可以表示为：\n$$\\begin{align}\n\\Delta w_{ij} = \\eta x_i y_j\n\\end{align}$$\n其中，Δwij\n表示神经元 i 和神经元 j 之间的突触权重变化，η 是学习率，xi 和 yj 分别是神经元\ni 和神经元 j 的激活状态。\nHebbian学习在神经科学和人工神经网络领域都有重要影响，特别是在理解神经网络如何通过经验和环境进行学习和调整方面。\nHebbian strength\n指的是神经元之间突触连接的强度，定义如下的神经元权重：\n$$\\begin{align}\nJ_{i j}=\\frac{1}{N} \\sum_{\\mu=1}^P\\left[c \\xi_i^\\mu \\xi_j^\\mu+\\gamma\n\\sum_{r=1}^d\\left(\\xi_i^\\mu \\xi_j^{\\mu+r}+\\xi_i^{\\mu+r}\n\\xi_j^\\mu\\right)\\right]\n\\end{align}$$\n其中c是标准Hebbian\nstrength；γ是不同记忆模式之间的强度；d是模型的Hebbian\n长度，之前讨论的是d = 1的情形，只记忆其中一个模式，d = 0是标准的Hopfield Model。ξiμ是二值变量，例如$p\\left(\\xi_i^\\mu= \\pm 1\\right)=\\frac{1}{2}\n\\delta\\left(\\xi_i^\\mu+1\\right)+\\frac{1}{2}\n\\delta\\left(\\xi_i^\\mu-1\\right)$。讨论的是P与N的极限情形，$\\alpha=\\frac{P}{N}$是memory load。\nComputation of\nthe Disorder-Averaged Free Energy\n将J重新写为：\n$$\\begin{align}\n\\mathbf{J}&amp;=\\frac{1}{N} \\xi^{\\mathrm{T}} \\mathbf{X} \\xi \\\\\nX_{\\mu \\eta} &amp; =c \\delta_{\\mu \\eta}+\\gamma\n\\sum_{r=1}^d\\left(\\delta_{\\mu,(\\eta+r) \\bmod P}+\\delta_{\\mu,(\\eta-r)\n\\bmod P}\\right) \\\\\n&amp; =(c-\\gamma) \\delta_{\\mu \\eta}+\\gamma \\sum_{r=-d}^d\n\\delta_{\\mu,(\\eta+r) \\bmod P}\n\\end{align}$$\nX的第m个本征值为，解的思路： $$\\begin{align}\n\\lambda_m&amp;=\\sum_{k=0}^{P-1} X_{1(k+1)} e^{-2 \\pi i m k / P} \\\\\n&amp; =\\sum_{k=0}^{P-1} X_{1(k+1)} \\cos \\left(2 \\pi \\frac{m k}{P}\\right)\n\\\\\n&amp; =\\sum_{k=0}^{P-1}\\left[c \\delta_{0 k}+\\gamma\n\\sum_{r=1}^d\\left(\\delta_{0,(k+r) \\bmod P}+\\delta_{0,(k-r) \\bmod\nP)}\\right] \\cos \\left(2 \\pi \\frac{m k}{P}\\right)\\right. \\\\\n&amp; =c+\\gamma \\sum_{r=1}^d\\left[\\cos \\left(-2 \\pi \\frac{m\nr}{P}\\right)+\\cos \\left(2 \\pi \\frac{m r}{P}\\right)\\right] \\\\\n&amp; =c+2 \\gamma \\sum_{r=1}^d \\cos \\left(2 \\pi \\frac{m r}{P}\\right)\n\\end{align}$$ 其中m = 0, 1, …, P − 1。\nHamiltonian和配分函数为： $$\\begin{align}\n\\mathcal{H}(\\mathbf{s})&amp;=-\\frac{1}{2} \\sum_{i \\neq j} J_{i j} s_i\ns_j \\\\\nZ&amp;=\\operatorname{Tr} \\exp \\left[\\frac{\\beta}{2 N}\n\\mathbf{s}^{\\mathrm{T}} \\boldsymbol{\\xi}^{\\mathrm{T}} \\mathbf{X}\n\\boldsymbol{\\xi} \\mathbf{s}\\right]\n\\end{align}$$\n其中 Tr 表示对分立 s 的求和。使用复本技巧：\n$$\\begin{align}\n\\langle\\ln Z\\rangle=\\lim _{n \\rightarrow 0} \\frac{\\ln \\left\\langle\nZ^n\\right\\rangle}{n},\n\\end{align}$$ 其中⟨⋅⟩表示对ξ的求和。因此有： $$\\begin{align}\nZ^n=\\operatorname{Tr} \\exp \\left[\\frac{\\beta}{2 N}\n\\sum_{a=1}^n\\left(\\mathbf{s}^a\\right)^{\\mathrm{T}}\n\\boldsymbol{\\xi}^{\\mathrm{T}} \\mathbf{X} \\boldsymbol{\\xi}\n\\mathbf{s}^a\\right] .\n\\end{align}$$\n考虑S个凝聚（foreground）模式P − S个非凝聚（background）模式。这里这两个模式的类别，表示什么含义？每次恢复的模式不应该只有一个么？根据以上定义，可以将X分为： $$\\begin{align}\n\\mathbf{X}=\\left[\\begin{array}{ll}\n\\mathbf{X}_{F F} &amp; \\mathbf{X}_{F B} \\\\\n\\mathbf{X}_{B F} &amp; \\mathbf{X}_{B B}\n\\end{array}\\right]\n\\end{align}$$ 其中 XFF ∈ ℝS × S, XBFT = XFB ∈ ℝS × (P − S)\nand XBB ∈ ℝ(P − S) × (P − S)。\n将XBB\n对角化 XBBμν = ∑σλσημσηνσ，其中\nλσ 与\nημσ\n是本征值与本征态。\n使用Hubbard-Stratonovich transformation：$\\exp \\left[\\frac{1}{2} b^2\\right]=$ ∫Dxexp [±bx],\n其中 $D x=\\frac{1}{\\sqrt{2 \\pi}} \\exp\n\\left(-\\frac{x^2}{2}\\right) d x$，因此有： $$\n\\begin{align}\nZ^n=&amp;\\operatorname{Tr} \\exp \\left[ \\frac{\\beta}{2 N} \\sum_{a, i, j,\n\\mu \\in B, v \\in B} s_i^a \\xi_i^\\mu X_{\\mu \\nu} \\xi_j^v\ns_j^a+\\frac{\\beta}{N} \\sum_{a, i, j, \\mu \\in B, v \\in F} s_i^a \\xi_i^\\mu\nX_{\\mu \\nu} \\xi_j^v s_j^a  +\\frac{\\beta}{2 N} \\sum_{a, i, j, \\mu \\in F,\nv \\in F} s_i^a \\xi_i^\\mu X_{\\mu \\nu} \\xi_j^v s_j^a\\right] \\\\\n=&amp;\\operatorname{Tr} \\exp  {\\left[\\frac{\\beta}{2 N} \\sum_{a, \\sigma}\n\\lambda_\\sigma\\left(\\sum_{i, \\mu \\in B} s_i^a \\xi_i^\\mu\n\\eta_\\mu^\\sigma\\right)^2+\\frac{\\beta}{N} \\sum_{a, i, j, \\mu \\in B, v \\in\nF} s_i^a \\xi_i^\\mu X_{\\mu \\nu} \\xi_j^v s_j^a +\\frac{\\beta}{2 N} \\sum_{a,\ni, j, \\mu \\in F, v \\in F} s_i^a \\xi_i^\\mu X_{\\mu \\nu} \\xi_j^\\nu\ns_j^a\\right]} \\\\\n= &amp; \\operatorname{Tr} \\prod_{a, \\sigma} \\int D x_\\sigma^a \\exp\n\\left[\\sum_{i, \\mu \\in B} \\frac{\\xi_i^\\mu}{\\sqrt{N}}\\left(\\sum_{a,\n\\sigma} s_i^a \\eta_\\mu^\\sigma \\sqrt{\\beta \\lambda_\\sigma}\nx_\\sigma^a+\\frac{\\beta}{\\sqrt{N}} \\sum_{a, j, v \\in F} s_i^a X_{\\mu \\nu}\n\\xi_j^v s_j^a\\right)+\\frac{\\beta}{2 N} \\sum_{a, i, j, \\mu \\in F, v \\in\nF} s_i^a \\xi_i^\\mu X_{\\mu \\nu} \\xi_j^v s_j^a\\right]\n\\end{align}\n$$\n定义： $$\\begin{align}\n\\Phi_B=&amp;\\exp \\left[\\sum_{i, \\mu \\in B}\n\\frac{\\xi_i^\\mu}{\\sqrt{N}}\\left(\\sum_{a, \\sigma} s_i^a \\eta_\\mu^\\sigma\n\\sqrt{\\beta \\lambda_\\sigma} x_\\sigma^a+\\frac{\\beta}{\\sqrt{N}} \\sum_{a,\nj, v \\in F} s_i^a X_{\\mu \\nu} \\xi_j^v s_j^a\\right)\\right] \\\\\n\\Phi_F=&amp;\\exp \\left[\\frac{\\beta}{2 N} \\sum_{a, i, j, \\mu \\in F, v \\in\nF} s_i^a \\xi_i^\\mu X_{\\mu \\nu} \\xi_j^v s_j^a\\right]\n\\end{align}$$\n计算无序平均{ξiμ}，可以有：\n$$\\begin{align}\n\\left\\langle Z^n\\right\\rangle=\\left\\langle\\operatorname{Tr} \\prod_{a,\n\\sigma} \\int D x_\\sigma^a \\Phi_B \\Phi_F\\right\\rangle\n\\end{align}$$\n首先分析⟨ΦB⟩，结合两个序参量$q_{a b}=\\frac{1}{N} \\sum_i^N s_i^a s_i^b\n\\quad\\text{for}\\quad a \\neq b$ 和 $m_\\mu^a=\\frac{1}{N} \\sum_i \\xi_i^\\mu s_i^a$\n有： $$\\begin{aligned}\n\\left\\langle\\Phi_B\\right\\rangle=&amp;\\exp \\left\\{\\frac{1}{2 N} \\sum_{i,\n\\mu \\in B}\\left[\\sum_a s_i^a\\left(\\sum_\\sigma \\eta_\\mu^\\sigma\n\\sqrt{\\beta \\lambda_\\sigma} x_\\sigma^a+\\frac{\\beta}{\\sqrt{N}} \\sum_{j, v\n\\in F} X_{\\mu \\nu} \\xi_j^v s_j^a\\right)\\right]^2\\right\\} \\\\\n\\left\\langle\\Phi_B\\right\\rangle= &amp; \\int \\prod_{a \\neq b} \\frac{d\nq_{a b} d \\hat{q}_{a b}}{2 \\pi / N} \\prod_{a, \\mu \\in F} \\frac{d m_\\mu^a\nd \\hat{m}_\\mu^a}{2 \\pi / N} \\\\\n&amp; \\times \\exp \\left[-\\frac{1}{2} N \\sum_{a \\neq b} \\hat{q}_{a b}\nq_{a b}+\\frac{1}{2} \\sum_{a \\neq b} \\hat{q}_{a b} \\sum_i s_i^a s_i^b-N\n\\sum_{a, \\mu \\in F} m_\\mu^a \\hat{m}_\\mu^a+\\sum_{a, \\mu \\in F}\n\\hat{m}_\\mu^a \\sum_i \\xi_i^\\mu s_i^a\\right] \\\\\n&amp; \\times \\exp \\left[\\frac{1}{2} \\sum_{\\mu \\in B}\n\\sum_a\\left(\\sum_\\sigma \\eta_\\mu^\\sigma \\sqrt{\\beta \\lambda_\\sigma}\nx_\\sigma^a+\\beta \\sqrt{N} \\sum_{\\nu \\in F} X_{\\mu \\nu}\nm_v^a\\right)^2\\right] \\\\\n&amp; \\times \\exp \\left[\\frac{1}{2} \\sum_{\\mu \\in B} \\sum_{a \\neq b}\nq_{a b}\\left(\\sum_\\sigma \\eta_\\mu^\\sigma \\sqrt{\\beta \\lambda_\\sigma}\nx_\\sigma^a+\\beta \\sqrt{N} \\sum_{\\nu \\in F} X_{\\mu \\nu}\nm_v^a\\right)\\right. \\\\\n&amp; \\left.\\times\\left(\\sum_\\sigma \\eta_\\mu^\\sigma \\sqrt{\\beta\n\\lambda_\\sigma} x_\\sigma^b+\\beta \\sqrt{N} \\sum_{\\nu \\in F} X_{\\mu \\nu}\nm_v^b\\right)\\right]\n\\end{aligned}$$\n再结合δ函数傅里叶变换与复本对称的应用：\n$$\n\\begin{aligned}\n\\left\\langle\\Phi_B\\right\\rangle=&amp;\\int \\frac{d q d \\hat{q}}{(2 \\pi /\nN)^{n(n-1)}} \\frac{d m d \\hat{m}}{(2 \\pi / N)^{n S}}-N n \\sum_{\\mu \\in\nF} m_\\mu \\hat{m}_\\mu \\exp \\left[-\\frac{1}{2} N n(n-1) \\hat{q} q\n\\quad+\\frac{1}{2} \\hat{q} \\sum_{a \\neq b} \\sum_i s_i^a s_i^b+\\sum_{a,\n\\mu \\in F} \\hat{m}_\\mu \\sum_i \\xi_i^\\mu s_i^a\\right] \\exp \\left[\\frac {\n1 } { 2 } \\sum _ { \\mu \\in B } \\sum _ { a } \\left(\\sum_\\sigma\n\\eta_\\mu^\\sigma \\sqrt{\\beta \\lambda_\\sigma}\nx_\\sigma^a\\right.\\left.\\quad+\\beta \\sqrt{N} \\sum_{\\nu \\in F} X_{\\mu \\nu}\nm_v\\right)^2\\right] \\\\\n&amp;\\times \\exp \\left[\\frac{q}{2} \\sum_{\\mu \\in B} \\sum_{a \\neq\nb}\\left(\\sum_\\sigma \\eta_\\mu^\\sigma \\sqrt{\\beta \\lambda_\\sigma}\nx_\\sigma^a+\\beta \\sqrt{N} \\sum_{v \\in F} X_{\\mu \\nu} m_\\nu\\right)\n\\times\\left(\\sum_\\sigma \\eta_\\mu^\\sigma \\sqrt{\\beta \\lambda_\\sigma}\nx_\\sigma^b+\\beta \\sqrt{N} \\sum_{v \\in F} X_{\\mu \\nu} m_v\\right)\\right]\n\\\\\n=&amp;\\int \\frac{d q d \\hat{q}}{(2 \\pi / N)^{n(n-1)}} \\frac{d m d\n\\hat{m}}{(2 \\pi / N)^{n S}} \\exp \\left[-\\frac{1}{2} N n(n-1) \\hat{q}\nq+\\frac{1}{2} \\hat{q} \\sum_{a \\neq b} \\sum_i s_i^a s_i^b-N n \\sum_{\\mu\n\\in F} m_\\mu \\hat{m}_\\mu +\\sum_{a, \\mu \\in F} \\hat{m}_\\mu \\sum_i\n\\xi_i^\\mu s_i^a\\right] \\\\\n&amp;\\times \\exp \\left[\\frac{1-q}{2} \\sum_{\\mu \\in B}\n\\sum_a\\left(\\sum_\\sigma \\eta_\\mu^\\sigma \\sqrt{\\beta \\lambda_\\sigma}\nx_\\sigma^a+\\beta \\sqrt{N} \\sum_{\\nu \\in F} X_{\\mu \\nu}\nm_v\\right)^2\\right] \\\\\n&amp; \\times \\exp \\left[\\frac{q}{2} \\sum_{\\mu \\in B}\\left(\\sum_{a,\n\\sigma} \\eta_\\mu^\\sigma \\sqrt{\\beta \\lambda_\\sigma} x_\\sigma^a+\\beta n\n\\sqrt{N} \\sum_{\\nu \\in F} X_{\\mu \\nu} m_\\nu\\right)^2\\right] \\\\\n= &amp; \\int \\frac{d q d \\hat{q}}{(2 \\pi / N)^{n(n-1)}} \\frac{d m d\n\\hat{m}}{(2 \\pi / N)^{n S}} \\prod_{\\mu, a} D y_\\mu^a \\prod_\\mu D z_\\mu\n\\\\\n&amp; \\times \\exp \\left[-\\frac{1}{2} N n(n-1) \\hat{q} q+\\frac{1}{2}\n\\hat{q} \\sum_{a \\neq b} \\sum_i s_i^a s_i^b-N n \\sum_{\\mu \\in F} m_\\mu\n\\hat{m}_\\mu+\\sum_{a, \\mu \\in F} \\hat{m}_\\mu \\sum_i \\xi_i^\\mu\ns_i^a\\right] \\\\\n&amp; \\times \\exp \\left[\\sqrt{1-q} \\sum_{\\mu \\in B}\n\\sum_a\\left(\\sum_\\sigma \\eta_\\mu^\\sigma \\sqrt{\\beta \\lambda_\\sigma}\nx_\\sigma^a+\\beta \\sqrt{N} \\sum_{\\nu \\in F} X_{\\mu \\nu} m_\\nu\\right)\ny_\\mu^a\\right] \\\\\n&amp; \\times \\exp \\left[\\sqrt{q} \\sum_{\\mu \\in B}\\left(\\sum_{a, \\sigma}\n\\eta_\\mu^\\sigma \\sqrt{\\beta \\lambda_\\sigma} x_\\sigma^a+\\beta n \\sqrt{N}\n\\sum_{\\nu \\in F} X_{\\mu \\nu} m_\\nu\\right) z_\\mu\\right] \\\\\n= &amp; \\int \\frac{d q d \\hat{q}}{(2 \\pi / N)^{n(n-1)}} \\frac{d m d\n\\hat{m}}{(2 \\pi / N)^{n S}} \\prod_{\\mu, a} D y_\\mu^a \\prod_\\mu D z_\\mu\n\\\\\n&amp; \\times \\exp \\left[-\\frac{1}{2} N n(n-1) \\hat{q} q+\\frac{1}{2}\n\\hat{q} \\sum_{a \\neq b} \\sum_i s_i^a s_i^b-N n \\sum_{\\mu \\in F} m_\\mu\n\\hat{m}_\\mu+\\sum_{a, \\mu \\in F} \\hat{m}_\\mu \\sum_i \\xi_i^\\mu\ns_i^a\\right] \\\\\n&amp; \\times \\exp \\left[\\sum_{a, \\sigma} x_\\sigma^a \\sqrt{\\beta\n\\lambda_\\sigma} \\sum_{\\mu \\in B} \\eta_\\mu^\\sigma\\left(\\sqrt{1-q}\ny_\\mu^a+\\sqrt{q} z_\\mu\\right)\\right] \\\\\n&amp; \\times \\exp \\left[\\beta \\sqrt{N} \\sum_{a, \\mu \\in B} \\sum_{v \\in\nF} X_{\\mu \\nu} m_\\nu\\left(\\sqrt{1-q} y_\\mu^a+\\sqrt{q}\nz_\\mu\\right)\\right]\n\\end{aligned}\n$$\n参考原书\n","categories":["Physics"],"tags":["Spin Glass","Replica Method","Hopfield Model"]},{"title":"Sherrington-Kirkpatrick Model","url":"/2022/11/20/Phys/SK_model/SK_model/","content":"利用复本方法计算 Sherrington-Kirkpatrick（SK）\n模型。目的是掌握和熟悉复本方法的使用。\nReference: * Statistical Physics of Spin Glasses and Information\nProcessing. Nishimori * Replica\ncalculations for the SK model笔误有点多\nLink: * Hopfield Model * Replica * The Parisi solution of Sherrington-Kirkpatrick Model\n\nSherrington-Kirkpatrick\nModel\n$$\\begin{align}\nH=&amp;\\sum_{i&lt;j} J_{i j} S_i S_j-h \\sum_i S_i \\label{1}\\\\\nP\\left(J_{i j}\\right)=&amp;\\frac{1}{J} \\sqrt{\\frac{N}{2 \\pi}} \\exp\n\\left(-\\frac{N}{2 J^2}\\left(J_{i j}-\\frac{J_0}{N}\\right)^2\\right)\\\\\n\\end{align}$$\n$$\\begin{align}\n\\text{mean}(J)=&amp;\\frac{J_0}{N} \\\\\n\\text{variance}(J)=&amp;\\frac{J^2}{N}\n\\end{align}$$\n其中S, J都是变量。考虑是在quneched状态。热力学平均是指对S的平均，记为⟨⋅⟩；构型平均是对相互作用参数J的平均，记为[⋅]。自由能写为：\n$$\\begin{align}\n[F(\\boldsymbol{s})]=-\\frac{1}{\\beta}[\\ln\nZ(\\boldsymbol{s})]=-\\frac{1}{\\beta}\\left[\\ln \\sum_{\\{\\boldsymbol{s}\\}}\n\\exp (-\\beta H(\\boldsymbol{s}))\\right]\n\\end{align}$$\nCalculating the\nfree energy with replica method\n由复本对称知：\n$$\\begin{align}\n[\\ln Z(s)]=\\lim_{n\\to 0}\\frac{[Z^n]-1}{n}\\label{4}\n\\end{align}$$\n结合$\\eqref{1}$，[Zn]可写为：\n$$\\begin{align}\n\\left[Z^n\\right]=\\int \\prod_{i&lt;j} d J_{i j} P\\left(J_{i j}\\right)\n\\sum_{\\left\\{\\boldsymbol{s}^\\alpha, \\boldsymbol{s}^\\beta, \\ldots,\n\\boldsymbol{s}^n\\right\\}} \\exp \\left(-\\beta \\sum_{i&lt;j} J_{i j}\n\\sum_{\\alpha=1}^n S_i^\\alpha S_j^\\alpha+\\beta h \\sum_{i=1}^N\n\\sum_{\\alpha=1}^n S_i^\\alpha\\right)\n\\end{align}$$\n直接对J进行积分：\nP = 1/J Sqrt[NN/(2 Pi)] Exp[-NN/(2 j^2) (jij - j0/NN)^2];Integrate[  P Exp[1/NN (-\\[Beta] jij si sj + \\[Beta] h si)], &#123;jij, -Infinity,    Infinity&#125;] // FullSimplify\n$$\\begin{align}\n\\left[Z^n\\right]=C_1 \\sum_{\\left\\{\\boldsymbol{s}^\\alpha,\n\\boldsymbol{s}^\\beta, \\ldots, \\boldsymbol{s}^n\\right\\}} \\exp\n\\left\\{\\frac{1}{N} \\sum_{i&lt;j}\\left(\\frac{1}{2} \\beta^2 J^2\n\\sum_{\\alpha, \\beta} S_i^\\alpha S_j^\\alpha S_i^\\beta S_j^\\beta+\\beta J_0\n\\sum_\\alpha S_i^\\alpha S_j^\\alpha\\right)+\\beta h \\sum_{i=1}^N\n\\sum_{\\alpha=1}^n S_i^\\alpha\\right\\} .\n\\end{align}$$\n对其中一项进行拆分： $$\\begin{align}\n\\sum_{\\alpha, \\beta} S_i^\\alpha S_j^\\alpha S_i^\\beta S_j^\\beta=2\n\\sum_{\\alpha&lt;\\beta} S_i^\\alpha S_j^\\alpha S_i^\\beta\nS_j^\\beta+\\sum_\\alpha\\left(S_i^\\alpha S_j^\\alpha\\right)^2=2\n\\sum_{\\alpha&lt;\\beta} S_i^\\alpha S_j^\\alpha S_i^\\beta S_j^\\beta+n\n\\end{align}$$\n因此有：\n$$\\begin{align}\n{\\left[Z^n\\right] } &amp; =C_1 \\sum_{\\left\\{s^\\alpha, s^\\beta, \\ldots,\ns^n\\right\\}} \\exp \\left\\{\\frac{1}{N} \\sum_{i&lt;j}\\left(\\frac{1}{2}\n\\beta^2 J^2\\left(2 \\sum_{\\alpha&lt;\\beta} S_i^\\alpha S_j^\\alpha\nS_i^\\beta S_j^\\beta+n\\right)+\\beta J_0 \\sum_\\alpha S_i^\\alpha\nS_j^\\alpha\\right)+\\beta h \\sum_{i=1}^N \\sum_{\\alpha=1}^n\nS_i^\\alpha\\right\\} \\\\\n&amp; =C_1 \\sum_{\\left\\{s^\\alpha, s^\\beta, \\ldots, s^n\\right\\}} \\exp\n\\left\\{\\frac{1}{N} \\sum_{i&lt;j}\\left(\\frac{1}{2} \\beta^2 J^2\nn+\\frac{1}{2} \\beta^2 J^2\\left(2 \\sum_{\\alpha&lt;\\beta} S_i^\\alpha\nS_j^\\alpha S_i^\\beta S_j^\\beta\\right)+\\beta J_0 \\sum_\\alpha S_i^\\alpha\nS_j^\\alpha\\right)+\\beta h \\sum_{i=1}^N \\sum_{\\alpha=1}^n\nS_i^\\alpha\\right\\} \\\\\n&amp; =C_1 \\exp \\left(\\frac{(N-1) \\beta^2 J^2 n}{4}\\right)\n\\sum_{\\left\\{s^\\alpha, s^\\beta, \\ldots, s^n\\right\\}} \\exp\n\\left\\{\\frac{1}{N} \\sum_{i&lt;j}\\left(\\beta^2 J^2 \\sum_{\\alpha&lt;\\beta}\nS_i^\\alpha S_j^\\alpha S_i^\\beta S_j^\\beta+\\beta J_0 \\sum_\\alpha\nS_i^\\alpha S_j^\\alpha\\right)+\\beta h \\sum_{i=1}^N \\sum_{\\alpha=1}^n\nS_i^\\alpha\\right\\}\\label{9}\n\\end{align}$$\n采用近似$\\exp \\left(\\frac{(N-1) \\beta^2 J^2\nn}{4}\\right) \\approx\\exp \\left(\\frac{N \\beta^2 J^2\nn}{4}\\right)$，接下来关注$\\eqref{9}$第二项中第一部分：\n$$\\begin{align}\n\\frac{1}{N} \\sum_{i&lt;j} \\beta^2 J^2 \\sum_{\\alpha&lt;\\beta} S_i^\\alpha\nS_j^\\alpha S_i^\\beta S_j^\\beta &amp; =\\frac{\\beta^2 J^2}{2\nN}\\left(\\sum_{\\alpha&lt;\\beta}\\left(\\sum_i S_i^\\alpha\nS_i^\\beta\\right)^2-\\sum_i \\sum_{\\alpha&lt;\\beta} S_i^\\alpha S_i^\\alpha\nS_i^\\beta S_i^\\beta\\right) \\\\\n&amp; =\\frac{\\beta^2 J^2}{2 N} \\sum_{\\alpha&lt;\\beta}\\left(\\sum_i\nS_i^\\alpha S_i^\\beta\\right)^2-\\frac{\\beta^2 J^2}{2 N} \\sum_i\n\\sum_{\\alpha&lt;\\beta} 1 \\label{9_1}\n\\end{align}$$\n将常数项加入前面的系数，接下来分析$\\eqref{9}$第二项中第二部分：\n$$\\begin{align}\n\\frac{\\beta J_0}{N} \\sum_{i&lt;j} \\sum_\\alpha S_i^\\alpha\nS_j^\\alpha=\\frac{\\beta J_0}{2 N} \\sum_\\alpha\\left(\\sum_i\nS_i^\\alpha\\right)^2-\\frac{\\beta J_0}{2 N} \\sum_i \\sum_\\alpha 1\n\\label{9_2}\n\\end{align}$$\n同样处理常数项目，结合$\\eqref{9}\\eqref{9_1}\\eqref{9_2}$，得到：\n$$\\begin{align}\n\\left[Z^n\\right]=C_2 \\exp \\left(\\frac{N \\beta^2 J^2 n}{4}\\right)\n\\sum_{\\left\\{s^\\alpha, s^\\beta, \\ldots, s^n\\right\\}} \\exp\n\\left\\{\\frac{\\beta^2 J^2}{2 N} \\sum_{\\alpha&lt;\\beta}\\left(\\sum_i\nS_i^\\alpha S_i^\\beta\\right)^2+\\frac{\\beta J_0}{2 N}\n\\sum_\\alpha\\left(\\sum_i S_i^\\alpha\\right)^2+\\beta h \\sum_{i=1}^N\n\\sum_{\\alpha=1}^n S_i^\\alpha\\right\\} \\label{10}\n\\end{align}$$\n需要将$\\eqref{10}$指数中的平方项转变为线性，使用Hubbard-Stratonovich\n替换：\n$$\\begin{align}\n\\exp \\left(\\frac{y^2}{2}\\right)=\\int_{-\\infty}^{\\infty} \\frac{d\nx}{\\sqrt{2 \\pi}} \\exp \\left(-\\frac{x^2}{2}\\right) \\exp (x y)\\label{11}\n\\end{align}$$\n可得：\n$$\n\\begin{gather}\n\\exp \\frac{\\beta^2 J^2}{2 N}\\left(\\sum_i S_i^\\alpha\nS_i^\\beta\\right)^2=\\int_{-\\infty}^{\\infty} \\frac{N d q_{\\alpha\n\\beta}}{\\sqrt{2 \\pi}} \\exp \\left(-\\beta^2 J^2 N \\frac{q_{\\alpha\n\\beta}^2}{2}+\\beta^2 J^2 q_{\\alpha \\beta} \\sum_i S_i^\\alpha\nS_i^\\beta\\right) \\\\\n\\exp \\frac{\\beta J_0}{2 N}\\left(\\sum_i\nS_i^\\alpha\\right)^2=\\int_{-\\infty}^{\\infty} \\frac{N d m_\\alpha}{\\sqrt{2\n\\pi}} \\exp \\left(-\\beta J_0 N m_\\alpha^2+\\beta J_0 m_\\alpha \\sum_i\nS_i^\\alpha\\right)\n\\end{gather}\n$$\n再将结果代入$\\eqref{10}$，然后得到结果：\n$$\\begin{equation}\n\\begin{aligned}\n&amp; {\\left[Z^n\\right]=} C_4 \\exp \\left(\\frac{N \\beta^2 J^2\nn}{4}\\right) \\int_{-\\infty}^{\\infty} \\prod_{\\alpha&lt;\\beta} d q_{\\alpha\n\\beta} \\prod_\\alpha d m_\\alpha \\\\\n&amp; \\exp \\left(-\\frac{\\beta^2 J^2 N}{2} \\sum_{\\alpha&lt;\\beta}\nq_{\\alpha \\beta}^2-\\frac{\\beta J_0 N}{2} \\sum_\\alpha m_\\alpha^2\\right)\n\\\\\n&amp; \\sum_{\\left\\{s^\\alpha, s^\\beta, \\ldots, s^n\\right\\}} \\exp\n\\left(\\beta^2 J^2 \\sum_{\\alpha&lt;\\beta} q_{\\alpha \\beta} \\sum_i\nS_i^\\alpha S_i^\\beta+\\beta \\sum_\\alpha\\left(J_0 m_\\alpha+h\\right) \\sum_i\nS_i^\\alpha\\right)\n\\end{aligned} \\label{14}\n\\end{equation}$$\n对于$\\eqref{14}$最后一项，改写为：\n$$\n\\prod_{i=1}^N \\sum_{\\left\\{s_i^\\alpha, s_i^\\beta, \\ldots, s_i^n\\right)}\n\\exp \\left(\\beta^2 J^2 \\sum_{\\alpha&lt;\\beta} q_{\\alpha \\beta}\nS_i^\\alpha S_i^\\beta+\\beta \\sum_\\alpha\\left(J_0 m_\\alpha+h\\right)\nS_i^\\alpha\\right)\n$$\n由于对于任意i，有si = ±1，这样对于不同的i是没有差别的：\n$$\\begin{align}\n\\left\\{\\sum_{\\left\\{s_i^\\alpha, s_i^\\beta, \\ldots, s_i^n\\right)} \\exp\n\\left(\\beta^2 J^2 \\sum_{\\alpha&lt;\\beta} q_{\\alpha \\beta} S^\\alpha\nS^\\beta+\\beta \\sum_\\alpha\\left(J_0 m_\\alpha+h\\right)\nS^\\alpha\\right)\\right\\}^N \\equiv \\exp \\left\\{N \\log\n\\sum_{\\left\\{s_i^\\alpha, s_i^\\beta, \\ldots, s_i^n\\right)} \\exp\n\\left(L\\left(\\left\\{q_{\\alpha \\beta},\nm_\\alpha\\right\\}\\right)\\right)\\right\\} \\label{18}\n\\end{align}$$\n其中定义： $$\\begin{align}\nL\\left(\\left\\{q_{\\alpha \\beta}, m_\\alpha\\right\\}\\right):=\\beta^2 J^2\n\\sum_{\\alpha&lt;\\beta} q_{\\alpha \\beta} S^\\alpha S^\\beta+\\beta\n\\sum_\\alpha\\left(J_0 m_\\alpha+h\\right) S^\\alpha \\label{19}\n\\end{align}$$\n将$\\eqref{18}\\eqref{19}$代入$\\eqref{14}$：\n$$\\begin{equation}\n\\begin{aligned}\n\\left[Z^n\\right]=&amp; C_4 \\exp \\left(\\frac{N \\beta^2 J^2 n}{4}\\right)\n\\int_{-\\infty}^{\\infty} \\prod_{\\alpha&lt;\\beta} d q_{\\alpha \\beta}\n\\prod_\\alpha d m_\\alpha \\\\\n&amp; \\exp \\left\\{-\\frac{\\beta^2 J^2 N}{2} \\sum_{\\alpha&lt;\\beta}\nq_{\\alpha \\beta}^2-\\frac{\\beta J_0 N}{2} \\sum_\\alpha m_\\alpha^2+N \\log\n\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right)} \\exp (L)\\right\\}\n\\end{aligned} \\label{20}\n\\end{equation}$$\n由于热力学极限有N → ∞，采用Laplace近似可知（进行该近似其是会出现一个常数项，这里没有写出，因为直接扔掉也对结果没有影响），结果取决于与指数上最大值的那个点：\n$$\n\\begin{gather}\nE:=-\\frac{\\beta^2 J^2 N}{2} \\sum_{\\alpha&lt;\\beta} q_{\\alpha\n\\beta}^2-\\frac{\\beta J_0 N}{2} \\sum_\\alpha m_\\alpha^2+N \\log\n\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right\\}} \\exp (L)\n\\label{22}\\\\\n\\left\\{q_{\\alpha \\beta}^{\\star}, m_\\alpha^{\\star}\\right\\}=\\arg \\max\n_{\\left\\{q_{\\alpha \\beta}, m_\\alpha\\right\\}} E\n\\end{gather}\n$$\n因此$\\eqref{14}$转变为：\n$$\\begin{align}\n{\\left[Z^n\\right] } &amp; =C_4 \\exp \\left\\{\\frac{N \\beta^2 J^2\nn}{4}-\\frac{\\beta^2 J^2 N}{2} \\sum_{\\alpha&lt;\\beta}\\left(q_{\\alpha\n\\beta}^{\\star}\\right)^2-\\frac{\\beta J_0 N}{2}\n\\sum_\\alpha\\left(m_\\alpha^{\\star}\\right)^2+N \\log \\sum_{\\left\\{S^\\alpha,\nS^\\beta, \\ldots, S^n\\right\\}} \\exp (L)\\right\\} \\label{24}\\\\\n&amp; =C_4 \\exp \\left\\{N n\\left(\\frac{\\beta^2 J^2}{4}-\\frac{\\beta^2\nJ^2}{2 n} \\sum_{\\alpha&lt;\\beta}\\left(q_{\\alpha\n\\beta}^{\\star}\\right)^2-\\frac{\\beta J_0}{2 n}\n\\sum_\\alpha\\left(m_\\alpha^{\\star}\\right)^2+\\frac{1}{n} \\log\n\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right\\}} \\exp\n(L)\\right)\\right\\} \\label{25}\n\\end{align}$$\n在进行到$\\eqref{24}$时候已经黔宾黩武，从定义$\\eqref{19}$中可以看出L包含q, m。此时处理已经很麻烦了，需要近似。\n同时采用复本极限n → 0，将$\\eqref{25}$进行展开：\n$$\\begin{align}\n\\left[Z^n\\right] \\approx 1+N n\\left\\{\\frac{\\beta^2 J^2}{4}-\\frac{\\beta^2\nJ^2}{2 n} \\sum_{\\alpha&lt;\\beta}\\left(q_{\\alpha\n\\beta}^{\\star}\\right)^2-\\frac{\\beta J_0}{2 n}\n\\sum_\\alpha\\left(m_\\alpha^{\\star}\\right)^2+\\frac{1}{n} \\log\n\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right\\}} \\exp (L)\\right\\}\n\\label{26}\n\\end{align}$$\n最后将$\\eqref{26}$代回复本技巧$\\eqref{4}$中：\n$$\n\\begin{align}\n\\frac{[\\log Z]}{N} &amp; =\\lim _{n \\rightarrow 0}\n\\frac{\\left[Z^n\\right]-1}{N n} \\\\\n&amp; =\\lim _{n \\rightarrow 0}\\left\\{\\frac{\\beta^2 J^2}{4}-\\frac{\\beta^2\nJ^2}{2 n} \\sum_{\\alpha&lt;\\beta}\\left(q_{\\alpha\n\\beta}^{\\star}\\right)^2-\\frac{\\beta J_0}{2 n}\n\\sum_\\alpha\\left(m_\\alpha^{\\star}\\right)^2+\\frac{1}{n} \\log\n\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right\\}} \\exp (L)\\right\\}\n\\label{28}\n\\end{align}\n$$\n最后需要确定{qαβ⋆, mα⋆}的表达式，使用$\\frac{\\partial}{\\partial q_{\\alpha \\beta}}\nE=\\frac{\\partial}{\\partial m_\\alpha} E=0$，从$\\eqref{22}$中得到：\n$$\\begin{align}\nq_{\\alpha \\beta}^{\\star}=&amp; \\frac{1}{\\beta^2 J^2}\n\\frac{\\partial}{\\partial q_{\\alpha \\beta}} \\log \\sum_{\\left\\{S^\\alpha,\nS^\\beta, \\ldots, S^n\\right\\}} \\exp (L)=\\frac{1}{\\beta^2 J^2}\n\\frac{\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right\\}} \\exp (L)\n\\beta^2 J^2}{\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right\\}} \\exp\n(L)} S^\\alpha S^\\beta . \\\\\n=&amp; \\frac{\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right\\}}\nS^\\alpha S^\\beta \\exp (L)}{\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots,\nS^n\\right\\}} \\exp (L)} \\\\\nm_\\alpha^{\\star}=&amp;\\frac{1}{\\beta J_0} \\frac{\\partial}{\\partial\nm_\\alpha} \\log \\sum_{\\left\\{s_i^\\alpha, s_i^\\beta, \\ldots, s_i^n\\right)}\n\\exp (L)=\\frac{\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right\\}}\nS^\\alpha \\exp (L)}{\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right\\}}\n\\exp (L)} .\n\\end{align}$$\nqαβ and\nmα as\norder parameters\n可以改写为（并不是直接通过上面的过程的得出，只是先把结论摆出来）：\n$$\\begin{align}\nq_{\\alpha \\beta}=\\left[\\frac{\\sum_{\\left\\{s^\\alpha, s^s, \\ldots,\ns^n\\right\\}} S_i^\\alpha S_i^\\beta \\exp \\left(-\\beta \\sum_{\\gamma=1}^n\nH_\\gamma\\right)}{\\sum_{\\left\\{s^\\alpha, s^\\beta, \\ldots, s^n\\right\\}}\n\\exp \\left(-\\beta \\sum_{\\gamma=1}^n H_\\gamma\\right)}\\right]\n\\equiv\\left[\\left\\langle S_i^\\alpha S_i^\\beta\\right\\rangle\\right]\n\\label{32}\n\\end{align}$$\n其中： $$\\begin{align}\nH_\\gamma=&amp;\\sum_{i&lt;j} J_{i j}^2\\beta S_i^\\gamma S_j^\\gamma-h\n\\sum_i S_i^\\gamma \\label{33}\\\\\nm_\\alpha=&amp;\\left[\\left\\langle S_i^\\alpha\\right\\rangle\\right]\n\\label{34}\n\\end{align}$$\nReplica-symmetric solution\n对于$\\eqref{24}$已经提到，需要处理里面的qαβ与mα的问题。现在直接简单粗暴的假设：\n$$\\begin{align}\n\\forall\\alpha,\\beta\\quad q_{\\alpha\\beta}=q,m_\\alpha=m \\label{RS}\n\\end{align}$$\n将$\\eqref{28}$近似之后的结果写为;\n$$\\begin{align}\n\\frac{[\\log Z]}{N} &amp; =\\lim _{n \\rightarrow 0}\\left\\{\\frac{\\beta^2\nJ^2}{4}-\\frac{\\beta^2 J^2(n-1)}{4} q^2-\\frac{\\beta J_0}{2}\nm^2+\\frac{1}{n} \\log \\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots,\nS^n\\right\\}} \\exp \\left(L_{q_{\\alpha \\beta}=q,\nm_\\alpha=m}\\right)\\right\\} \\label{35} \\\\\n&amp; =\\frac{\\beta^2 J^2}{4}\\left(1+q^2\\right)-\\frac{\\beta J_0}{2}\nm^2+\\lim _{n \\rightarrow 0} \\frac{1}{n} \\log \\sum_{\\left\\{S^\\alpha,\nS^\\beta, \\ldots, S^n\\right\\}} \\exp \\left(L_{q_\\alpha \\beta}=q,\nm_\\alpha=m\\right) \\label{36}\n\\end{align}$$\n将其中L项具体写为：\n$$\\begin{align}\n\\frac{1}{n} \\log \\sum_{\\left\\{s_i^\\alpha, s_i^\\beta, \\ldots,\ns_i^n\\right)} \\exp \\left(L_{q_{\\alpha \\beta}=q,\nm_\\alpha=m}\\right)=\\frac{1}{n}\\log \\sum_{\\left\\{S^\\alpha, S^\\beta,\n\\ldots, S^n\\right\\}} \\exp \\left(\\beta^2 J^2 q \\sum_{\\alpha&lt;\\beta}\nS^\\alpha S^\\beta+\\beta\\left(J_0 m+h\\right) \\sum_\\alpha S^\\alpha\\right)\n\\end{align}$$\n引入变量ẑ，结合$\\eqref{11}$将SαSβ线性化：\n$$\\begin{align}\np(\\hat{z})=\\sqrt{\\frac{1}{2 \\pi}} \\exp \\left(-\\frac{\\hat{z}^2}{2}\\right)\n\\end{align}$$\n$$\n\\begin{align}\n&amp; \\frac{1}{n} \\log \\sum_{\\left\\{s_i^\\alpha, s_i^\\beta, \\ldots,\ns_i^n\\right)} \\exp \\left(\\beta^2 J^2 \\sum_{\\alpha&lt;\\beta} q_{\\alpha\n\\beta} S^\\alpha S^\\beta+\\beta \\sum_\\alpha\\left(J_0 m_\\alpha+h\\right)\nS^\\alpha\\right) \\\\\n= &amp; \\frac{1}{n} \\log \\sum_{\\left\\{s_i^\\alpha, s_i^\\beta, \\ldots,\ns_i^n\\right)} \\int d z p(z) \\exp \\left(\\beta J \\sqrt{q} \\hat{z}\n\\sum_\\alpha S^\\alpha-\\frac{n}{2} \\beta^2 J^2 q+\\beta\\left(J_0 m+h\\right)\n\\sum_\\alpha S^\\alpha\\right) \\\\\n= &amp; \\frac{1}{n} \\log\\left[ \\exp \\left(-\\frac{n}{2} \\beta^2 J^2\nq\\right) \\int d z p(\\hat{z}) \\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots,\nS^n\\right\\}} \\exp \\left(\\sum_\\alpha S^\\alpha\\left(\\beta J \\sqrt{q}\n\\hat{z}+\\beta\\left(J_0 m+h\\right)\\right)\\right)\\right] \\\\\n= &amp; \\frac{1}{n} \\log\\left[ \\exp \\left(-\\frac{n}{2} \\beta^2 J^2\nq\\right) \\int D z \\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right\\}}\n\\exp \\left(\\sum_\\alpha S^\\alpha\\left(\\beta J \\sqrt{q} z+\\beta\\left(J_0\nm+h\\right)\\right)\\right)\\right] \\\\\n= &amp; \\frac{1}{n} \\log\\left[ \\exp \\left(-\\frac{n}{2} \\beta^2 J^2\nq\\right) \\int D z \\prod_{\\gamma=1}^n \\sum_{S^\\gamma= \\pm 1} \\exp\n\\left(S^\\gamma\\left(\\beta J \\sqrt{q} z+\\beta\\left(J_0\nm+h\\right)\\right)\\right)\\right] \\\\\n= &amp; \\frac{1}{n} \\log\\left[ \\exp \\left(-\\frac{n}{2} \\beta^2 J^2\nq\\right) \\int D z  \\left\\{2 \\cosh \\left(\\beta J \\sqrt{q}\nz+\\beta\\left(J_0 m+h\\right)\\right)\\right\\}^n\\right] \\label{38_1} \\\\\n= &amp; \\frac{1}{n} \\log\\left[ \\exp \\left(-\\frac{n}{2} \\beta^2 J^2\nq\\right) \\int D z \\exp \\left(n \\log 2 \\cosh \\left(\\beta J \\sqrt{q}\nz+\\beta\\left(J_0 m+h\\right)\\right)\\right) \\right] \\\\\n= &amp;  \\left(-\\frac{1}{2} \\beta^2 J^2 q\\right)+\\frac{1}{n} \\log\\left[\n\\int D z \\exp \\left(n \\log 2 \\cosh \\left(\\beta J \\sqrt{q}\nz+\\beta\\left(J_0 m+h\\right)\\right)\\right) \\right]\\label{39} \\\\\n\\end{align}\n$$ 对其中n进行极小值展开，这里其是存在一些问题更清晰的应该将求极限的操作放在后面进行，并且将另一个n分离出来，不过问题不大只会造成理解困难。\n$$\\begin{align}\n&amp;\\approx \\left(-\\frac{1}{2} \\beta^2 J^2 q\\right)+\\frac{1}{n} \\log\n\\left\\{1+n \\int D z \\log 2 \\cosh \\left(\\beta J \\sqrt{q} z+\\beta\\left(J_0\nm+h\\right)\\right)\\right\\} \\\\\n&amp;\\approx \\left(-\\frac{1}{2} \\beta^2 J^2 q\\right)+\\int D z \\log 2\n\\cosh \\left(\\beta J \\sqrt{q} z+\\beta\\left(J_0\nm+h\\right)\\right)\\label{41}\n\\end{align}$$\n定义： $$\\begin{align}\n\\tilde{H}(z):=J \\sqrt{q} z+J_0 m+h  \\label{42}\n\\end{align}$$\n结合$\\eqref{41}\\eqref{42}$将$\\eqref{36}$写为：\n$$\\begin{align}\n\\frac{[\\log Z]}{N}=\\frac{\\beta^2 J^2}{4}(1-q)^2-\\frac{\\beta J_0}{2}\nm^2+\\int D z \\log 2 \\cosh (\\beta \\tilde{H}(z)) \\label{44}\n\\end{align}$$\n通过$\\partial_q \\frac{[\\log\nZ]}{N}=\\partial_m \\frac{[\\log Z]}{N}=0$获得极值点（计算q的时候需要分布积分处理一下）：\nPP = Sqrt[\\[Beta]^2 j^2 q/(2 Pi)] Exp[-z^2/2 \\[Beta]^2 j^2 q];HH = j Sqrt[q] z + j0 m + h;ZZ = (\\[Beta]^2 j^2)/4 (1 - q)^2 - (\\[Beta] j0)/2 m^2 +    Inactivate[    Integrate[PP Log[2 Cosh[\\[Beta] HH]], &#123;z, -Infinity, Infinity&#125;]];D[ZZ, m] // TraditionalFormD[Tanh[\\[Beta] HH], z] // FullSimplify\n$$\n\\begin{gather}\nm=\\int D z \\tanh \\beta \\tilde{H}(z) \\label{45}\\\\\nq=1-\\int D z \\operatorname{sech}^2 \\beta \\tilde{H}(z)=\\int D z \\tanh ^2\n\\beta \\tilde{H}(z) \\label{46}\n\\end{gather}\n$$\nReplica\nsymmetry breaking and the Parisi solution\nProblem\nwith the symmetric results: negative entropy at low temperature\n进行这样的假设J0 = h = 0，有\n$\\tilde{H}(z)=J \\sqrt{q}\nz$；并且有零温极限β → ∞，此时q → 1。但还是需要更q与β的线性结果，将$\\eqref{46}$在这个条件下进行零温近似：\n$$\\begin{align}\n\\lim _{\\beta \\rightarrow \\infty} \\int D z \\operatorname{sech}^2 \\beta\n\\tilde{H}(z)&amp;=\\int D z \\frac{2}{\\beta J} \\delta(\\beta J z)\\\\\n&amp;=\\sqrt{\\frac{2}{\\pi}} \\frac{T}{J}\n\\end{align}$$\n考虑到$\\int d x\\operatorname{sech}^2 \\beta\nx=\\frac{2}{\\beta}$，等价于$\\int d\nx\\frac{2}{\\beta}\\delta(x)$。\n因此有： $$\\begin{align}\nq=1-\\frac{T}{J} \\sqrt{\\frac{2}{\\pi}} \\label{q_limit}\n\\end{align}$$\n计算自由能： $$\\begin{align}\n[f]\\beta=-\\frac{[\\log Z]}{N}=-\\frac{\\beta^2 J^2}{4}(1-q)^2-\\int D z \\log\n2 \\cosh (\\beta J \\sqrt{q} z) \\label{48}\n\\end{align}$$\n其中[f]表示构型平均。将$\\eqref{q_limit}$代入$\\eqref{48}$最后一项：\n$$\\begin{align}\n\\int D z \\log 2 \\cosh (\\beta J \\sqrt{q} z) &amp; =2 \\int_0^{\\infty} D z\n\\log 2 \\cosh (\\beta J \\sqrt{q} z) \\\\\n&amp; =2 \\int_0^{\\infty} D z \\log 2 \\frac{\\exp (-\\beta J \\sqrt{q}\nz)+\\exp (\\beta J \\sqrt{q} z)}{2} \\\\\n&amp; \\approx 2 \\int_0^{\\infty} D z \\log 2 \\frac{\\exp (\\beta J \\sqrt{q}\nz)}{2} \\\\\n&amp;=\\frac{2 \\beta J \\sqrt{q}}{\\sqrt{2\\pi}}\n\\end{align}$$\n$\\sqrt{q}$已经是1附近的小量，因此结合$\\eqref{q_limit}$有$\\sqrt{q}\\approx q=1-\\frac{T}{J}\n\\sqrt{\\frac{2}{\\pi}}$：\n$$\\begin{align}\n\\int D z \\log 2 \\cosh (\\beta J \\sqrt{q} z)\n&amp;=\\frac{2 \\beta J}{\\sqrt{2\\pi}}\\left(1-\\frac{T}{J}\n\\sqrt{\\frac{2}{\\pi}}\\right) \\\\\n&amp;= \\sqrt{\\frac{2}{\\pi}}\\beta J-\\frac{2}{\\pi}\n\\end{align}$$\n从$\\eqref{48}$自由能有：\n$$\\begin{align}\n[f] \\approx -\\sqrt{\\frac{2}{\\pi}}J + \\frac{2 T}{\\pi}\n\\end{align}$$\n利用关系$S=-\\frac{\\partial F}{\\partial\nT}$，得到熵为： $$\\begin{align}\nS=-\\frac{2}{\\pi}\n\\end{align}$$\n显然负熵是没有含义的，这来源于假设的错误，需要引入复本对称破缺解决。\nStability of solutions\n利用一阶梯度为零的方法寻找极值，这存在一个问题：找到的解是否稳定？利用Hassian矩阵分析稳定性，并且假定h = 0。注记： $$\\begin{align}\ny^{\\alpha \\beta}:=\\beta J q_{\\alpha \\beta}, x^\\alpha=\\sqrt{\\beta J_0}\nm_\\alpha\n\\end{align}$$\n改写$\\eqref{28}$：\n$$\\begin{align}\n[f]=-\\frac{\\beta J^2}{4}-\\lim _{n \\rightarrow 0} \\frac{1}{\\beta\nn}\\left\\{-\\sum_{\\alpha&lt;\\beta} \\frac{1}{2}\\left(y^{\\alpha\n\\beta}\\right)^2-\\sum_\\alpha \\frac{1}{2}\\left(x^\\alpha\\right)^2+\\log\n\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right\\}} \\exp \\left(\\beta J\n\\sum_{\\alpha&lt;\\beta} y^{\\alpha \\beta} S^\\alpha S^\\beta+\\sqrt{\\beta\nJ_0} \\sum_\\alpha x^\\alpha S^\\alpha\\right)\\right\\}\n\\end{align}$$\n结合之前的复本近似假设，认为不同的值是微扰之后的结果xα = x + ϵα, yαβ = y + ηαβ，则$\\eqref{19}$：\n$$\\begin{align}\n&amp; L_0:=\\beta J y \\sum_{\\alpha&lt;\\beta} S^\\alpha S^\\beta+\\sqrt{\\beta\nJ_0} x \\sum_\\alpha S^\\alpha \\\\\n&amp; \\langle f\\rangle_{L^0}=\\frac{\\sum_{\\left\\{S^\\alpha, S^\\beta,\n\\ldots, S^n\\right\\}} e^{L_0\\left(\\left\\{S^\\alpha, S^\\beta, \\ldots,\nS^n\\right\\}\\right)} f}{\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots,\nS^n\\right\\}} e^{L_0\\left(\\left\\{S^\\alpha, S^\\beta, \\ldots,\nS^n\\right\\}\\right)} }\n\\end{align}$$\n需要完善\nAppend\nHessian\nHessian矩阵在极值点的稳定性分析中起着关键作用，具体涉及以下几个方面：\nHessian矩阵的定义\nHessian矩阵是由二阶偏导数组成的方阵，表示函数在某一点的二阶导数信息。对于一个多变量函数\nf(x1, x2, …, xn)，Hessian矩阵\nH 定义为：\n$$\nH = \\begin{bmatrix}\n\\frac{\\partial^2 f}{\\partial x_1^2} &amp; \\frac{\\partial^2 f}{\\partial\nx_1 \\partial x_2} &amp; \\cdots &amp; \\frac{\\partial^2 f}{\\partial x_1\n\\partial x_n} \\\\\n\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} &amp; \\frac{\\partial^2\nf}{\\partial x_2^2} &amp; \\cdots &amp; \\frac{\\partial^2 f}{\\partial x_2\n\\partial x_n} \\\\\n\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\n\\frac{\\partial^2 f}{\\partial x_n \\partial x_1} &amp; \\frac{\\partial^2\nf}{\\partial x_n \\partial x_2} &amp; \\cdots &amp; \\frac{\\partial^2\nf}{\\partial x_n^2}\n\\end{bmatrix}\n$$\n极值点与Hessian矩阵\n在某一点 x0，如果 ∇f(x0) = 0，则\nx0\n是一个驻点，可能是极大值点、极小值点或鞍点。Hessian矩阵 H(x0)\n在这个驻点的性质可以帮助确定这个驻点的类型。\nHessian矩阵的正定性与负定性\n\n正定矩阵与局部极小值:\n\n一个正定矩阵的所有特征值都是正的。\n对于任何非零向量 v，有\nvTHv &gt; 0。\n如果在驻点 x0，Hessian矩阵 H(x0)\n是正定的，那么在 x0\n附近，函数 f\n的曲率向上，类似于一个碗的形状。对于任何微小的偏离 x0 的向量 v，二阶泰勒展开式的二次项 $\\frac{1}{2} v^T H v$ 会贡献一个正值，因此\nf(x0 + v) &gt; f(x0)，即\nx0\n是局部极小值点。\n\n负定矩阵与局部极大值:\n\n一个负定矩阵的所有特征值都是负的。\n对于任何非零向量 v，有\nvTHv &lt; 0。\n如果在驻点 x0，Hessian矩阵 H(x0)\n是负定的，那么在 x0\n附近，函数 f\n的曲率向下，类似于一个倒置的碗的形状。对于任何微小的偏离 x0 的向量 v，二阶泰勒展开式的二次项 $\\frac{1}{2} v^T H v$ 会贡献一个负值，因此\nf(x0 + v) &lt; f(x0)，即\nx0\n是局部极大值点。\n\n混合正负特征值与鞍点:\n\n如果Hessian矩阵 H(x0)\n既有正特征值也有负特征值，那么它既不正定也不负定。\n在这种情况下，存在一些方向 v1 使得 v1THv1 &gt; 0，同时存在其他方向\nv2 使得 v2THv2 &lt; 0。\n如果在驻点 x0，Hessian矩阵 H(x0)\n既不正定也不负定，那么在 x0 附近，函数 f\n会在某些方向上向上弯曲（极小值行为），而在其他方向上向下弯曲（极大值行为）。这意味着\nx0\n不是局部极值点，而是一个鞍点，类似于马鞍的形状，在某些方向上是极小值，在另一些方向上是极大值。\n\n\n实际应用\n在优化问题中，Hessian矩阵用于评估驻点的稳定性和类型。在机器学习和深度学习中，Hessian矩阵用于分析损失函数的曲率和优化算法的收敛性。\n总结来说，Hessian矩阵通过其正定性或负定性帮助我们区分驻点的类型，从而判断这些点是极大值点、极小值点还是鞍点，这对于理解函数的局部行为和稳定性非常重要。\n$\\exp\\left(\\frac{\\partial}{\\partial\nh}\\right)$形式算子含义\n(()) 是一个形式算子（formal\noperator），它的作用可以理解为将函数沿着其变量 h\n方向移动一个单位距离。要理解这一点，我们需要结合泰勒级数展开和算子的作用进行说明。\n泰勒级数展开\n考虑一个函数 f(h)，在 h 处的泰勒展开可以表示为：\n$$f(h + a) = \\sum_{n=0}^{\\infty}\n\\frac{a^n}{n!} \\frac{\\partial^n f(h)}{\\partial h^n}$$\n这个展开式表示的是函数 f(h) 在 h 点处的 a 位移。特别地，当 a = 1 时：\n$$f(h + 1) = \\sum_{n=0}^{\\infty}\n\\frac{1^n}{n!} \\frac{\\partial^n f(h)}{\\partial h^n} =\n\\sum_{n=0}^{\\infty} \\frac{1}{n!} \\frac{\\partial^n f(h)}{\\partial\nh^n}$$\n形式算子 $\\exp\\left(\\frac{\\partial}{\\partial\nh}\\right)$\n形式算子 $\\exp\\left(\\frac{\\partial}{\\partial\nh}\\right)$ 的定义基于它的泰勒级数展开：\n$$\\exp\\left(\\frac{\\partial}{\\partial\nh}\\right) = \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\n\\frac{\\partial}{\\partial h} \\right)^n$$\n当这个算子作用在函数 f(h)\n上时，它会应用上述展开式：\n$$\\exp\\left(\\frac{\\partial}{\\partial\nh}\\right) f(h) = \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\n\\frac{\\partial}{\\partial h} \\right)^n f(h)$$\n这实际上与泰勒展开式中 a = 1 的情况一致：\n$$\\exp\\left(\\frac{\\partial}{\\partial\nh}\\right) f(h) = \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\frac{\\partial^n\nf(h)}{\\partial h^n} = f(h + 1)$$\n具体说明\n\n泰勒展开表示位移：泰勒级数展开表示函数在其定义点的某一位移。例如，f(h + a) 是函数\nf(h) 在 h 点处的 a 位移。\n算子的作用：$\\exp\\left(\\frac{\\partial}{\\partial\nh}\\right)$ 作为一个形式算子，其作用相当于将函数沿着其变量 h\n方向移动一个单位。因为它的作用与泰勒展开的结果一致，当 a = 1\n时，正好表示向前移动一个单位距离。\n形式算子的求和性质：通过展开 $\\exp\\left(\\frac{\\partial}{\\partial\nh}\\right)$\n的泰勒级数，我们实际上是在累加所有阶数的导数项，这与泰勒级数本身的形式完全吻合，确保了我们得到的结果是函数在\nh 处的一个单位位移。\n\n总结\n$\\exp\\left(\\frac{\\partial}{\\partial\nh}\\right)$ 形式算子的作用可以理解为利用泰勒级数展开的特性，将函数\nf(h) 沿变量 h\n的方向移动一个单位距离。这种理解源于泰勒展开中的每一项都对应于函数的一个导数项，而形式算子的展开正好与泰勒展开的累加形式一致，从而实现了位移的效果。\n","categories":["Physics"],"tags":["Spin Glass","Replica Method","Sherrington-Kirkpatrick Model"]},{"title":"The Parisi solution of Sherrington-Kirkpatrick Model","url":"/2022/11/20/Phys/SK_model/SK_model1/","content":"利用复本方法计算 Sherrington-Kirkpatrick（SK） 模型。该章节主要介绍\nParisi 解。\nReference: * Statistical Physics of Spin Glasses and Information\nProcessing. Nishimori * Replica\ncalculations for the SK model笔误有点多 * RS\nand RSB solutions for SK model with spin-S\nLink: * Hopfield Model * Replica * Sherrington-Kirkpatrick Model\n\n根据\n$$\\begin{align}\n-\\beta[f]= &amp; \\lim _{n \\rightarrow 0} \\frac{\\left[Z^n\\right]-1}{n\nN}=\\lim _{n \\rightarrow 0}\\left\\{-\\frac{\\beta^2 J^2}{4 n} \\sum_{\\alpha\n\\neq \\beta} q_{\\alpha \\beta}^2-\\frac{\\beta J_0}{2 n} \\sum_\\alpha\nm_\\alpha^2+\\frac{1}{4} \\beta^2 J^2+\\frac{1}{n} \\log \\operatorname{Tr}\n\\mathrm{e}^L\\right\\} \\label{2.17}\n\\end{align}$$\nMulti-step replica\nsymmetry breaking (RSB)\n在复本对称假设$\\eqref{RS}$中qαβ与mαβ并不依赖于αβ，为了打破对称需要考虑q矩阵的结构。现在考虑 n-RSB\n的矩阵，首先对于 1-RSB有m1 &lt; n，例如当n = 6, m1 = 3时候，q矩阵有（对角线为零的原因在于，当α = β时候没有定义）：\n$$\\begin{align}\n\\left(\\begin{array}{ccc|ccc}\n0 &amp; q_1 &amp; q_1 &amp; &amp; &amp; \\\\\nq_1 &amp; 0 &amp; q_1 &amp; &amp; q_0 &amp; \\\\\nq_1 &amp; q_1 &amp; 0 &amp; &amp; &amp; \\\\\n\\hline &amp; &amp; &amp; 0 &amp; q_1 &amp; q_1 \\\\\n&amp; q_0 &amp; &amp; q_1 &amp; 0 &amp; q_1 \\\\\n&amp; &amp; &amp; q_1 &amp; q_1 &amp; 0\n\\end{array}\\right)\\label{1-RSB}\n\\end{align}$$\n可以执行相同的迭代操作，将粒度不断细化，例如再进行对称破缺$\\eqref{1-RSB}$左上角的块变为： $$\\begin{align}\n\\begin{array}{ccc|ccc}\n0 &amp; q_2 &amp; q_2 &amp; &amp; &amp; \\\\\nq_2 &amp; 0 &amp; q_2 &amp; &amp; q_1 &amp; \\\\\nq_2 &amp; q_2 &amp; 0 &amp; &amp; &amp; \\\\\n\\hline &amp; &amp; &amp; 0 &amp; q_2 &amp; q_2 \\\\\n&amp; q_1 &amp; &amp; q_2 &amp; 0 &amp; q_2 \\\\\n&amp; &amp; &amp; q_2 &amp; q_2 &amp; 0\n\\end{array} \\label{2-RSB}\n\\end{align}$$\n同时应当满足条件：\n$$\\begin{align}\nn \\geq m_1 \\geq m_2 \\geq \\ldots \\geq 1\n\\end{align}$$\n定义函数： $$\\begin{align}\nq(x)=q_i \\quad\\left(m_{i+1} \\leq x \\leq m_i\\right)\n\\end{align}$$\n进行复本对称的极限变换n → 0，将不等关系进行任意的翻转（令人费解的反号）：\n$$\\begin{align}\n0 \\leq m_1 \\leq m_2 . . \\leq 1\n\\end{align}$$\nFirst step RSB\n再次回到计算[Zn]，结合$\\eqref{19}$，在J0 = h = 0的假设下，将$\\eqref{1-RSB}$融入进去有：\n$$\\begin{align}\n\\sum_{\\alpha&lt;\\beta} q_{\\alpha \\beta} S^\\alpha\nS^\\beta=\\frac{1}{2}\\left\\{q_0\\left(\\sum_\\alpha^n\nS^\\alpha\\right)^2+\\left(q_1-q_0\\right) \\sum_{b=1}^{n /\nm_1}\\left(\\sum_{\\alpha \\in B_b}^{m_1} S^\\alpha\\right)^2-n q_1\\right\\}\n\\label{67}\n\\end{align}$$\n其中Bb\n表示 b-th\nblock。第一项是没有进行复本破缺的，第二项是表示一阶复本破缺，第三项将对角线的贡献排除。同样的，对于$\\eqref{28}$有：\n$$\\begin{align}\n\\lim _{n \\rightarrow 0} \\frac{1}{n} \\sum_{\\alpha \\neq \\beta} q_{\\alpha\n\\beta}^2=\\lim _{n \\rightarrow 0} \\frac{1}{n}\\left\\{n^2\nq_0^2+\\frac{n}{m_1} m_1^2\\left(q_1^2-q_0^2\\right)-n\nq_1^2\\right\\}=\\left(m_1-1\\right) q_1^2-m_1 q_0^2 \\label{68}\n\\end{align}$$\n此时已经将自由能中含有qαβ的地方进行替换，接下来分析$\\eqref{28}$。首先将$\\eqref{68}$代入：\n$$\\begin{align}\n\\beta\\left[f_{1 R S B}\\right]=\\frac{\\beta^2\nJ^2}{4}\\left\\{\\left(m_1-1\\right) q_1^2-m_1 q_0^2-1\\right\\}+\\frac{\\beta\nJ_0}{2} m^2-\\frac{1}{n} \\log \\sum_{\\left\\{S^\\alpha, S^3, \\ldots,\nS^n\\right\\}} \\exp \\left(L_{1 R S B}\\right) \\label{70}\n\\end{align}$$\n再将$\\eqref{67}$代入$\\eqref{19}$：\n$$\n\\begin{gather}\nL\\left(\\left\\{q_{\\alpha \\beta}, m_\\alpha\\right\\}\\right):=\\beta^2 J^2\n\\sum_{\\alpha&lt;\\beta} q_{\\alpha \\beta} S^\\alpha S^\\beta+\\beta\n\\sum_\\alpha\\left(J_0 m_\\alpha+h\\right) S^\\alpha \\label{71} \\\\\n\\Rightarrow L_{1 R S B}=\\frac{\\beta^2\nJ^2}{2}\\left\\{q_0\\left(\\sum_\\alpha^n\nS^\\alpha\\right)^2+\\left(q_1-q_0\\right) \\sum_{b=1}^{n /\nm_1}\\left(\\sum_{\\alpha \\in B_b}^{m_1} S^\\alpha\\right)^2-n\nq_1\\right\\}+\\beta \\sum_\\alpha\\left(J_0 m_\\alpha+h\\right) S^\\alpha\n\\label{72}\n\\end{gather}\n$$\n由于里面有$\\left(\\sum_\\alpha^n\nS^\\alpha\\right)^2$和$\\left(\\sum_{\\alpha\n\\in B_b}^{m_1}\nS^\\alpha\\right)^2$，需要将平方项变为线性项，同样使用$\\eqref{11}$的办法：\n$$\n\\begin{align}\n&amp; \\frac{1}{n} \\log \\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots,\nS^n\\right\\}} \\exp \\left(L_{1 R S B}\\right) \\\\\n&amp; =\\frac{1}{n} \\log \\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots,\nS^n\\right)} \\int D u \\exp \\left(\\beta J \\sqrt{q_0} u \\sum_\\alpha\nS^\\alpha-\\frac{n}{2} \\beta^2 J^2 q_1+\\sum_\\alpha S^\\alpha \\beta\\left(J_0\nm+h\\right)+\\left(q_1-q_0\\right)\\frac{\\beta^2 J^2}{2} \\sum_{b=1}^{n /\nm_1}\\left(\\sum_{\\alpha \\in B_b}^{m_1} S^\\alpha\\right)^2\\right) \\\\\n&amp; =-\\frac{1}{2} \\beta^2 J^2 q_1+\\underbrace{\\frac{1}{n} \\log\n\\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots, S^n\\right)} \\int D u \\exp\n\\left(\\sum_\\alpha S^\\alpha\\left(\\beta J \\sqrt{q_0} u+\\beta\\left(J_0\nm+h\\right)\\right)+\\left(q_1-q_0\\right)\\frac{\\beta^2 J^2}{2}\n\\sum_{b=1}^{n / m_1}\\left(\\sum_{\\alpha \\in B_b}^{m_1}\nS^\\alpha\\right)^2\\right)}_{\\Delta} \\label{72_2}\n\\end{align}\n$$\n引入vb线性化$\\left(\\sum_{\\alpha \\in B_b}^{m_1}\nS^\\alpha\\right)^2$：\n$$\n\\begin{align}\n&amp; \\frac{1}{n} \\log \\sum_{\\left\\{S^\\alpha, S^\\beta, \\ldots,\\right\\}}\n\\int D u \\prod_{b=1}^{n / m_1}\\left(\\int D v_b\\right) \\exp\n\\left(\\sum_\\alpha S^\\alpha \\beta J \\sqrt{q_0} u+\\sum_\\alpha S^\\alpha\n\\beta\\left(J_0 m+h\\right)+\\beta J \\sqrt{q_1-q_0} \\sum_{b=1}^{n / m_1}\nv_b \\sum_{\\alpha \\in B_b}^{m_1} S^\\alpha\\right) \\\\\n= &amp; \\frac{1}{n} \\log \\int D u \\sum_{\\left\\{S^\\alpha, S^\\beta,\n\\ldots, S^n\\right\\}} \\prod_{b=1}^{n / m_1}\\left\\{\\int v e \\exp\n\\left(\\sum_\\alpha S^\\alpha \\beta\\left(J_0 m+h+\\beta J \\sqrt{q_0}\nu\\right)\\right) \\exp \\left(\\beta J \\sqrt{q_1-q_0} v \\sum_{\\alpha \\in\nB_b}^{m_1} S^\\alpha\\right)\\right\\} \\\\\n= &amp; \\frac{1}{n} \\log \\int D u \\prod_{b=1}^{n / m_1}\\left\\{\\int D v_b\n\\sum_{\\left\\{S^\\alpha\\right\\} \\in B_b} \\exp\n\\left(\\sum_{\\left\\{S^\\alpha\\right\\} \\in B_b} S^\\alpha\\beta\\left(J_0\nm+h+\\beta J \\sqrt{q_0} u+J \\sqrt{q_1-q_0} v_b\\right)\\right)\\right\\} \\\\\n= &amp; \\frac{1}{n} \\log \\int D u \\prod_{b=1}^{n / m_1}\\left\\{\\int D\nv_b\\left\\{\\sum_{S= \\pm 1} \\exp \\left(S \\beta\\left(J_0 m+h+\\beta J\n\\sqrt{q_0} u+J \\sqrt{q_1-q_0} v_b\\right)\\right)\\right\\}^{m_1}\\right\\} \\\\\n= &amp; \\frac{1}{n} \\log \\int D u\\left\\{\\int v\\left\\{\\sum_{S= \\pm 1}\n\\exp \\left(S \\beta\\left(J_0 m+h+\\beta J \\sqrt{q_0} u+J \\sqrt{q_1-q_0}\nv\\right)\\right)\\right\\}^{m_1}\\right\\}^{n / m_1} \\\\\n= &amp; \\frac{1}{n} \\log \\int D u\\left\\{\\int D v\\left\\{2 \\cosh\n\\left(\\beta\\left(J_0 m+h+\\beta J \\sqrt{q_0} u+J \\sqrt{q_1-q_0}\nv\\right)\\right)\\right\\}^{m_1}\\right\\}^{n / m_1} \\\\\n= &amp; \\frac{1}{n} \\log \\int D u \\exp \\left\\{\\frac{n}{m_1} \\log\n\\left\\{\\int D v\\left\\{2 \\cosh \\left(\\beta\\left(J_0 m+h+\\beta J\n\\sqrt{q_0} u+J \\sqrt{q_1-q_0}\nv\\right)\\right)\\right\\}^{m_1}\\right\\}\\right\\} \\\\\n\\approx &amp; \\frac{1}{n} \\log \\left\\{1+\\frac{n}{m_1} \\int D u \\log\n\\left\\{\\int D v\\left\\{2 \\cosh \\left(\\beta\\left(J_0 m+h+\\beta J\n\\sqrt{q_0} u+J \\sqrt{q_1-q_0}\nv\\right)\\right)\\right\\}^{m_1}\\right\\}\\right\\} \\text { expand exponent\naround } 0 \\\\\n\\approx &amp; \\frac{1}{n} \\frac{n}{m_1} \\int D u \\log \\left\\{\\int D\nv\\left\\{2 \\cosh \\left(\\beta\\left(J_0 m+h+\\beta J \\sqrt{q_0} u+J\n\\sqrt{q_1-q_0} v\\right)\\right)\\right\\}^{m_1}\\right\\} \\text { expand\nexponent around } 1 \\\\\n= &amp; \\log 2+\\frac{1}{m_1} \\int D u \\log \\left\\{\\int D v\\left\\{\\cosh\n\\left(\\beta\\left(J_0 m+h+\\beta J \\sqrt{q_0} u+J \\sqrt{q_1-q_0}\nv\\right)\\right)\\right\\}^{m_1}\\right\\} \\text { pull the factor of } 2\n\\text { out } \\label{82}\n\\end{align}\n$$\n令： $$\\begin{align}\n\\Xi=\\beta\\left(J_0 m+h+\\beta J \\sqrt{q_0} u+J \\sqrt{q_1-q_0} v\\right)\n\\label{86}\n\\end{align}$$\n有： $$\\begin{align}\n\\Delta=\\log 2+\\frac{1}{m_1} \\int D u \\log \\left\\{\\int D v\\{\\cosh\n\\Xi\\}^{m_1}\\right\\} \\label{87}\n\\end{align}$$\n结合$\\eqref{72_2}\\eqref{87}$将$\\eqref{70}$写为： $$\\begin{align}\n\\beta\\left[f_{1 R S B}\\right]=\\frac{\\beta^2\nJ^2}{4}\\left\\{\\left(m_1-1\\right) q_1^2-m_1 q_0^2+2\nq_1-1\\right\\}+\\frac{\\beta J_0}{2} m^2-\\log 2-\\frac{1}{m_1} \\int D u \\log\n\\left\\{\\int D v\\{\\cosh \\Xi\\}^{m_1}\\right\\} .\n\\end{align}$$\n得到极值点为： $$\\begin{gather}\nm^*=\\int D u \\frac{\\int D v\\{\\cosh \\Xi\\}^{m_1} \\tanh \\Xi}{\\int D\nv\\{\\cosh \\Xi\\}^{m_1}} \\\\\nq_0^* =\\int D u\\left(\\frac{\\int D v\\{\\cosh \\Xi\\}^{m_1} \\tanh \\Xi}{\\int D\nv\\{\\cosh \\Xi\\}^{m_1}}\\right)^2 \\\\\nq_1^* =\\int D u \\frac{\\int D v\\{\\cosh \\Xi\\}^{m_1}\\{\\tanh \\Xi\\}^2}{\\int D\nv\\{\\cosh \\Xi\\}^{m_1}}\n\\end{gather}$$\n mathematica代码与python代码\nFull RSB Solution\n由于熵还是负数，接下来进行更高阶的复本对称破缺（k-RSB）计算$\\eqref{28}$。与一阶复本对称$\\eqref{67}$类似:\n$$\\begin{align}\n\\sum_{\\alpha \\neq \\beta} q_{\\alpha \\beta}^l &amp; =q_0^l\nn^2+\\left(q_1^l-q_0^l\\right) m_1^2 \\cdot\n\\frac{n}{m_1}+\\left(q_2^l-q_1^l\\right) m_2^2 \\cdot \\frac{m_1}{m_2} \\cdot\n\\frac{n}{m_1}+\\cdots-q_K^l \\cdot n \\\\ &amp; =n\n\\sum_{j=0}^K\\left(m_j-m_{j+1}\\right) q_j^l \\label{3.37}\n\\end{align}$$\n其中l是任意整数，m0 = n, mK + 1 = 1，在极限情况n → 0下，使用mj − mj + 1 → −dx，可以得到：\n$$\\begin{align}\n\\frac{1}{n} \\sum_{\\alpha \\neq \\beta} q_{\\alpha \\beta}^l\n\\rightarrow-\\int_0^1 q^l(x) \\mathrm{d} x \\label{3.38}\n\\end{align}$$\n在J0 = 0, h = 0的条件下，结合$E=-\\frac{\\partial \\log Z}{\\partial\n\\beta}$、$\\chi=-\\frac{\\partial^2\nF}{\\partial h^2}$与$\\eqref{28}$，可得：\n没有证明\n$$\\begin{gather}\nE=-\\frac{\\beta J^2}{2}\\left(1+\\frac{2}{n} \\sum_{\\alpha&lt;\\beta}\nq_{\\alpha \\beta}^2\\right) \\rightarrow-\\frac{\\beta\nJ^2}{2}\\left(1-\\int_0^1 q^2(x) \\mathrm{d} x\\right) \\\\\n\\chi=\\beta\\left(1+\\frac{1}{n} \\sum_{\\alpha \\neq \\beta} q_{\\alpha\n\\beta}\\right) \\rightarrow \\beta\\left(1-\\int_0^1 q(x) \\mathrm{d} x\\right)\n\\end{gather}$$\nparisi equation\n接下来需要将高阶复本破缺技巧应用在自由能$\\eqref{2.17}$，和计算一阶复本对称的操作一样，首先计算q0然后计算第一次分块q1的贡献并且排除q0的影响，以此类推，在主对角线上是qK。首先计算如下项：\n$$\n\\begin{align}\nG &amp; =\\operatorname{Tr} \\exp \\left(\\frac{1}{2} \\sum_{\\alpha,\n\\beta=1}^n q_{\\alpha \\beta} S^\\alpha S^\\beta+h \\sum_\\alpha^n\nS^\\alpha\\right) \\\\\n&amp; =\\left.\\exp \\left(\\frac{1}{2} \\sum_{\\alpha, \\beta} q_{\\alpha\n\\beta} \\frac{\\partial^2}{\\partial h_\\alpha \\partial h_\\beta}\\right)\n\\prod_\\alpha 2 \\cosh h_\\alpha\\right|_{h_\\alpha=h}  \\label{B.1}\n\\end{align}\n$$\n这里将qαβ贡献的项目视为h项的偏移，因此使用$\\exp(\\frac{\\partial^2}{\\partial h_\\alpha \\partial\nh_\\beta})$的形式表示这个偏移量。如果使用复本对称的假设，则：\n$$\\begin{align}\nG=\\exp \\left(\\frac{q}{2} \\frac{\\partial^2}{\\partial h^2}\\right)(2 \\cosh\nh)^n \\label{B.2}\n\\end{align}$$\n其中使用到：\n$$\n\\left.\\sum_\\alpha \\frac{\\partial f\\left(h_1, \\ldots,\nh_n\\right)}{\\partial h_\\alpha}\\right|_{h_\\alpha=h}=\\frac{\\partial f(h,\n\\ldots, h)}{\\partial h}\n$$\n从$\\eqref{67}$中可以看出，当时的思想是从复本对称假设出发，然后将整个矩阵分为几部分（取决于$\\frac{n}{m}$大小），在主对角线的块上为一阶复本对称q1；那么同样的二阶复本对称可以将每一个一阶复本对称的块分为几部分，然后将主对角线的块作为二阶复本q2；这个流程以此类推。现在可以反过来，从K阶复本逐渐变为0阶级复本：\n\n对于K − 1阶复本有(qK − qK − 1)I(mK)，表示(mK × mK)大小。\n生长出(K − 2)复本，将K阶复本通过DiagK − 1扩张  (qK − qK − 1)DiagK − 1[I(mK)]，然后K − 2阶写为(qK − 1 − qK − 2)I(mK − 1)矩阵的大小为(mK − 1 × mK − 1)。整体为:\n  (qK − qK − 1)DiagK − 1[I(mK)] + (qK − 1 − qK − 2)I(mK − 1)\n重复步骤2，得到K − 3复本。矩阵的大小为(mK − 2 × mK − 2)\n  (qK − qK − 1)DiagK − 2[I(mK)] + (qK − 1 − qK − 2)DiagK − 2[I(mK − 1)] + (qK − 2 − qK − 3)I(mK − 2)\n\n在清楚以上步骤之后，接下来首先处理(mK × mK)大小矩阵Tr ，并将结果标注为g(mK, h)，由于这是复本破缺的最后一次，因此这个矩阵元是复本对称的，由$\\eqref{B.2}$得到：\n$$\\begin{align}\ng\\left(m_K, h\\right)=\\exp \\left\\{\\frac{1}{2}\\left(q_K-q_{K-1}\\right)\n\\frac{\\partial^2}{\\partial h^2}\\right\\}(2 \\cosh h)^{m_K} \\label{B.4}\n\\end{align}$$\n对于K − 1阶，是考虑将g(mK, h)复制到对角部分，然后每一个元素相加qK − 1 − qK − 2，从$\\eqref{B.2}$可以得到：\n$$\\begin{align}\ng\\left(m_{K-1}, h\\right)=\\exp\n\\left\\{\\frac{1}{2}\\left(q_{K-1}-q_{K-2}\\right)\n\\frac{\\partial^2}{\\partial h^2}\\right\\}\\left[g\\left(m_K,\nh\\right)\\right]^{m_{K-1} / m_K} \\label{B.5}\n\\end{align}$$\n一直重复这个过程，直到复本对称项： $$\\begin{align}\nG=g(n, h)=\\exp \\left\\{\\frac{1}{2} q(0) \\frac{\\partial^2}{\\partial\nh^2}\\right\\}\\left[g\\left(m_1, h\\right)\\right]^{n / m_1}  \\label{B.6}\n\\end{align}$$\n考虑到极限n → 0下有mj − mj − 1 = −dx，将$\\eqref{B.5}$写为：\n$$\\begin{align}\ng(x+\\mathrm{d} x, h)=\\exp \\left\\{-\\frac{1}{2} \\mathrm{~d} q(x)\n\\frac{\\partial^2}{\\partial h^2}\\right\\} g(x, h)^{1+\\mathrm{d} \\log x}\n\\label{B.7}\n\\end{align}$$\n对于$\\eqref{B.4}$，当K → ∞有mk → 1，因为存在g(1, h) = 2cosh h。将$\\eqref{B.7}$转化为微分形式（对dq与dx进行展开）：\n$$\n\\frac{\\partial g}{\\partial x}=-\\frac{1}{2} \\frac{\\mathrm{d}\nq}{\\mathrm{~d} x} \\frac{\\partial^2 g}{\\partial h^2}+\\frac{1}{x} g \\log g\n$$\n利用注记f0(x, h) = (1/x)log g(x, h)改写为：\n$$\\begin{align}\n\\frac{\\partial f_0}{\\partial x}=-\\frac{1}{2} \\frac{\\mathrm{d}\nq}{\\mathrm{~d} x}\\left\\{\\frac{\\partial^2 f_0}{\\partial\nh^2}+x\\left(\\frac{\\partial f_0}{\\partial h}\\right)^2\\right\\} \\label{B.8}\n\\end{align}$$\n分析$\\eqref{B.6}$的极限情况，根据之前的讨论知道，当n → 0的时候，m1 → 0：\n$$\\begin{align}\n\\frac{1}{n} \\log \\operatorname{Tr} \\mathrm{e}^L &amp;= \\left. \\exp\n\\left(\\frac{1}{2} q(0) \\frac{\\partial^2}{\\partial h^2}\\right)\n\\frac{1}{x} \\log g(x, h)\\right|_{x, h \\rightarrow 0} \\\\\n&amp; =\\left.\\exp \\left(\\frac{1}{2} q(0) \\frac{\\partial^2}{\\partial\nh^2}\\right) f_0(0, h)\\right|_{h \\rightarrow 0} \\\\\n&amp; =\\int \\mathrm{D} u f_0(0, \\sqrt{q(0)} u) \\label{B.10}\n\\end{align}$$\n结合$\\eqref{3.38},\\eqref{B.10}$将$\\eqref{2.17}$写为q(1)这一项怎么来的？：\n$$\\begin{align}\n\\beta f=-\\frac{\\beta^2 J^2}{4}\\left\\{1+\\int_0^1 q(x)^2 \\mathrm{~d} x-2\nq(1)\\right\\}-\\int \\mathrm{D} u f_0(0, \\sqrt{q(0)} u) \\label{3.41}\n\\end{align}$$\n其中f0应当满足\nParisi equation，即$\\eqref{B.9}$:\n$$\\begin{align}\n\\frac{\\partial f_0(x, h)}{\\partial x}=-\\frac{J^2}{2} \\frac{\\mathrm{d}\nq}{\\mathrm{~d} x}\\left\\{\\frac{\\partial^2 f_0}{\\partial\nh^2}+x\\left(\\frac{\\partial f_0}{\\partial h}\\right)^2\\right\\}\n\\label{3.42}\n\\end{align}$$\n有 f0(1, h) = log 2cosh βh。\nOrder parameter near\nthe critical point\n虽然求解$\\eqref{3.41}$十分困难，但是在临界点附近的性质是可以研究的。\n在J0 = h = 0的条件下，$\\eqref{2.17}$展为4阶可以是：\n未经计算，直接抄的，并且十分简略\n$$\n\\begin{align}\n\\beta f= &amp; \\lim _{n \\rightarrow 0}\n\\frac{1}{n}\\left\\{\\frac{1}{4}\\left(\\frac{T^2}{T_{\\mathrm{f}}^2}-1\\right)\n\\operatorname{Tr} Q^2-\\frac{1}{6} \\operatorname{Tr} Q^3 - \\frac{1}{8}\n\\operatorname{Tr} Q^4+\\frac{1}{4} \\sum_{\\alpha \\neq \\beta \\neq \\gamma}\nQ_{\\alpha \\beta}^2 Q_{\\alpha \\gamma}^2-\\frac{1}{12} \\sum_{\\alpha \\neq\n\\beta} Q_{\\alpha \\beta}^4\\right\\},\n\\end{align}\n$$\n其中Qαβ = (βJ)2qαβ，令$\\theta=\\frac{T_f-T}{T_f}$并且考虑复本极限n → 0有：\n$$\n\\beta f=\\frac{1}{2} \\int_0^1 \\mathrm{~d} x\\left\\{|\\theta|\nq^2(x)-\\frac{1}{3} x q^3(x)-q(x) \\int_0^x q^2(y) \\mathrm{d}\ny+\\frac{1}{6} q^4(x)\\right\\}\n$$\n对q(x)求导：\n$$\n2|\\theta| q(x)-x q^2(x)-\\int_0^x q^2(y) \\mathrm{d} y-2 q(x) \\int_x^1\nq(y) \\mathrm{d} y+\\frac{2}{3} q^3(x)=0\n$$\n持续求微分得到结果： |θ|−xq(x) − ∫x1q(y)dy + q2(x) = 0  \nor   q′(x) = 0\n$$\nq(x)=\\frac{x}{2} \\quad \\text { or } \\quad q^{\\prime}(x)=0\n$$\n最后得到的解与|θ|有关：\n$$\n\\begin{align}\n&amp; q(x)=\\frac{x}{2} \\quad\\left(0 \\leq x \\leq x_1=2 q(1)\\right) \\\\\n&amp; q(x)=q(1) \\quad\\left(x_1 \\leq x \\leq 1\\right) \\\\\n&amp; q(1)=|\\theta|+\\mathcal{O}\\left(\\theta^2\\right)\n\\end{align}\n$$\n当接近相变点时，q(x = 0)。\n\n\nq(x)\n\n","categories":["Physics"],"tags":["Spin Glass","Replica Method","Sherrington-Kirkpatrick Model","Parisi solution","Replica Symmetry Breaking"]},{"title":"Tensor network Monte Carlo simulations for the two-dimensional random-bond Ising model","url":"/2024/09/18/Phys/TNMC/TNMC/","content":"Tensor Network Monte Carlo (TNMC)\nmethod将张量网络和蒙特卡洛模拟结合，是一种新的模拟方法。本文分为两个部分，介绍TNMC方法，以及其在随机二维Ising模型上的实验。\nLink: * Tensor network\nMonte Carlo simulations for the two-dimensional random-bond Ising\nmodel * Unbiased Monte\nCarlo for the age of tensor networks\nCode: * TNMC\n\nMetropolis-Hasting method\n\nIn particular, the local moves can get trapped in local minima,\nespecially in disordered systems, because due to the nature of the\nrugged energy landscape, the probability of moving to a higher-energy\nstate is low.\n\n对于传统的蒙卡，主要存在两个问题：临界慢化和阻锉模型基态问题，这两个问题是由完全不同的因素造成的。临界慢化的原因是在临界点会形成团簇，单个格点翻转接受概率低，这种阻碍也称为磁畴壁，有效的解决方案是从单一格点翻转改为集体翻转；基态问题是由于模型结构自身具有的阻锉引起的。\n这两个问题也可以从自由能的角度看待。自由能是通过熵和能量的竞争得到的，临界慢化对应相变点，此时系统倾向于处于熵极大的构型，也就是在能量相同的情况下拥有尽可能多的构型，但是这样就会遇到采样的困难，目标构型是非常稀疏的；同时还有另一个问题，熵并不容易衡量，这就意味着在穷尽结果前并不知道自己选取的构型是否为目标构型。没有评价指标和稀疏采样，造成临界慢化的困难性。那么提升方案（Swendsen-wang、Wolff）为什么有效呢？它们并没有设计机制解决稀疏采样和无评价指标的问题，而是利用在临界点特性。这些算法敏锐的觉察到，这些目标构型之间存在关联，因此从一个目标构型出发可以快速采样到其它的目标构型。基于此，接受率成为一个很好的评价指标。\n那接下来从自由能的角度分析基态。由于温度趋近于零，此时自由能等于能量，而基态的构型是由模型决定的，因此这是具有特定解的问题，同时评价构型优劣的指标为能量，能量越低是更倾向于选择的构型。此时的难点在于如何搜索。主要有两个方面，首先在穷举之前并不清楚目前低能量构型是最低能量构型；其次如何找到高效的搜索的方法。优化策略我认为有两种，首先是通过启发式的方法搜索，给出一个撒点的方式；另一方面是通过将构型的表示方法进行编码，在编码的空间进行搜索，将一些非凸的结构转化为凸性。\n竟然没有在博客中写过这个内容…之后想写的话添加上引用。\n$$\\begin{align}\n\\frac{P\\left(\\mathbf{s}_b\\right)}{P\\left(\\mathbf{s}_a\\right)}&amp;=e^{\\beta\nE\\left(\\mathbf{s}_a\\right)-\\beta E\\left(\\mathbf{s}_b\\right)} \\\\\nP(\\mathbf{s})&amp;=\\prod_{i=1}^N P\\left(s_i \\mid\n\\mathbf{s}_{&lt;i}\\right)\\\\\nP\\left(s_i \\mid\n\\mathbf{s}_{&lt;\\mathbf{i}}\\right)&amp;=\\frac{\\sum_{\\mathbf{s}_{&gt;i}}\ne^{-\\beta E\\left(s_i, \\mathbf{s}_{&lt;i}\\right)}}{\\sum_{s_i,\n\\mathbf{s}_{&gt;i}} e^{-\\beta E\\left(s_i,\n\\mathbf{s}_{&lt;i}\\right)}}=\\frac{Z\\left(s_i,\n\\mathbf{s}_{&lt;i}\\right)}{\\sum_{s_i} Z\\left(s_i,\n\\mathbf{s}_{&lt;i}\\right)} \\label{5}\n\\end{align}$$\nTensor network proposals\n将Ising模型求解配分函数的过程转化为张量网络。首先将整个网格表示为：\n\n\ntensor network\n\n由节点δ和转移矩阵W组成。其中节点δ的具体表达式，根据其连接边的数目（腿）决定，例如δ1有2条腿、δ2有3条腿、δ5有4条腿。 \n每一个节点，通过其腿的标号表示，例如δ2 = δmno, δ6 = δijkl，由于Ising模型只有±1，因此每条腿的选项只有1, 2两个，并且δ的取值定为：\n$$\\begin{align}\n\\delta_{ijkl}= \\begin{cases}1 &amp; i=j=k=l \\\\ 0 &amp; \\text { else }\n\\quad(i, j, k, l=1,2)\\end{cases}\n\\end{align}$$\n每一条腿表示对应格点的自旋取值，因此同一个自旋外延出来的腿应该具有相同的取值。\n然后定义转移矩阵：\n$$\\begin{align}\nW_{i j}=\\left(\\begin{array}{cc}\ne^{\\beta J_{i j}} &amp; e^{-\\beta J_{i j}} \\\\\ne^{-\\beta J_{i j}} &amp; e^{\\beta J_{i j}}\n\\end{array}\\right)\n\\end{align}$$\n其中 W11 = W22 = exp (βJij), W12 = W21 = exp (−βJij)，Jij表示相邻的相互作用系数（Ising模型中是相同的，在spin\nglass）。\n接下来需要进一步对矩阵进行收缩，将转移矩阵收缩进格点中，表示为 \n在之前的模型中，箭头表示收缩的方向，由下及上、由左及右。例如δ5会收缩两个方向的，因此将l, k进行求和：\n$$\\begin{align}\nT_5 = T_{ijqr}=\\sum_l\\sum_k \\delta_{ijkl} W_{kq}W_{lr}\n\\end{align}$$\nδ2同理：\n$$\\begin{align}\nT_2 = T_{mis}=\\sum_o\\sum_n \\delta_{nmo} W_{oi}W_{ns}\n\\end{align}$$\n接下来对于T2T5的收缩，可以通过对i的求和，表示为∑iTmisTijqr。\n因此求配分函数，接下来就是通过指标的收缩求和。 \n精确求解这个张量网络会遇到维数增长的问题，可以通过singular-value-decomposition（SVD）近似的方法解决这个问题。\nComputing\nthe partition function using tensor networks\n计算蒙卡的接受效率，需要通过计算$\\eqref{5}$。因此，接下来描述如何利用张量网络结合采样，计算$\\eqref{5}$。\n以计算s4为例，那么已经提前知道采样s1, s2, s3的值。此时张量网络可以表示为：\n\n\nsample tensor\n\n当自旋确定，改变的是在自旋收缩的时候，不再是求和而是直接固定。上图展示了如何通过指标的收缩，表示∑s4Z(s4, s &lt; 4)。对于计算Z(s4, s &lt; 4)则需要将，δ4改为固定的s4：\n\n\nsample tensor2\n\n其中f(s4) = eβJ14s1s4，张量两边为s4的取值。然后逐渐增加位置，直到完成整体的采样。\n通过如上的计算方式，便可以计算$\\eqref{5}$。其中，存在一些小技巧：为了加速，在计算的时候可以存储之前的计算结果，之后相似的构型可以直接查表。\n然而这个计算方式也存在问题，看似解决了之前迭代速度慢的问题，但每次迭代比之前要花费更多的时间。这个算法真正有效的地方在于临界行为处，当处理复杂的能量面时候，这个算法能够更快速的迭代，而不是传统蒙卡被困于无穷关联长度中。\nResult\n接下来在随机二维Ising模型上进行实验，随机体现在自旋之间的相互作用J正负是以p和1 − p的概率选取。\n该算法的核心点在于接受率的提升，所以第一个数据展示在SVD不同维度的情况，以及不同温度、不同尺寸的情况下接受率的变化。\n\n\nresult\n\n第二个实验展示了CPU用时和内存消耗。\n\n\nresult2\n\n","categories":["Physics"],"tags":["Monte Carlo","Computer Physics","Tensor Network"]},{"title":"Reclaiming the Lost Conformality in a non-Hermitian Quantum 5-state Potts Model","url":"/2024/03/20/Phys/five_state_Pottes_Model/five_state_Pottes_Model/","content":"这篇文章并未读完，更多的内容在于知识上的补充\nAbstract\n共形对称发生在临界点，，但是在重整化群的相变点相撞的时候，这种对称性会消失。认为这种实平面的固定点将会变到复平面中。这篇工作，利用非厄米量子5态Potts模型，成功提取到了复平面的高度。\n\nThe Potts Model\n$$\\begin{align}\nH = -\\sum_{&lt;ij&gt;}J(\\theta_{ij})\n\\end{align}$$\nplanar Potts model: $$\\begin{align}\n\\theta_{ij}=&amp;\\theta_{n_i}-\\theta_{n_j} \\\\\nJ(\\theta) =&amp; -\\epsilon_1\\cos \\theta_{ij}\n\\end{align}$$\nstandard Potts model (simply the Potts model): $$\\begin{align}\nJ(\\theta_{ij}) =&amp; \\epsilon_2\\delta(n_i, n_j)\n\\end{align}$$\n以下讨论针对标准的Potts模型。分别用转移矩阵、乘积展开、染色多项式三种方法，得到配分函数。\n\n转移矩阵法 ZN = Tr VN\n其中 $$ $$\n于是配分函数也就是 ZN = (eβJ + q − 1)N + (q − 1)(eβJ − 1)N\n乘积展开 $$\n\\begin{aligned}\nZ_N &amp; =\\sum_{\\{\\sigma\\}} \\exp \\left[\\beta J \\sum_{\\langle i\nj\\rangle} \\delta\\left(\\sigma_i, \\sigma_j\\right)\\right] \\\\\n&amp; =\\sum_{\\{\\sigma\\}} \\prod_{\\langle i j\\rangle}\\left[1+v\n\\delta\\left(\\sigma_i, \\sigma_j\\right)\\right]\n\\end{aligned}\n$$\n其中 v = eβJ − 1\n。\n\n关于Pottes\nModel相变精确解，与纽结理论的联系\nAppend\n共形对称\n共形对称（Conformal\nsymmetry）是一种特殊类型的全局对称性，它指的是一个理论或系统在共形变换下保持不变的性质。\n共形变换是一类特殊的坐标变换，它们不仅包括了普通的平移和旋转，还包括了尺度变换（即缩放）和特殊的非线性变换。共形对称在物理学中尤其重要，因为它通常与系统的尺度不变性相关联，这意味着物理规律在不同的长度尺度上都是相同的。\n高低温展开\nIsing模型与Duality——相变温度\nIsing模型与Duality——特殊的相变\nMIT\nnotes\n以2-D Ising 模型为例，配分函数写为： Z = ∑{si}exp (−βH) = ∑{si}exp (K∑ &lt; i, j&gt;sisj)\n其中K = βJ。\n高温展开，即K → 0为： $$\\begin{equation}\n\\begin{aligned}\nZ= &amp; \\sum_{\\left\\{s_i\\right\\}} \\prod_{&lt;i, j&gt;} \\exp \\left(K s_i\ns_j\\right) \\\\\n= &amp; \\sum_{\\left\\{s_i\\right\\}} \\prod_{&lt;i, j&gt;}\\left[\\sinh\n\\left(K s_i s_j\\right)+\\cosh \\left(K s_i s_j\\right)\\right] \\\\\n= &amp; (\\cosh K)^{2 N} \\sum_{\\left\\{s_i\\right\\}} \\prod_{&lt;i,\nj&gt;}\\left[1+s_i s_j \\tanh K\\right] \\\\\n= &amp; (\\cosh K)^{2 N}\\left[\\sum_{\\left\\{s_i\\right\\}} 1+\\tanh K\n\\sum_{\\left\\{s_i\\right\\}&lt;i, j&gt;} s_i s_j\n+(\\tanh K)^2 \\sum_{\\left\\{s_i\\right\\}} \\sum_{&lt;i, j&gt;} \\sum_i s_j\ns_n s_m+\\cdots \\right ]\\\\\n=&amp; (\\cosh K)^{2 N} 2^N\\left[1+N(\\tanh K)^4+2 N(\\tanh K)^6 +(4\nN+N(N-5))(\\tanh K)^8 \\cdots\\right]\n\\end{aligned}\n\\end{equation}$$\n\n\n高温展开\n\n低温展开，即K → +∞，零温极限： Z = 2e2KN[1 + Nexp (−2K)4 + 2Nexp (−2K)6 + (4N + (N − 5)N)exp (−2K)8⋯]\n\n对偶\n至此我们已经发现对于正方格点上的二维Ising模型,\n高温理论的形式与低温理论一致。我们可以在热力学极限下计算自由能 $$\nF=-\\frac{\\ln Z}{N}=-\\ln 2-2 \\ln \\cosh K-g(\\tanh K)=-2 K-g(\\exp (-2 K))\n$$\n后面两项分别是高温展开的自由能与低温展开的自由能。其中 g(x) = ln (1 + Nx4 + 2Nx6⋯)/N.\n我们知道 2 维Ising模型只有两相, 也就是自由能有且只有一个奇异点。也就是\ng(x)\n有且只有一个奇异点。对于上面两个表达式, 奇异点对应的 Kc\n一定相同.那就意味着 $$\n\\begin{aligned}\n\\tanh K_c &amp; =\\exp \\left(-2 K_c\\right) \\\\\n\\exp \\left(4 K_c\\right)-2 \\exp \\left(2 K_c\\right)-1 &amp; =0 \\\\\nK_c &amp; =\\frac{\\ln (1+\\sqrt{2})}{2} \\approx 0.4407\n\\end{aligned}\n$$\ndual lattice\n\n\ndual lattice\n\n上图实心格点表示原晶格，然后在原格点围城的最小面积上，构造一个新的格点，用空心原点表示，代表对偶晶格。\n在几何上将原晶格和对偶晶格联系起来，如下图所示，其中格点内的正负代表原晶格，如果反平行边线用实线条连接，平行则不连接。这样便可以把格点转化为图进行研究。\n\n\ndual lattice\n\nSelf-duality\n高温展开与低温展开在无限项的情况下是严格的，因此其对应的相应该有相同的关系。利用自对偶的性质求解相变温度。\n","categories":["Physics"],"tags":["Potts Model"]},{"title":"A Unified Variational Framework for Quantum Excited States","url":"/2025/05/16/Phys/Unified_Variational_Framework/UVF/","content":"提出一种通过最小化交叠矩阵逆的乘积，寻找多体波函数基态的算法。\nLink: * A Unified\nVariational Framework for Quantum Excited States * Spectral Inference Networks:\nUnifying Deep and Spectral Learning * The Geometry\nof Algorithms with Orthogonality Constraints * Accurate\ncomputation of quantum excited states with neural networks\n\nBackground\n从最初的牛顿迭代法出发，首先在1998年提出一种基于矩阵本征值的迭代方法，然后deepmind团队拓展该方法，用于求解薛定谔方程。\n众说周知，牛顿梯度下降法是结合梯度信息求解优化问题的开篇之作，之后为了克服阻措并且应用于大规模优化提出随机梯度下降以及之后动量的梯度下降，以及为在数值求解微分方程中提升准确度提出龙革-库塔方法。那么，新的方法是为了处理什么困难，是基于什么样的物理含义？\n新的算法作用于 stiefel 和 grassmann\nmanifolds，对于一个有约束的优化问题，将解空间去除约束部分，则得到这两种流形。用以处理最小化F(Y)问题，其中存在约束条件YY−1 = I，假设有F(Y) = F(YQ)则对应为Grassmann\nmanifold，否则为 Stiefel\nmanifold。修改的出发点是将有约束问题转化为无约束问题，进行处理。\n\n整体流程为首先初始化选取初始点，然后通过计算梯度，逐渐更新逼近最小值。切向量Δ通过YTΔ + ΔTY = 0定义，对于法向量通过最小化任意切向量的内积寻找min Tr(Δ1TΔ2)。在文章中有很多的内容，用于具体说明计算法向量的方法。\n \n接下来将本质值作为求解目标。 $$\\begin{align}\n&amp;\\max_\\mathbf u \\mathbf u^T \\mathbf A \\mathbf u,\\quad \\mathbf u^T\n\\mathbf u =1 \\\\\n&amp;\\max_\\mathbf u \\frac{\\mathbf u^T \\mathbf A \\mathbf u}{\\mathbf u^T\n\\mathbf u}\n\\end{align}$$\n本征向量的集合U = (u1, u2, u3⋯uN)，对应最大特征值的特征向量为：\n$$\\begin{align}\n&amp; \\mathbf u_i = \\arg \\max_\\mathbf u \\frac{\\mathbf u^T \\mathbf A\n\\mathbf u}{\\mathbf u^T \\mathbf u} \\\\\n&amp; \\max_\\mathbf U \\text{Tr}\\left((\\mathbf U^T \\mathbf U)^{-1}\\mathbf\nU^T \\mathbf A \\mathbf U\\right) \\\\\n\\end{align}$$\n展开写为： $$\\begin{align}\n\\operatorname*{max}_{\\mathbf{U}}\\operatorname{Tr}\\left(\\left(\\sum_{i}\\mathbf{u}^{i\nT}\\mathbf{u}^{i}\\right)^{-1}\\sum_{i j}A_{i j}\\mathbf{u}^{i\nT}\\mathbf{u}^{j}\\right)\n\\end{align}$$\n在特征向量中，其中操作为内积，拓展到特征函数，需要引入核函数$\\langle f,g\\rangle\\stackrel{\\cdot}{=}\\int\nf(\\mathbf{x})g(\\mathbf{x})p(\\mathbf{x})d\\mathbf{x}\\,=\\,\\mathbb{E}_{\\mathbf{x}\\sim\np(\\mathbf{x})}\\dot{[f(\\mathbf{x})g(\\mathbf{x})]}$，构造对称操作线性函数𝒦[f](x) = 𝔼x′[k(x, x′)f(x′)]：\n$$\\begin{align}\n\\operatorname*{max}_{\\mathbf{u}}\\operatorname{Tr}\\left(\\mathbb{E}_{\\mathbf{x}}\\left[\\mathbf{u}(\\mathbf{x})\\mathbf{u}(\\mathbf{x})^{T}\\right]^{-1}\\mathbb{E}_{\\mathbf{x},\\mathbf{x}^{\\prime}}\\left[k(\\mathbf{x},\\mathbf{x}^{\\prime})\\mathbf{u}(\\mathbf{x})\\mathbf{u}(\\mathbf{x}^{\\prime})^{T}\\right]\\right)\n\\end{align}$$\n其中k(x, x′)是定义的核函数。\nMethod\n从Ns个非正交态{|ψi(θi)⟩}的集合中，最小化L = Tr(S−1H)，其中θi是变分参数，\n$$\\begin{align}\n&amp;{\\bf S}_{i\nj}(\\vec{\\theta})=\\langle\\psi_{i}(\\vec{\\theta}_{i})|\\psi_{j}(\\vec{\\theta}_{j})\\rangle,\\\\\n&amp;{\\bf H}_{i\nj}(\\vec{\\theta})=\\langle\\psi_{i}(\\vec{\\theta}_{i})|H|\\psi_{j}(\\vec{\\theta}_{j})\\rangle\n\\end{align}$$\n\n工作流程如上图片，通过张量矩阵乘积态表示波函数，然后计算overlap\nmatrix和hamilitonian matrix，通过优化算法计算函数的损失。\n","categories":["Physics"],"tags":["Variational","Optimize"]},{"title":"Analytic and Algorithmic Solution of Random Satisfiability Problems","url":"/2024/07/09/Phys/science_3831989/RSP/","content":"Parisi关于组合优化问题的分析。\nreference: * Analytic\nand Algorithmic Solution of Random Satisfiability Problems\n\n关于组合优化问题关心两类求解算法、理论分析，第二类理论分析具体为一类组合优化问题在不同实例的情况下，有哪些共性特征。\n考虑热力学极限α = M/N，其中N是变量数，M是子句数目，其中α是一个恒定值。将其转化为统计物理问题，N个布尔变量用二值s表示，每个子句a包含k个变量（K-SAT问题）即k个自旋相互作用，相互作用强度J ∈ {−1, 1}通过子句中的¬决定，将所有子句进行加和：\n$$\\begin{align}\nH=\\sum_a \\prod_k \\frac{1+J_a s_k}{2^k}\n\\end{align}$$\n最终H的值表示违反的关系的个数，当全部满足的时候H = 0。定义零温下的自由能关系：\nexp (−NyΦ(y)) = ∫𝕕wexp (N[Σ(e) − ye])\n其中e表示自由能，Σ为对应自由能量的熵。为了计算Φ，使用空腔的方法。\n$\\begin{aligned}\n\\min _{s_2, \\ldots, s_K}\\left(H-\\frac{1}{2} \\sum_{j=2}^K h_j s_j\\right)\n=-\\frac{1}{2}\\left[a_J\\left(h_2, \\ldots, h_K\\right)+s_1 u_J\\left(h_2,\n\\ldots, h_K\\right)\\right]\n\\end{aligned}$\n 上图为表示空腔的因子图。\n\n\nphase diagram\n\n相图可以用如上的结果表示，红线代表平均每个变量不满足的几率；绿线代表遍历性破缺线条；蓝线表示解的熵线。\n","categories":["Physics"],"tags":["Spin Glass","Combinatorial Optimization Methods","Boltzmann Machine","Replica Method","Replica Symmetry Breaking"]},{"title":"Replica in Double Decent","url":"/2025/09/17/Phys/replica_double_decent/note/","content":"使用副本方法研究神经网络训练中双下降（doube decent）现象。\nReference: * 作业题目\n\n问题\n给定一个数据集 D = {xμ, yμ}μ = 1P，其中\nxμ ∈ ℝN，每个元素服从高斯分布\n𝒩(0, 1)。标签 yμ\n由下式产生：\n$$\ny^\\mu = \\frac{1}{\\sqrt{N}} \\sum_{i=1}^N w_i^* x_i^\\mu + \\sigma\n\\epsilon^\\mu\n$$\n其中 ϵμ ∼ 𝒩(0, 1)，真实权重满足\n$|\\bf{w}^*|^2 = N$。\n考虑如下哈密顿量：\n$$\nH(w) = \\frac{1}{2\\lambda} \\sum_{\\mu=1}^P \\Big( \\sum_{i=1}^N \\frac{w_i\nx_i^\\mu}{\\sqrt N} - y^\\mu \\Big)^2 + \\frac{1}{2} \\sum_{i=1}^N w_i^2\n$$\n其中w为学习到的参数，w*为目标参数（最优超参），这是一个\nteacher-student 模型。\n研究任务：\n\n用复本理论计算泛化误差：\n\n$$\nE_g = \\Big\\lang \\Big( \\frac{1}{\\sqrt{N}} \\sum_{i=1}^N (w_i - w_i^*)\nx_i^\\mu \\Big)^2 \\Big\\rangle_x\n$$\n并绘制 Eg 与 α = P/N\n的关系，考察不同 σ, λ, β\n情况。同时比较有限 N\n数值实验结果与理论是否一致。\n\n在低温极限下，当 λ = 0，研究零噪声与有限噪声情形下\nEg 与\nα 的关系。\n（进阶）分析是否能得到 Eg 随 α 的解析关系？自由能对 α\n的导数是否出现不连续（一级相变）？是否能观测到双下降现象？\n\n副本计算\n$$\nP = \\frac{H(\\bf{w})}{Z}\\quad Z=\\int d \\bf{w} \\exp\\{-\\beta H(\\bf{w})\\}\n$$\n并且有： $$\nf = \\frac{-1}{\\beta N}\\lang\\ln Z\\rang\n$$\n利用副本技巧： $$\nf = \\lim_{N\\to \\infin, n\\to \\infin}\\frac{-1}{\\beta N n}\\lang\\ln Z^n\\rang\n= \\lim_{N\\to \\infin, n\\to \\infin}\\frac{-1}{\\beta N n}\\ln\\lang Z^n\\rang\n$$\n计算配分函数的副本平均：\n$$\n\\begin{align*}\n\\lang Z^n \\rang &amp;= \\left\\lang\n    \\int \\prod_{a}^n\\prod_i^N d w^a_i \\exp\\{-\\beta H(\\bf{w})\\}\n    \\right\\rang \\\\\n&amp;= \\left\\lang\n\\int \\prod_{a}^n\\prod_i^N d w^a_i \\exp\\left\\{\\frac{-\\beta}{2\\lambda}\n\\sum_{\\mu=1}^P \\Big( \\sum_{i=1}^N \\frac{w_i^a x_i^\\mu}{\\sqrt N} - y^\\mu\n\\Big)^2 - \\frac{\\beta}{2} \\sum_{i=1}^N {w_i^a}^2\\right\\}\n\\right\\rang \\\\\n&amp;= \\left\\lang\n\\int \\prod_{a}^n\\prod_i^N d w^a_i \\exp\\left\\{\\frac{-\\beta}{2\\lambda}\n\\sum_{\\mu=1}^P \\Big( \\sum_{i=1}^N \\frac{w_i^a x_i^\\mu}{\\sqrt N} -\n\\frac{1}{\\sqrt{N}} \\sum_{i=1}^N w_i^* x_i^\\mu - \\sigma \\epsilon^\\mu\n\\Big)^2 - \\frac{\\beta}{2} \\sum_{i=1}^N {w_i^a}^2\\right\\}\n\\right\\rang \\\\\n&amp;= \\left\\lang\n\\int \\exp\\left\\{\\frac{-\\beta}{2\\lambda} \\sum_{a}^{n}\\sum_{\\mu=1}^P \\Big(\n\\sum_{i=1}^N \\frac{w_i^a x_i^\\mu}{\\sqrt N} - \\frac{1}{\\sqrt{N}}\n\\sum_{i=1}^N w_i^* x_i^\\mu - \\sigma \\epsilon^\\mu \\Big)^2 -\n\\frac{\\beta}{2} \\sum_{a}^{n}\\sum_{i=1}^N {w_i^a}^2\\right\\}\n\\left(\\prod_{a}^n\\prod_i^N d w^a_i \\right)\n\\right\\rang\n\\end{align*}\n$$\n数据分布变为隐藏层分布\n将对整体的期望，写为对于指数的期望： $$\n\\begin{align}\n\\lang Z^n \\rang = \\int \\exp N\\left\\{-\\alpha G_E - \\frac{\\beta}{2 N}\n\\sum_{a}^{n}\\sum_{i=1}^N {w_i^a}^2\\right\\} \\prod_{a}^n\\prod_i^N d w^a_i\n\\end{align}\n$$\n对于数据的期望，其中对于P的求和，可以认为是独立同分布，因此可以直接将求和符号去掉P = αN，可以得到：\n$$\n\\begin{align}\nG_E = -\\ln \\left\\lang\\exp \\left\\{\n    \\frac{-\\beta}{2\\lambda} \\sum_{a}^{n} \\Big( \\sum_{i=1}^N \\frac{w_i^a\nx_i^\\mu}{\\sqrt N} - \\frac{1}{\\sqrt{N}} \\sum_{i=1}^N w_i^* x_i^\\mu -\n\\sigma \\epsilon^\\mu \\Big)^2\n\\right\\}\\right\\rang\n\\end{align}\n$$\n接下来引入局域场： $$\\begin{align}\nv^a &amp;= \\sum_{i=1}^N \\frac{w_i^a x_i^\\mu}{\\sqrt N} \\\\\nu &amp;= \\sum_{i=1}^N \\frac{w_i^* x_i^\\mu}{\\sqrt N}\n\\end{align}$$\n由于xi ∼ 𝒩(0, 1)，任意高斯向量的线性变换仍然是高斯向量，可以得到局域场联合分布的协方差：\n(u, {va}) ∼ 𝒩(0, Σ),  Σuu = 1, Σuva = ra, Σvavb = qab\n其中r和q为序参量： $$\\begin{align}\nr^a &amp;= \\sum_{i=1}^N \\frac{w_i^a w_i^*}{ N} \\\\\nq^{ab} &amp;= \\sum_{i=1}^N \\frac{w_i^a w_i^b}{N}\n\\end{align}$$\n可以将配分函数进一步写为： $$\n\\begin{align*}\n\\lang Z^n \\rang &amp;= \\int \\exp \\left\\{ N\\left(-\\alpha G_E -\n\\frac{\\beta}{2 } \\sum_{a}^{n} q^{aa}\\right)\\right\\} \\\n\\prod_{a\\leq b}^n\\delta(N q^{ab}-\\sum_i^N w_i^a w_i^b) \\\n\\prod_{a=1}^n \\delta(Nr^a -\\sum_i^N w_i^a w_i^*)\\\nd N r^a d N q^{a b}\\prod_i^N d w_i^a \\\\\n&amp;= \\int \\exp \\left\\{ N\\left(-\\alpha G_E - \\frac{\\beta}{2 }\n\\sum_{a}^{n} q^{aa}\\right)\\right\\} \\\n\\prod_{a\\leq b}^n\\left(\\frac{1}{2\\pi i}\\int d\\hat q^{ab}\\\n\\exp\\Big[-N\\hat q^{ab} q^{ab}+\\hat q^{ab}\\sum_i\nw_i^{(a)}w_i^{(b)}\\Big]\\right) \\\n\\prod_{a=1}^n \\left(\\frac{1}{2\\pi i}\\int d\\hat r_a\\ \\exp\\!\\Big[-N\\hat\nr_a r_a+\\hat r_a \\sum_i w_i^* w_i^{(a)}\\Big]\\right)\\\nd N r^a d N q^{a b}\\prod_i^N d w_i^a \\\\\n&amp;=\\int \\left(\\prod_a^n \\frac{N d r^a d \\hat r^a}{2\\pi i} \\right)\n\\left(\\prod_{a\\leq b}^n \\frac{N d q^{ab} d \\hat q^{ab}}{2\\pi i} \\right)\n\\\n\\exp \\left\\{ -\\alpha N G_E\\right\\} \\\\\n&amp;\\quad \\int\\prod_{i,a}^{N,n} d w_i^a\\exp \\left\\{ N\\left(\n    - \\frac{\\beta}{2 } \\sum_{a}^{n} q^{aa}\\\n    - \\hat q^{ab} q^{ab}+\\frac{1}{N}\\hat q^{ab}\\sum_i w_i^{a}w_i^{b} \\\n    -\\hat r_a r_a+\\frac{1}{N}\\hat r_a \\sum_i w_i^* w_i^{a}\n\\right)\\right\\} \\\\\n&amp;=\\int \\left(\\prod_a^n \\frac{N d r^a d \\hat r^a}{2\\pi i} \\right)\n\\left(\\prod_{a\\leq b}^n \\frac{N d q^{ab} d \\hat q^{ab}}{2\\pi i} \\right)\n\\\n\\exp \\left\\{ -\\alpha N G_E\\right\\} \\\\\n&amp;\\quad \\exp \\left\\{ N\\left(\n    - \\frac{\\beta}{2 } \\sum_{a}^{n} q^{aa}\\\n    - \\hat q^{ab} q^{ab} \\\n    -\\hat r_a r_a\n\\right)\\right\\} \\\\\n&amp;\\quad \\int\\prod_{i,a}^{N,n} d w_i^a\\exp \\left\\{ N\\left(\n    \\frac{1}{N}\\hat q^{ab}\\sum_i w_i^{a}w_i^{b} \\\n    +\\frac{1}{N}\\hat r_a \\sum_i w_i^* w_i^{a}\n\\right)\\right\\} \\\\\n&amp;=\\int \\left(\\prod_a^n \\frac{N d r^a d \\hat r^a}{2\\pi i} \\right)\n\\left(\\prod_{a\\leq b}^n \\frac{N d q^{ab} d \\hat q^{ab}}{2\\pi i} \\right)\n\\exp \\left\\{ N\\left(-\\alpha G_E+G_S\\right)\\right\\}\n\\end{align*}\n$$\n其中有： $$\n\\begin{align*}\nG_E &amp;= -\\ln \\left\\lang\\exp \\left\\{\n    \\frac{-\\beta}{2\\lambda} \\sum_{a}^{n} \\Big( \\sum_{i=1}^N \\frac{w_i^a\nx_i^\\mu}{\\sqrt N} - \\frac{1}{\\sqrt{N}} \\sum_{i=1}^N w_i^* x_i^\\mu -\n\\sigma \\epsilon^\\mu \\Big)^2\n\\right\\}\\right\\rang \\\\\n&amp;= -\\ln \\left\\lang\\exp \\left\\{\n    \\frac{-\\beta}{2\\lambda} \\sum_{a}^{n} \\Big( v^a - u - \\sigma \\epsilon\n\\Big)^2\n\\right\\}\\right\\rang\n\\end{align*}\n$$ 以及： $$\n\\begin{align*}\nG_S &amp;= \\left(\n    - \\frac{\\beta}{2 } \\sum_{a}^{n} q^{aa}\\\n    - \\sum_{a\\leq b}^n\\hat q^{ab} q^{ab} \\\n    - \\sum_a^n\\hat r_a r_a\n\\right) \\\n+\\frac{1}{N}\\ln\\int\\prod_{i,a}^{N,n} d w_i^a\\exp \\left\\{  \n    \\hat q^{ab}\\sum_i w_i^{a}w_i^{b} \\\n    +\\hat r_a \\sum_i w_i^* w_i^{a}\n\\right\\} \\\\\n\\end{align*}\n$$\n目前为止整体计算时严格的，成功将输入数据x通过线性变换与权重w相耦合，产生新的序参量u、v。由于为线性变换，且知道x的分布情况，因此可以将u、v的联合分布写出来。同时产生必要的方差项，也称其为overlap项，在我看来就是将两个矩阵进行交叠，衡量矩阵交叠程度（即矩阵相似性）。\n然后通过将δ转变为高斯积分，将积分测度进行修改。\n接下来采用副本对称假设，将求解目标近似： $$\\begin{align}\nr^a = r&amp;,\\quad \\hat r^a = \\hat r\\\\\nq^{ab} = \\delta_{ab}q'+(1-\\delta_{ab})q&amp;,\\quad \\hat\nq^{ab}=\\delta_{ab}(-\\frac{1}{2}\\hat q')+(1-\\delta_{ab})\\hat q\n\\end{align}$$\n接下来结合副本技巧逐个求解GS与GE项。\n熵项GS\n$$\n\\begin{align*}\nG_S &amp;= \\left(\n    - \\frac{\\beta}{2 } \\sum_{a}^{n} q^{aa}\\\n    - \\sum_{a\\leq b}^n\\hat q^{ab} q^{ab} \\\n    - \\sum_a^n\\hat r_a r_a\n\\right) \\\n+\\frac{1}{N}\\ln\\int\\prod_{i,a}^{N,n} d w_i^a\\exp \\left\\{  \n    \\hat q^{ab}\\sum_i w_i^{a}w_i^{b} \\\n    +\\hat r_a \\sum_i w_i^* w_i^{a}\n\\right\\} \\\\\n&amp;= \\left(\n    - \\frac{n \\beta}{2 } q'\\\n    - \\frac{n(n-1)}{2}\\hat q q \\\n    + \\frac{n}{2}\\hat q' q'\n    - n \\hat r r\n\\right) \\\n+\\frac{1}{N}\\ln\\int\\prod_{i,a}^{N,n} d w_i^a\\exp \\left\\{  \n    \\frac{1}{2}\\hat q\\sum_{ab}\\sum_i w_i^{a}w_i^{b} \\\n    -\\frac{1}{2}(\\hat q'+\\hat q)\\sum_a \\sum_i w_i^{a}w_i^{a} \\\n    +\\hat r \\sum_a\\sum_i w_i^* w_i^{a}\n\\right\\} \\\\\n&amp;= \\left(\n    - \\frac{n \\beta}{2 } q'\\\n    - \\frac{n(n-1)}{2}\\hat q q \\\n    + \\frac{n}{2}\\hat q' q'\n    - n \\hat r r\n\\right) \\\n+\\frac{1}{N}\\ln\\int\\prod_{i,a}^{N,n} d w_i^a\\exp \\left\\{  \n    \\frac{1}{2}\\hat q\\sum_i \\left(\\sum_{a}w_i^{a}\\right)^2 \\\n    -\\frac{1}{2}(\\hat q'+\\hat q)\\sum_a \\sum_i w_i^{a}w_i^{a} \\\n    +\\hat r \\sum_a\\sum_i w_i^* w_i^{a}\n\\right\\} \\\\\n&amp;= \\left(\n    - \\frac{n \\beta}{2 } q'\\\n    - \\frac{n(n-1)}{2}\\hat q q \\\n    + \\frac{n}{2}\\hat q' q'\n    - n \\hat r r\n\\right) \\\n+\\frac{1}{N}\\ln\\int\\prod_i D z_i\\int\\prod_{a}^{n} d w_i^a\\exp \\left\\{  \n    \\sqrt{\\hat q}\\sum_i \\sum_{a}w_i^{a}z_i \\\n    -\\frac{1}{2}(\\hat q'+\\hat q)\\sum_a \\sum_i w_i^{a}w_i^{a} \\\n    +\\hat r \\sum_a\\sum_i w_i^* w_i^{a}\n\\right\\} \\\\\n&amp;= \\left(\n    - \\frac{n \\beta}{2 } q'\\\n    - \\frac{n(n-1)}{2}\\hat q q \\\n    + \\frac{n}{2}\\hat q' q'\n    - n \\hat r r\n\\right) \\\n+\\frac{1}{N}\\ln \\left[\\int D z \\left[\\int d w\\exp \\left\\{  \n    \\sqrt{\\hat q} w z \\\n    -\\frac{1}{2}(\\hat q'+\\hat q)  w w \\\n    +\\hat r  w^* w\n\\right\\} \\right]^n\\right]^{N}\\\\\n&amp;= \\left(\n    - \\frac{n \\beta}{2 } q'\\\n    - \\frac{n(n-1)}{2}\\hat q q \\\n    + \\frac{n}{2}\\hat q' q'\n    - n \\hat r r\n\\right) \\\n+\\ln \\int D z \\left[\\int d w\\exp \\left\\{  \n    \\sqrt{\\hat q} w z \\\n    -\\frac{1}{2}(\\hat q'+\\hat q)  w w \\\n    +\\hat r  w^* w\n\\right\\} \\right]^n\\\\\n\\end{align*}\n$$\n上面最后一步通过引入辅助变量，将平方项变为线性项，从而把副本的数量n之间的耦合消去。由于假设lim N → ∞，因此可以将⟪zn⟫ ∼ N(−αGE + GS)，从而可以分别求GS与GE的极限。\n$$\n\\begin{align*}\n\\lim_{n\\to 0}\\frac{G_S}{n} &amp;= \\left(\n    - \\frac{\\beta}{2 } q'\\\n    + \\frac{1}{2}\\hat q q \\\n    + \\frac{1}{2}\\hat q' q'\n    - \\hat r r\n\\right)\\\n+\\lim_{n\\to 0}\\frac{1}{n}\\ln \\int D z \\left[\\int d w\\exp \\left\\{  \n    \\sqrt{\\hat q} w z \\\n    -\\frac{1}{2}(\\hat q'+\\hat q)  w w \\\n    +\\hat r  w^* w\n\\right\\} \\right]^n\\\\\n&amp;= \\left(\n    - \\frac{\\beta}{2 } q'\\\n    + \\frac{1}{2}\\hat q q \\\n    + \\frac{1}{2}\\hat q' q'\n    - \\hat r r\n\\right)\\\n+\\int D z \\ln\\int d w\\exp \\left\\{  \n    \\sqrt{\\hat q} w z \\\n    -\\frac{1}{2}(\\hat q'+\\hat q)  w w \\\n    +\\hat r  w^* w\n\\right\\}\\\\\n&amp;=  - \\frac{\\beta}{2 } q'\\\n    + \\frac{1}{2}\\hat q q \\\n    + \\frac{1}{2}\\hat q' q'\n    - \\hat r r\n+\\frac{1}{2}\\ln{2\\pi}-\\frac{1}{2}\\ln(\\hat q+\\hat q')+\\frac{\\hat q+\\hat\nr^2 {w^*}^2}{2(\\hat q+\\hat q')}\\\\\n\\end{align*}\n$$\n由于约束$|\\bf{w}^*|^2 = N$，而$\\bf w$为一个N维向量，因此平均下w*2 = 1。\n$$\n\\begin{align*}\n\\lim_{n\\to 0}\\frac{G_S}{n} &amp;=  - \\frac{\\beta}{2 } q'\\\n    + \\frac{1}{2}\\hat q q \\\n    + \\frac{1}{2}\\hat q' q'\n    - \\hat r r\n+\\frac{1}{2}\\ln{2\\pi}-\\frac{1}{2}\\ln(\\hat q+\\hat q')+\\frac{\\hat q+\\hat\nr^2}{2(\\hat q+\\hat q')}\\\\\n\\end{align*}\n$$\n能量项GE\n$$\n\\begin{align*}\nG_E &amp;= -\\ln \\left\\lang\\exp \\left\\{\n    \\frac{-\\beta}{2\\lambda} \\sum_{a}^{n} \\Big( v^a - u - \\sigma \\epsilon\n\\Big)^2\n\\right\\}\\right\\rang\n\\end{align*}\n$$\n其中期望是对输入数据x进行，并且x符合一个特定分布，在经过线性变换之后我们将其转化为v、u之间的组合。因为高斯分布在经过线性变化之后依旧是高斯分布，接下来期望就是计算u、v。\n已经知道分布为: (u, {va}) ∼ 𝒩(0, Σ),  Σuu = 1, Σuva = r, Σvavb = δabq′ + (1 − δab)q\n计算混合高斯分布的条件分布，由高斯条件分布公式得到： 𝔼[va | u] = r u,   Cov(v | u) = C = (q’ − q) In + (q − r2) 11⊤\n其中 1 = (1, …, 1)⊤ ∈ ℝn。\n记 c ≡ u − σϵ。则\n$\\sum_{a=1}^n (u-v_a-\\sigma\\epsilon)^2 \\;=\\;\n\\|\\;v - c\\,\\mathbf 1\\;\\|_2^2$， 在给定 u, ϵ 下，v − c1 ∼ 𝒩 ((ru − c)1, C)。\n高斯二次型的矩母函数给出（对固定 u, ϵ）： $$\\mathbb\nE\\!\\left[\\exp\\!\\left(-\\frac{\\beta}{2\\lambda}\\|v-c\\mathbf\n1\\|^2\\right)\\Big|\\,u,\\epsilon\\right]\n= \\det\\!\\big(I_n+\\tfrac{\\beta}{\\lambda}C\\big)^{-1/2}\\;\n\\exp\\!\\left(-\\frac{\\beta}{2\\lambda}(r u-c)^2\\,\\mathbf\n1^\\top(I_n+\\tfrac{\\beta}{\\lambda}C)^{-1}\\mathbf 1\\right)$$\n利用 C 的“秩一更新”谱分解\nC = (q’ − q)In + (q − r2)11⊤\n的特征值： λ⟂ = q’ − q  (重数\nn − 1),   λ∥ = q’ − q + n(q − r2)\n因此 $$\\begin{align*}\n&amp;\\det(I_n+\\tfrac{\\beta}{\\lambda}C)=\\big(1+\\tfrac{\\beta}{\\lambda}(q'-q)\\big)^{n-1}\\!\\big(1+\\tfrac{\\beta}{\\lambda}\\lambda_\\parallel\\big)\\\\\n&amp;\\mathbf 1^\\top(I_n+\\tfrac{\\beta}{\\lambda}C)^{-1}\\mathbf 1\n=\\frac{n}{\\,1+\\tfrac{\\beta}{\\lambda}\\lambda_\\parallel\\,}\n\\end{align*}$$\n把 c = u − σϵ、(ru − c) = (r − 1)u + σϵ\n代回得： $$\\begin{aligned}\n&amp;\\mathbb E\\!\\left[\\exp\\!\\left(-\\frac{\\beta}{2\\lambda}\\sum_a\n(u-v_a-\\sigma\\epsilon)^2\\right)\\Big|u,\\epsilon\\right]\\\\\n&amp;\\quad=\\Big(1+\\tfrac{\\beta}{\\lambda}(q'-q)\\Big)^{-\\frac{n-1}{2}}\n\\Big(1+\\tfrac{\\beta}{\\lambda}\\big(q'-q+n(q-r^2)\\big)\\Big)^{-\\frac{1}{2}}\n\\\\ &amp;\\qquad\\times\n\\exp\\!\\left(-\\frac{\\beta}{2\\lambda}\\,\\frac{n\\,\\big((r-1)u+\\sigma\\epsilon\\big)^2}{\\,1+\\tfrac{\\beta}{\\lambda}\\big(q'-q+n(q-r^2)\\big)\\,}\\right).\n\\end{aligned}$$\n再对 u, ϵ\n做平均并取 n → 0\nu, ϵ\n独立标准高斯，(r − 1)u + σϵ ∼ 𝒩(0, (r − 1)2 + σ2)。用\n$$\\mathbb\nE\\big[e^{-\\frac{a}{2}Z^2}\\big]=(1+a)^{-1/2}\\quad (Z\\sim\\mathcal\nN(0,1))$$\n并只保留 O(n)\n项（因为最后要计算 limn → 0GE/n），记\n$$A\\equiv\n1+\\frac{\\beta}{\\lambda}(q'-q)=\\frac{\\lambda+\\beta(q'-q)}{\\lambda}$$\n则 $$\\lim_{n\\to 0}\\frac{G_E}{n}\n=\\frac{1}{2}\\ln A\n+\\frac{1}{2}\\frac{\\beta}{\\lambda\nA}\\Big[q-2r+1+\\sigma^2\\Big]$$\n把 ln A = ln (λ + β(q′ − q)) − ln λ\n展开，并注意 λA = λ + β(q′ − q)，得到：\n$$\\lim_{n\\to 0}\\frac{G_E}{n}\n=\\frac{1}{2}\\ln\\!\\big[\\lambda+\\beta(q’-q)\\big]-\\frac{1}{2}\\ln\\lambda\n+\\frac{1}{2}\\,\\frac{\\beta\\,(q-2r+1+\\sigma^2)}{\\lambda+\\beta(q’-q)}$$\n更为简洁的做法\n核心观念：对 Y = (u − v1 − σϵ, …, u − vn − σϵ)⊤\n有 $$\\mathbb\nE\\!\\left[e^{-\\frac{\\beta}{2\\lambda}\\|Y\\|^2}\\right]\n=\\det\\!\\Big(I_n+\\tfrac{\\beta}{\\lambda}\\,\\mathrm{Cov}(Y)\\Big)^{-1/2}$$\n而 Cov(Y) = a In + b 11⊤,  a = q’ − q,  b = 1 − 2r + σ2 + q\n这种“aI + b11⊤”矩阵的特征值是：a（重数 n-1）与 a + bn（沿 1 方向）。于是 $$G_E=\\tfrac12\\ln\\det\\!\\Big(I+\\tfrac{\\beta}{\\lambda}\\mathrm{Cov}(Y)\\Big)\n=\\tfrac12\\Big[(n-1)\\ln\\!\\big(1+\\tfrac{\\beta}{\\lambda}a\\big)\n+\\ln\\!\\big(1+\\tfrac{\\beta}{\\lambda}(a+bn)\\big)\\Big]$$\n纯标量的函数；现在对它做 n → 0，利用 Mathematica 计算:\n$Assumptions = &#123;beta &gt; 0, lambda &gt; 0, sigma &gt;= 0,   qPrime &gt;= q, r ∈ Reals, q ∈ Reals&#125;;a = qPrime - q;b = 1 - 2 r + sigma^2 + q;GE = 1/2 * ((n - 1) * Log[1 + beta/lambda * a]       + Log[1 + beta/lambda * (a + b * n)]);Limit[GE/n, n -&gt; 0, Assumptions -&gt; $Assumptions] // FullSimplify\n得到一致的结果： $$\\frac{1}{2}\\ln\\!\\big[\\lambda+\\beta(q’-q)\\big]-\\frac{1}{2}\\ln\\lambda\n+\\frac{1}{2}\\,\\frac{\\beta\\,(q-2r+1+\\sigma^2)}{\\lambda+\\beta(q’-q)}$$\n鞍点方程\n(* 参数假设 *)$Assumptions = &#123;alpha &gt; 0, beta &gt; 0, lambda &gt; 0, sigma &gt;= 0,    r ∈ Reals, q ∈ Reals, qPrime ∈ Reals,    rHat ∈ Reals, qHat ∈ Reals, qHatPrime ∈ Reals&#125;;(* 能量项 GE/n *)GEoverN = 1/2 (Log[lambda + beta (qPrime - q)] - Log[lambda]) +    1/2 beta (q - 2 r + 1 + sigma^2)/(lambda + beta (qPrime - q));(* 熵项 GS/n *)GSoverN = -r rHat + 1/2 q qHat + 1/2 qPrime qHatPrime - (beta/2) qPrime +    1/2 Log[2 Pi] - 1/2 Log[qHat + qHatPrime] +    (qHat + rHat^2)/(2 (qHat + qHatPrime));(* 总的自由能 *)Phi = -alpha GEoverN + GSoverN // Simplify;(* 对 hat 变量的鞍点条件 *)eqsHat = Thread[D[Phi, #] == 0 &amp; /@ &#123;rHat, qHat, qHatPrime&#125;];eqsHat2 = Thread[D[Phi, #] == 0 &amp; /@ &#123;r, q, qPrime&#125;];(* 解出 hat 变量 *)sol1 = Solve[eqsHat, &#123;rHat, qHat, qHatPrime&#125;, Reals] // Simplifysol2 = Solve[eqsHat2, &#123;rHat, qHat, qHatPrime&#125;, Reals] // Simplify\n然后将解进行简化 (* 定义两组解 *)sol1 = &#123;   rHat -&gt; -(r/(q - qPrime)),   qHat -&gt; (q - r^2)/(q - qPrime)^2,   qHatPrime -&gt; (-2 q + qPrime + r^2)/(q - qPrime)^2&#125;;sol2 = &#123;   rHat -&gt; (alpha beta)/(lambda - beta q + beta qPrime),   qHat -&gt; (alpha beta^2 (1 + q - 2 r + sigma^2))/(lambda + beta (-q + qPrime))^2,   qHatPrime -&gt; beta + (alpha beta (lambda + beta (-1 - 2 q + qPrime + 2 r - sigma^2)))/(lambda + beta (-q + qPrime))^2&#125;;(* 对比化简：将 sol1 代回鞍点方程，看能否简化为 sol2 *)Simplify[sol1 /. sol2,  Assumptions -&gt; &#123;alpha &gt; 0, beta &gt; 0, lambda &gt; 0, sigma &gt;= 0,    r ∈ Reals, q ∈ Reals, qPrime ∈ Reals&#125;]\n得到迭代方程为： $$\\begin{aligned}\n\\frac{\\alpha \\beta}{\\lambda - \\beta q + \\beta q'} &amp;\\;\\;=\\;\\;\n-\\frac{r}{\\,q - q'} \\, \\\\\n\\frac{\\alpha \\beta^{2}\\,\\big(1 + q - 2r + \\sigma^{2}\\big)}{\\big(\\lambda\n+ \\beta(-q+q')\\big)^{2}} &amp;\\;\\;=\\;\\; \\frac{q - r^{2}}{(q - q')^{2}}\n\\, \\\\\n\\beta + \\frac{\\alpha \\beta \\,\\big(\\lambda + \\beta(-1 - 2q + q' + 2r -\n\\sigma^{2})\\big)}{\\big(\\lambda + \\beta(-q+q')\\big)^{2}} &amp;\\;\\;=\\;\\;\n\\frac{-2q + q' + r^{2}}{(q - q')^{2}}\n\\end{aligned}$$\n先记 Δ ≡ q’ − q。\n\n更新 Δ\n\n由第1式： $$ \\quad\n\\Delta^{\\text{new}}\\;=\\;\\frac{r^{(t)}\\,\\lambda}{\\beta(\\alpha-r^{(t)})}\\  \\tag{U1}$$\n给定 r(t)\n先算 Δnew。\n\n更新 q\n\n把第2式整理为对 q\n的固定点： $${q-r^2}\\;=\\;\\alpha\\Big(\\frac{\\beta\\Delta}{\\lambda+\\beta\\Delta}\\Big)^2\n\\Big(1+q-2r+\\sigma^2\\Big)$$ 定义$K\\;\\equiv\\;\\alpha\\Big(\\frac{\\beta\\Delta}{\\lambda+\\beta\\Delta}\\Big)^2,$可解得\n$$ \\\nq^{\\text{new}}\\;=\\;\\frac{\\,r^{2}+K\\,(1-2r+\\sigma^{2})\\,}{\\,1-K\\,}\\  \\tag{U2}$$\n注意这一步只用到 r, Δ，不需要旧的 q。\n\n更新 q′\n\n最简便的是用 Δ 回填： q′new = qnew + Δnew \n\n一种稳健的循环（带阻尼）\n\n给定初值 r(0) ∈ (0, min {α, 1})，循环：\n$$\\begin{aligned}\n&amp;\\Delta^\\star\\leftarrow\n\\frac{r^{(t)}\\lambda}{\\beta(\\alpha-r^{(t)})},\\quad\nK\\leftarrow\n\\alpha\\Big(\\frac{\\beta\\Delta^\\star}{\\lambda+\\beta\\Delta^\\star}\\Big)^2,\\\\\n&amp;q^\\star\\leftarrow\n\\frac{r^{(t)2}+K(1-2r^{(t)}+\\sigma^2)}{1-K},\\qquad\nq’^\\star\\leftarrow q^\\star+\\Delta^\\star,\\\\\n&amp;\\text{（可选：用第3式的残差 } \\mathcal R(r^{(t)}) \\text{ 调整 }\nr)\\\\\n&amp;r^{(t+1)}\\leftarrow (1-\\eta)\\,r^{(t)}+\\eta\\cdot\n\\frac{\\alpha\\beta\\,\\Delta^\\star}{\\lambda+\\beta\\Delta^\\star}\\quad\n(\\eta\\in(0,1]) .\n\\end{aligned}$$ • 若不想用方程(3)做校正，可以直接用 (U1)\n的左式更新 r（如上），通常加一点阻尼 $$会更稳。 •\n也可以把第3式写成一维残差 g(r) = 0，每步做一次牛顿/割线更新\nr。\n\n用第3式构造一维残差并更新 r（可替代 (U1)）\n\n先用 r 生成 Δ(r), q(r)（按\n(U2) 里的 K 与 (U1) 的 Δ\n公式），再把 $$g(r)\\;\\equiv\\;\\underbrace{\\beta+\\dfrac{\\alpha\\beta\\,[\\lambda+\\beta(-1-q+\\Delta(r)+2r-\\sigma^2)]}{(\\lambda+\\beta\\Delta(r))^2}}_{\\text{LHS\n(3)}}\n\\;-\\;\\underbrace{\\Big(\\frac{r^{2}-q(r)}{\\Delta(r)^2}+\\frac{1}{\\Delta(r)}\\Big)}_{\\text{RHS(3)}}.$$\n做一维根求解： $$ r^{(t+1)} \\;=\\; r^{(t)} -\n\\eta \\,\\frac{g(r^{(t)})}{g’(r^{(t)})}\\ \\ \\text{或}\\ \\\nr^{(t+1)}=r^{(t)}-\\eta\\,\\frac{g(r^{(t)})}{g(r^{(t)})-g(r^{(t-1)})}\\,(r^{(t)}-r^{(t-1)}).$$\n• 第一种是牛顿（需要数导，数值差分即可）； •\n第二种是割线（不需要导数），η ∈ (0, 1] 为阻尼。\n收敛判据：$|r{(t+1)}-r{(t)}|+|q{(t+1)}-q{(t)}|+|q’{(t+1)}-q’{(t)}|&lt;$且\n|g(r(t + 1))| &lt; ε。\n泛化误差\n泛化误差为: $$\\begin{aligned}\nE_g &amp;= \\Big\\lang \\Big( \\frac{1}{\\sqrt{N}} \\sum_{i=1}^N (w_i - w_i^*)\nx_i^\\mu \\Big)^2 \\Big\\rangle_x \\\\\n&amp;= \\Big\\lang (v - u)^2 \\Big\\rangle_x \\\\\n&amp;= \\mathrm{Var}(v)+\\mathrm{Var}(u)-2\\,\\mathrm{Cov}(u,v)\\\\\n&amp;= 1 + q' - 2r\n\\end{aligned}$$\n实验与理论结果\n通过迭代方程，得到双下降图像： \n实验得到，这里有一个tric，epoch一定要大： \n","categories":["Physics"],"tags":["Spin Glass","Replica Method"]},{"title":"Replica","url":"/2022/11/13/Phys/replica/replica/","content":"Reference: * Hopfield模型的统计物理视频\n* Analytic\nand Algorithmic Solution of Random Satisfiability Problems * Gibbs\nstates and the set of solutions of random constraint satisfaction\nproblems\n\nAverage\n淬火平均（quenched average）： $$\\begin{align}\n\\langle\\ln Z\\rangle\n\\end{align}$$\n退火平均（annealed average）: $$\\begin{align}\n\\ln\\langle Z\\rangle\n\\end{align}$$\n首先从数学上来看这两者是不一样的，可以把ln 当成一个凸函数来看待，本质分析的就是先平均再经过凸函数处理，还是先经过凸函数处理然后再平均。通过Jensen不等式有：\n⟨ln Z⟩ ≤ ln ⟨Z⟩\n这两者有什么区别呢？\n对于一个物理量 Q\n，淬火平均表示为： $$\\begin{align}\n\\langle Q \\rangle_{\\text{quenched}} = \\int P(\\{J\\}) \\left[\n\\frac{1}{Z(\\{J\\})} \\sum_{\\{s\\}} Q(\\{s\\}, \\{J\\}) e^{-\\beta H(\\{s\\},\n\\{J\\})} \\right] d\\{J\\}\n\\end{align}$$\n\n{J}：无序变量的集合（如随机耦合）。\nP({J})：无序变量的概率分布。\n{s}：系统的状态（如自旋配置）。\nH({s}, {J})：系统的哈密顿量（能量函数）。\nZ({J})：对固定无序变量的配分函数。\n\n对于一个物理量 Q\n，退火平均表示为： $$\\begin{align}\n\\langle Q \\rangle_{\\text{annealed}} = \\frac{1}{Z_{\\text{annealed}}}\n\\sum_{\\{s\\}, \\{J\\}} Q(\\{s\\}, \\{J\\}) e^{-\\beta H(\\{s\\}, \\{J\\})}\n\\end{align}$$\n\nZannealed：退火平均下的配分函数：\n$$\\begin{align}\nZ_{\\text{annealed}} = \\sum_{\\{s\\}, \\{J\\}} e^{-\\beta H(\\{s\\}, \\{J\\})}\n\\end{align}$$\n\n两者的主要区别在{J}的处理上，对于淬火平均只是选取了其中的几个无序点进行计算，即固定J为特定的值。而退火平均将会考虑所有J的分布组合。以$Z和Z进行区别，其中Z是对所有构型S进行的求和；是对耦合系数J$的平均，对于两种方式这个符号有着不同的含义，淬火平均只会选取其中的一些点进行计算，而退火平均将会计算所有的构型。\n对于铁磁Ising模型，由于J本固定的，因此不会存在上面的讨论的⟨⋅⟩符号的区别。但是对于Hopfield模型，其相互作用是随机连接的，这里存在J变化的问题，因此需要讨论退火与淬火的区别。\n这里有一个猜测，Jensen不等式什么时候取等号，就是对{J}进行平均的时候，由于每一个具体的J存在一个权重，因此可能将ln 计算变成一个线性的计算。想办法证明这个猜测。\n通常对于这两个概念来说，是从演化时间尺度上比较，淬火表示无序的时间尺度远大于动力学的时间尺度，退火表示无序与动力学的时间尺度差不多大。\nReplica Method\n利用数学中的极限有：\n$$\\begin{align}\n\\ln Z=\\lim_{n\\to0}\\frac{Z^n-1}{n}\n\\end{align}$$\n然后计算两边的期望值： $$\\begin{align}\n\\langle\\ln Z\\rangle=\\lim _{n \\rightarrow 0} \\frac{\\left\\langle\nZ^n\\right\\rangle-1}{n}=\\lim _{n \\rightarrow 0} \\frac{\\ln \\left\\langle\nZ^n\\right\\rangle}{n},\n\\end{align}$$\n其中 ⟨⋅⟩ 是 ξ 的无序平均。\n以下证明，以上公式第二个等号成立。首先利用$\\ln z=z-\\frac{z^2}{2}+\\cdots$：\n$$\\begin{align}\n\\langle\\ln Z\\rangle=\\lim _{n \\rightarrow 0} \\frac{n\\langle\\ln\nZ\\rangle}{n}=\\lim _{n \\rightarrow 0} \\frac{\\ln (1+n\\langle\\ln\nZ\\rangle)}{n}\n\\end{align}$$ 因为 Zn ≃ 1 + nln Z + ⋯,\n得到 ⟨Zn⟩ ≃ 1 + n⟨ln Z⟩⋯，故当n是一个小量的时候可以将展开公式从右到左用：\n$$\\begin{align}\n\\lim _{n \\rightarrow 0} \\frac{\\ln (1+n\\langle\\ln Z\\rangle)}{n}=\\lim _{n\n\\rightarrow 0} \\frac{\\ln \\left\\langle Z^n\\right\\rangle}{n}\n\\end{align}$$\n其中 n\n足够小，可以利用展开Zn = enln Z = 1+\nnln Z + ⋯.\n每个自旋的平均值可以写为：\n$$\\begin{align}\nf=\\lim _{n \\rightarrow 0} \\lim _{N \\rightarrow \\infty} \\frac{-\\ln\n\\left\\langle Z^n\\right\\rangle}{\\beta n N} .\n\\end{align}$$\nReplica Symmetry\nand Replica Symmetry Breaking\n在Hopfield Model 相图中已经展示了复本技巧的使用，得到相图：\n\n\ndiagram\n\n在虚线下方将会得到非物理的解，这个现象的发生是因为之前进行的复本对称假设过于简陋，需要使用更高阶的近似——复本对称破缺。\nGeneralized\nFree Energy and Complexity of States\n\n\nfree energy landscape\n\n随着温度的下降，一整个自由能的解，将会分裂为几个部分。每一最小值点对应TAP方程或者信念传播方程的解。为了解开Gibbs\nmeasure中的耦合，需要引入额外的一项刻画自由能的波动，定义为y。有如下的关系：\n$$\\begin{align}\ne^{-y \\Phi}=\\sum_\\alpha e^{-y F_\\alpha}=\\int \\mathrm{d} f e^{N(-y\nf+\\Sigma(f))} \\label{RSB}\n\\end{align}$$\n其中∑(f)是指数多个态的集合体；Φ表示复本（广义）自由能；通过自由能密度fα表示波动。这个式子也被叫做\n1-RSB 。\n自由能表达式$F=-\\frac{1}{\\beta}\\ln\nZ$，可以得到Z = exp [−βF];同时配分函数为Z = ∑Sexp [−βH(S)]。将两项结合有exp [−βF] = Z = ∑Sexp [−βH(S)]。将Φ类比F；α类比S，由此可以得到$\\eqref{RSB}$中第一个等号。\n将自由能写成平均值表达方式Fα = Nfα，其中fα为α构型下的自由能密度，则e−yFα = e−Nyfα。对所有构型求和∑α不能直接写为积分，因为可能出现简并度问题，需要引入额外的简并度参数C(f)：∑αe−yFα = ∫dfC(f)eN(−yf)，将C(f)写在指数上可以得到∫dfeN(−yf + Σ(f))。不难发现Σ(f)是f数量的熵。由此可以得到$\\eqref{RSB}$中第二个等号。\n对于第三项，在热力学极限下，结合 Laplace 近似得到： $$\\begin{align}\n-y \\phi =\\max _f\\{\\Sigma(f)-y f\\} \\label{laplace}\n\\end{align}$$\n求极值点，可知 $y=\\frac{\\partial\n\\Sigma(f)}{\\partial\nf}$，这里已经符合勒让德变化的前提条件了。ϕ表示复本自由能密度（自旋的平均值）。通过勒让德变换，得到如下的关系：\n$$\n\\begin{align}\nf &amp; =\\frac{\\partial(y \\phi)}{\\partial y} \\label{94}\\\\\n\\Sigma &amp; =y(f-\\phi)=y^2 \\frac{\\partial \\phi}{\\partial y} \\label{95}\n\\end{align}\n$$\ny也被称作Parisi参数。\nClaculate Generalized Free\nEnergy\n利用一阶复本对称破缺的空腔方法可以计算ϕ。空腔方法首先是构建因子图，利用功能节点与变量节点表示整个计算目标，然后通过分析功能节点与变量节点增删对整体变化的影响，将整个计算目标表示为功能节点与变量节点的变化点关系。\n首先在因子图上增加一个变量节点，在增加节点前后变化如下：\n$$\n\\begin{align}\ne^{-y \\phi_i^{\\text {new }}} &amp; =\\sum_\\alpha e^{-y F^\\alpha-y \\Delta\nF_i^\\alpha}=e^{-y \\phi^{\\text {old }}} \\sum_\\alpha \\omega(\\alpha) e^{-y\n\\Delta F_i^\\alpha} \\\\\n&amp; =e^{-y \\phi^{\\text {old }}}\\left\\langle e^{-y \\Delta\nF_i}\\right\\rangle\n\\end{align}\n$$ 其中$\\omega(\\alpha)=\\frac{e^{-y\nF^\\alpha}}{\\sum_a e^{-y F^\\alpha}}$，并且⟨⋅⟩表示所有α构型的平均。\n对于增加功能节点有关系式： $$\\begin{align}\ne^{-y \\phi_a^{\\text {new }}}=e^{-y \\phi^{\\mathrm{old}}}\\left\\langle\ne^{-y \\Delta F_a}\\right\\rangle\n\\end{align}$$ 由此复本自由能转变为空腔操作： $$\n\\begin{align}\n&amp; -y \\Delta \\phi_i=\\ln \\left\\langle e^{-y \\Delta F_i}\\right\\rangle\n\\\\\n&amp; -y \\Delta \\phi_a=\\ln \\left\\langle e^{-y \\Delta F_a}\\right\\rangle\n\\end{align}\n$$\n最后利用Bethe近似，复本自由能得到表示为： $$\\begin{align}\n\\phi=\\sum_i \\Delta \\phi_i-\\sum_a(|\\partial a|-1) \\Delta \\phi_a,\n\\end{align}$$ 因此$\\eqref{94}$和$\\eqref{95}$表示为： $$\n\\begin{aligned}\nf &amp; =\\frac{\\left\\langle\\Delta F_i e^{-y \\Delta\nF_i}\\right\\rangle}{\\left\\langle e^{-y \\Delta\nF_i}\\right\\rangle}-\\sum_a(|\\partial a|-1) \\frac{\\left\\langle\\Delta F_a\ne^{-y \\Delta F_a}\\right\\rangle}{\\left\\langle e^{-y \\Delta\nF_a}\\right\\rangle} \\\\\n\\Sigma &amp; =y(f-\\phi)\n\\end{aligned}\n$$\nCavity\nEnergy Cavity\n已知 Parisi 参量y与逆温度β，引入新的参数m构建极限情况下这两者的关系：\n$$\\begin{align}\n\\lim_{\\beta\\to\\infty,m\\to 0}\\beta m=y\n\\end{align}$$\n广义自由能与能量之间的关系为： $$\\begin{align}\n\\exp[-y\\Phi]&amp;=\\sum_{\\alpha,S}\\exp[-m\\beta H_\\alpha(S)] \\\\\n&amp;= \\sum_{\\alpha}Z^m_\\alpha\n\\end{align}$$\n利用Laplace近似，$\\eqref{laplace}写为$：\n$$\\begin{align}\n-\\beta m \\phi(\\beta, m)=\\max _{s, \\epsilon}\\{\\Sigma(s,\n\\epsilon)+m(s-\\beta \\epsilon)\\} \\label{913}\n\\end{align}$$\n其中将自由能写为熵和能量的依赖关系−βf = s − βϵ。\n如果看能量的关系，将$\\eqref{913}$中熵固定，有关系： $$\\begin{align}\n\\phi_\\epsilon(y)=\\max _\\epsilon\\{\\Sigma(\\epsilon)-y \\epsilon\\} .\n\\end{align}$$\nΣ(ϵ)表示在能量密度为ϵ的情况下，集团的数目。以K-SAT问题为例，其中ϵ表示能量（如果全部满足则ϵ = 0，存在不满足的情况时则ϵ &gt; 0）；Σ(ϵ)表示在该能量的情况下有多少个解的数目，当lim ϵ → 0的时候就表示全部满足的解的数目。\nEntropic Cavity\n将$\\eqref{913}$中能量固定，得到：\n$$\\begin{align}\n\\phi(m) = \\max_{s}\\{\\Sigma(s)+ms\\}\n\\end{align}$$\n并且有勒让德变化关系： $$\\begin{align}\ns=&amp;\\frac{\\partial \\phi(m)}{\\partial m}\\\\\n\\Sigma(s)&amp;=\\phi(m)-ms\n\\end{align}$$\n\n\nms\n\n上图中的小图斜率为$-m=\\frac{\\partial\n\\Sigma(s)}{\\partial s}$，只有0 ≤ m的部分有意义，随着熵s增大广义熵Σ开始减少，对于优化问题对应含义为：当组合优化问题中（例如k-SAT问题）一个特定问题（给定参数）的解的数量增加时候（s增加），则组合优化问题（没有指定具体参数）存在这样解的问题数量将会减少（Σ变小）；小图中m = 0的点，对应上面讨论的ϵ = 0的情况，即问题只需满足有解条件。大图是m与k-SAT问题中α的关系，当问题比较容易的时候( ≤ αc)m = 1，随着问题的难度增加（α变大），m开始变小，逐渐出现小图中的的关系，当达到一定程度（ = αc）的时候成为是否有解的阈值。\n\n\nsigma-alpha\n\n上图中两条曲线是两条相变线。m = 1的红线是动力学相变线，遍历性开始破缺，从此线开始问题对应的解的数量开始变少，例如蒙卡模拟临界慢化；m = 0是熵为0的线，分别基态与激发态，判别是否有解。\n1RSB\n之前已经将Cavity\n用于计算一个构型的自由能，接下来将其引入复本技巧中，计算不同构型自由能之间的耦合。\n$$\\begin{align}\nP\\left(m_{i \\rightarrow a}\\right)=\\frac{1}{\\mathcal{Z}_{i \\rightarrow\na}} \\prod_{b \\in \\partial i \\backslash a} \\int \\mathrm{d} \\hat{m}_{b\n\\rightarrow i} \\delta\\left(m_{i \\rightarrow\na}-\\mathcal{F}\\left(\\left\\{\\hat{m}_{b \\rightarrow\na}\\right\\}\\right)\\right) Z_{i \\rightarrow a}^m\n\\end{align}$$\n其中必须考虑一个构型自由能变化，导致对其它自由能构型的扰动，这一项用Zi → am表示。可以尝试使用变分导出。\n当m = 1的时候，$\\eqref{913}$有: $$\\begin{align}\n\\phi(\\beta,m=1)=\\epsilon-\\frac{\\Sigma(s,\\epsilon)+s}{\\beta}=\\epsilon-Ts_\\text{tot}\n\\end{align}$$ 其中stot = Σ + s是总解的数目，Σ为构型数目，s为一个构型中解的数目，两者相乘则得到stot。这个公式说明了\nCavity的方法在1阶复本破缺的情况下适用的原因。\n接下来讨论冻结（Frozen）的情况，也即是每一个构型只有一个解的情况，此时s = 0： $$\\begin{align}\ne^{-N \\beta m \\phi(\\beta, m)}=\\sum_\\alpha e^{-N \\beta m\nf_\\alpha}=\\sum_\\alpha e^{-N \\beta m \\epsilon_\\alpha}=e^{-N \\beta m\nf_{\\mathrm{RS}}(\\beta m)}\n\\end{align}$$\n存在冻结温度sRS(βs) = 0，此时有$m=\\frac{\\beta_s}{\\beta}=1$。m的含义为$1-m=\\sum_\\alpha\\overline{\\omega_\\alpha^2}$，其中ω为构型权重，更多的参考Storage\ncapacity of memory networks with binary couplings。\n阅读这篇文献。\nMore Steps of Replica\nSymmetry Breaking\n由于使用了空腔方法，在具备长程关联的情况下将会变得不精确。解正确的必要条件是spin\nglass susceptibility χSG\n没有发散:\n$$\\begin{align}\n\\chi_{\\mathrm{SG}}=\\frac{1}{N} \\sum_{i, j}\n\\overline{\\left(\\left\\langle\\sigma_i\n\\sigma_j\\right\\rangle-\\left\\langle\\sigma_i\\right\\rangle\\left\\langle\\sigma_j\\right\\rangle\\right)^2}\n\\end{align}$$ 其中⟨⋅⟩是热力学平均，上划线是无序平均。当这个条件不满足的时候，需要引入更高阶的复本对称。\nOptimization\n参考 Spin Glass Theory and Beyound 书籍。\nAppend\n勒让德变换\n勒让德变换（Legendre\ntransform）是一种数学工具，用于在物理学和数学中将一个函数转换为其共轭变量的函数。它在经典力学、热力学、统计力学以及最优化问题中有重要应用。勒让德变换能够将一个变量的依赖关系转化为另一变量的依赖关系，从而简化问题的求解。\n定义\n设 f(x)\n是一个实函数，其导数 f′(x)\n单调且严格递增，这样 f′(x) 的反函数\nx = (f′)−1(p)\n存在。勒让德变换将函数 f(x) 转换为一个新函数 g(p)，其中 p 是 f(x) 的导数 p = f′(x)。勒让德变换定义为：\ng(p) = xp − f(x)\n其中， x 满足 p = f′(x)。这个过程可以逆转过来得到\nf(x)，即\nf(x) = xp − g(p)\n其中，p 满足 x = g′(p)。\n性质\n\n对偶关系：勒让德变换是自反的，即对 f(x) 进行勒让德变换得到\ng(p)，再对 g(p) 进行勒让德变换会返回到\nf(x)。\n凸函数：勒让德变换通常用于凸函数。对于一个凸函数\nf(x)，其勒让德变换\ng(p) 也是凸的。\n\n应用\n\n热力学：在热力学中，勒让德变换用于将内能 U(S, V)\n转换为其他热力学势，例如亥姆霍兹自由能 F(T, V)、吉布斯自由能\nG(T, P) 和焓\nH(S, P)。这些不同的热力学势对应于不同的自然变量，可以更方便地描述系统的平衡状态。\n\n亥姆霍兹自由能：F(T, V) = U − TS\n吉布斯自由能：G(T, P) = U − TS + PV\n焓：H(S, P) = U + PV\n\n经典力学：在哈密顿力学中，勒让德变换将拉格朗日函数\nL(q, q̇)\n转换为哈密顿函数 H(q, p)： H(q, p) = q̇p − L(q, q̇)\n其中，$p = \\frac{\\partial L}{\\partial\n\\dot{q}}$。\n优化理论：勒让德变换在优化问题中也有应用，特别是在凸优化问题中，它将原函数的最小化问题转换为共轭函数的最小化问题。\n\n例子\n考虑一个简单的函数 $f(x) = \\frac{1}{2} k\nx^2$，其中 k\n是常数。我们可以计算其勒让德变换 g(p)：\n\n计算导数：p = f′(x) = kx\n解出 x：$x = \\frac{p}{k}$\n代入勒让德变换公式：$g(p) = x p - f(x) =\n\\frac{p}{k} p - \\frac{1}{2} k \\left( \\frac{p}{k} \\right)^2 =\n\\frac{p^2}{2k}$\n\n所以， $f(x) = \\frac{1}{2} k x^2$\n的勒让德变换是 $g(p) =\n\\frac{p^2}{2k}$。\n总结来说，勒让德变换是一个强大的数学工具，用于在不同变量之间进行转换，从而简化物理和数学问题的求解过程。\nK-SAT\nK-SAT问题是计算复杂性理论和计算机科学中一个著名的逻辑难题，属于布尔可满足性问题（Boolean\nsatisfiability problem,\nSAT）的一个特例。K-SAT问题被广泛研究，因为它在理论计算机科学中具有重要意义，并且是NP完全问题的典型代表。\nK-SAT问题的定义\n\n布尔变量：K-SAT问题涉及一组布尔变量 x1, x2, …, xn，每个变量可以取值为真（True,\n1）或假（False, 0）。\n子句：一个子句是布尔变量的若干文字（变量或其否定）的或（OR）运算。例如，((x_1\nx_2 x_3)) 是一个包含三个文字的子句。\nK个文字：在K-SAT问题中，每个子句包含恰好K个不同的文字（变量或其否定）。\n公式：K-SAT问题给定一个布尔公式，是这些子句的与（AND）运算。例如，一个3-SAT问题的公式可能是：\n(x1 ∨ ¬x2 ∨ x3) ∧ (¬x1 ∨ x2 ∨ x4) ∧ (x2 ∨ ¬x3 ∨ ¬x4)\n\n问题描述\nK-SAT问题的目标是确定是否存在一个布尔变量的赋值，使得整个公式为真。换句话说，找到一种布尔变量的赋值，使得所有子句都为真。\n重要性\n\nNP完全性：对于 K ≥ 3，K-SAT问题是NP完全的，这意味着它是NP问题中最难的一类。如果可以找到一个多项式时间算法来解决任意的3-SAT问题，那么所有NP问题都可以在多项式时间内解决。\n应用：K-SAT问题在计算机科学和工程中有广泛的应用，包括电路设计、软件验证、人工智能中的约束满足问题、规划和调度等。\n理论研究：K-SAT问题是计算复杂性理论的重要研究对象，许多复杂性理论的基本结果都是通过研究K-SAT问题得到的。\n\n特例\n\n2-SAT问题：2-SAT问题是K-SAT问题的一个特例，其中每个子句包含恰好两个文字。2-SAT问题可以在多项式时间内解决，不像K-SAT问题（对于\nK ≥ 3）那样是NP完全的。\n1-SAT问题：1-SAT问题是最简单的特例，其中每个子句只包含一个文字。显然，1-SAT问题可以在线性时间内解决。\n\n示例\n考虑以下3-SAT问题： (x1 ∨ ¬x2 ∨ x3) ∧ (¬x1 ∨ x2 ∨ x4) ∧ (x2 ∨ ¬x3 ∨ ¬x4)\n我们需要找到一种布尔变量的赋值，使得上述公式为真。例如，赋值 x1 = True, x2 = False, x3 = True, x4 = False\n可以使得每个子句都为真，从而满足整个公式。\n结论\nK-SAT问题在计算机科学中具有重要意义，尤其是作为NP完全问题的代表。它不仅在理论研究中扮演重要角色，也在许多实际应用中得到广泛应用。通过研究和解决K-SAT问题，计算机科学家可以更好地理解复杂问题的本质以及开发有效的算法。\nstop\n","categories":["Physics"],"tags":["Spin Glass","Replica Method","Hopfield Model"]},{"title":"Feynman path integrals","url":"/2024/05/26/Phys/Path_integrals/Path_integrals/","content":"考虑到状态的演化，最直接的想法是通过经典力学通过拉格朗日量来构建经典的运动路径。如何处理的问题不是精确的状态，而是概率密度的分布，如何求概率密度分布的演化？路径积分则是十分自然的想法。将每一个小的状态，以任意的路径进行演化，最后得到最终转态的概率分布。这样处理的麻烦在于，不是每一条路径都是等价的，有一些路径发生的概率高一些，另一些则低一些。如何表示这样的概率分布，以及实际得到演化后的概率分布，则是本文要探讨的。\n当然，这只是一个简单的版本，需要更多的讨论。\n参考： * QM -\n路径积分 (Path Integral) PT. 1 - 基本构架 * QM - 路径积分 (Path\nIntegral) PT. 2 - 求解实例\n\n路径积分的基本构架\n\n本部分的目标： 1. 构建传播子 2. 相空间、位形空间的形式 3.\n以自由粒子为例，展示两种形式\n\n传播子是研究态随时间演化的方法，这样演化过程由基本方程确定，在量子力学中这样的方程是薛定谔方程。但是随时间演化的方程有很多，这些同样可以在传播子的框架下研究。\n由于薛定谔方程过于出名，接下来的讨论在薛定谔方程下进行。\n传播子\n定义一个算符 U，它的作用是给出演化结果:\n$$\\begin{align}\nU\\left(t-t_0\\right)\\left|\\psi\\left(t_0\\right)\\right\\rangle=|\\psi(t)\\rangle\n\\end{align}$$\n然后求解 U\n的表达式，研究时间演化最熟悉的是薛定谔方程: $$\\begin{align}\n&amp; i \\hbar \\frac{\\mathrm{d}}{\\mathrm{d}\nt}|\\psi(t)\\rangle=H|\\psi(t)\\rangle \\\\\n\\Rightarrow &amp; \\frac{\\mathrm{d}}{\\mathrm{d} t}\nU\\left(t-t_0\\right)\\left|\\psi\\left(t_0\\right)\\right\\rangle=-i\n\\frac{H}{\\hbar}\nU\\left(t-t_0\\right)\\left|\\psi\\left(t_0\\right)\\right\\rangle \\\\\n\\Rightarrow &amp; \\frac{\\mathrm{d}}{\\mathrm{d} t} U\\left(t-t_0\\right)=-i\n\\frac{H}{\\hbar} U\\left(t-t_0\\right) \\\\\n\\Rightarrow &amp; \\mathrm{d} \\ln U\\left(t-t_0\\right)=-i \\frac{H}{\\hbar}\n\\mathrm{d} t \\\\\n\\Rightarrow &amp; U\\left(t-t_0\\right)=e^{-i \\frac{H}{\\hbar} t} \\cdot\n\\text { const }\n\\end{align}$$\n如果时间不变自然不发生演化，以此作为初始条件，即 t = t0 ⇒ U = I。确定系数之后得到了么正时间演化算符的表达式:\n$$\\begin{align}\nU\\left(t-t_0\\right)=e^{-i \\frac{H}{\\hbar}\\left(t-t_0\\right)}\n\\end{align}$$\n在形式上地使用： $$\\begin{align}\n|\\psi(t)\\rangle=U\\left(t-t_0\\right)\\left|\\psi\\left(t_0\\right)\\right\\rangle\n\\label{1_U}\n\\end{align}$$\n接下来$\\eqref{1_U}$式取坐标表象，即左乘 ⟨r⃗|，再插入完备性关系式 I = ∫|r⃗0⟩⟨r⃗0|dr⃗0，可得：\n$$\\begin{align}\n\\psi(\\vec{r}, t)&amp;=\\int\\left\\langle\\vec{r}\\left|U\\left(t,\nt_0\\right)\\right| \\vec{r}_0\\right\\rangle\\left\\langle\\vec{r}_0 \\mid\n\\psi\\left(t_0\\right)\\right\\rangle \\mathrm{d} \\vec{r}_0 \\\\\n&amp;=\\int K\\left(\\vec{r}, t ; \\vec{r}_0, t_0\\right)\n\\psi\\left(\\vec{r}_0, t_0\\right) \\mathrm{d} \\vec{r}_0 \\\\\nK\\left(\\vec{r}, t ; \\vec{r}_0, t_0\\right) &amp;=\n\\left\\langle\\vec{r}\\left|U\\left(t, t_0\\right)\\right|\n\\vec{r}_0\\right\\rangle\n\\end{align}$$\n其中 K(r⃗, t; r⃗0, t0)\n称作传播子, 作用如上所示, 路径积分的最终目的就是得到其具体表达式。\n传播子的性质\n设置时间节点（无特殊声明全文适用）：\n$$\\begin{align}\nt_0&lt;t_n \\leq t=t_N, n \\in\\{1,2,3, \\cdots, N\\}\n\\end{align}$$\n注意不平均分割时间。由传播子的定义，我们不难发现它具有如下特性：\n$$\\begin{align}\nK\\left(\\vec{r}, t ; \\vec{r}_0, t_0\\right) &amp;\n=\\left\\langle\\vec{r}\\left|U\\left(t, t_0\\right)\\right|\n\\vec{r}_0\\right\\rangle \\\\\n&amp; =\\left\\langle\\vec{r}\\left|U\\left(t, t_1\\right) U\\left(t_1,\nt_0\\right)\\right| \\vec{r}_0\\right\\rangle \\\\\n&amp; =\\int\\left\\langle\\vec{r}\\left|U\\left(t, t_1\\right)\\right|\n\\vec{r}_1\\right\\rangle\\left\\langle\\vec{r}_1\\left|U\\left(t_1,\nt_0\\right)\\right| \\vec{r}_0\\right\\rangle \\mathrm{d} \\vec{r}_1 \\\\\n&amp; =\\int\\left\\langle\\vec{r}\\left|U\\left(t, t_2\\right)\\right|\n\\vec{r}_2\\right\\rangle\\left\\langle\\vec{r}_2\\left|U\\left(t_2,\nt_1\\right)\\right|\n\\vec{r}_1\\right\\rangle\\left\\langle\\vec{r}_1\\left|U\\left(t_1,\nt_0\\right)\\right| \\vec{r}_0\\right\\rangle \\mathrm{d} \\vec{r}_1\n\\mathrm{~d} \\vec{r}_2 \\\\\n&amp; =\\int K\\left(\\vec{r}, t ; \\vec{r}_2, t_2\\right) K\\left(\\vec{r}_2,\nt_2 ; \\vec{r}_1, t_1\\right) K\\left(\\vec{r}_1, t_1 ; \\vec{r}_0,\nt_0\\right) \\mathrm{d} \\vec{r}_1 \\mathrm{~d} \\vec{r}_2\n\\end{align}$$\n注意我们要求上式中恒满足关系 r⃗N = r⃗, tN = t, a &gt; b ⇔ ta &gt; tb。利用该性质进行无穷分割:\n$$\\begin{align}\nK\\left(\\vec{r}, t ; \\vec{r}_0, t_0\\right)&amp;=\\int\\left[\\prod_{n=1}^N\nK\\left(\\vec{r}_n, t_n ; \\vec{r}_{n-1}, t_{n-1}\\right)\\right] \\mathrm{d}\n\\vec{r}_1 \\cdots \\mathrm{d} \\vec{r}_{N-1} \\\\\n\\max \\left\\{t_n-t_{n-1}\\right\\} &amp;\\rightarrow 0\n\\end{align}$$\n将积分号里边儿的那个无穷小过程传播子换一个符号, 记为:\n$$\\begin{align}\nK\\left(\\vec{r}, t ; \\vec{r}_0, t_0\\right)=\\int\\left[\\prod_{n=1}^N\n\\mathcal{K}\\left(\\vec{r}_n, t_n ; \\vec{r}_{n-1}, t_{n-1}\\right)\\right]\n\\mathrm{d} \\vec{r}_1 \\cdots \\mathrm{d} \\vec{r}_{N-1}{ }^{[2]}\n\\end{align}$$\n相空间的路径积分\n要求 K(r⃗, t; r⃗0, t0)\n，需先处理 𝒦(r⃗n, tn; r⃗n − 1, tn − 1)\n。\n$$\\begin{align}\n\\mathcal{K}\\left(\\vec{r}_n, t_n ; \\vec{r}_{n-1},\nt_{n-1}\\right)&amp;=\\left\\langle\\vec{r}_n\\left|U\\left(t_n,\nt_{n-1}\\right)\\right|\n\\vec{r}_{n-1}\\right\\rangle=\\left\\langle\\vec{r}_n\\left|e^{-\\frac{i\nH}{\\hbar} \\Delta t_n}\\right| \\vec{r}_{n-1}\\right\\rangle\\\\\ne^{-\\frac{i}{\\hbar} H \\Delta\nt_n}&amp;=e^{-\\frac{i}{\\hbar}\\left[\\frac{p^2}{2 m}+V\\left(\\vec{R},\nt_n\\right)\\right] \\Delta t_n \\Delta t_n \\rightarrow 0}\ne^{-\\frac{i}{\\hbar} V\\left(\\vec{R}, t_n\\right) \\Delta t_n}\ne^{-\\frac{i}{\\hbar} \\frac{p^2}{2 m} \\Delta t_n}\n\\end{align}$$\n𝒦表示极短时间内从一个状态到另一个状态，在极限情况下式精确的；K是一段时间的跳跃。因此有 K ≠ 𝒦，在一些情况下这两个是相等的例如自由粒子。\n可以推知：\n$$\\begin{align}\n\\mathcal{K}\\left(\\vec{r}_n, t_n ; \\vec{r}_{n-1}, t_{n-1}\\right) &amp;\n=\\left\\langle\\vec{r}_n\\left|e^{-\\frac{i}{\\hbar} V\\left(\\vec{R},\nt_n\\right) \\Delta t_n} e^{-\\frac{i}{\\hbar} \\frac{p^2}{2 m} \\Delta\nt_n}\\right| \\vec{r}_{n-1}\\right\\rangle \\\\\n&amp; =e^{-\\frac{i}{\\hbar} V\\left(\\vec{r}_n, t_n\\right) \\Delta\nt_n}\\left\\langle\\vec{r}_n\\left|e^{-\\frac{i}{\\hbar} \\frac{P^2}{2 m}\n\\Delta t_n}\\right| \\vec{r}_{n-1}\\right\\rangle \\\\\n&amp; =\\int e^{-\\frac{i}{\\hbar} V\\left(\\vec{r}_n, t_n\\right) \\Delta\nt_n}\\left\\langle\\vec{r}_n \\mid\n\\vec{p}_n\\right\\rangle\\left\\langle\\vec{p}_n\\left|e^{-\\frac{i}{\\hbar}\n\\frac{P^2}{2 m} \\Delta t_n}\\right| \\vec{r}_{n-1}\\right\\rangle \\mathrm{d}\n\\vec{p}_n \\\\\n&amp; =\\int e^{-\\frac{i}{\\hbar} V\\left(\\vec{r}_n, t_n\\right) \\Delta\nt_n}\\left\\langle\\vec{r}_n \\mid \\vec{p}_n\\right\\rangle\ne^{-\\frac{i}{\\hbar} \\frac{p_n^2}{2 m} \\Delta t_n}\\left\\langle\\vec{p}_n\n\\mid \\vec{r}_{n-1}\\right\\rangle \\mathrm{d} \\vec{p}_n \\\\\n&amp; =\\frac{1}{(2 \\pi \\hbar)^3} \\int e^{-\\frac{i}{\\hbar}\nV\\left(\\vec{r}_n, t_n\\right) \\Delta t_n} e^{i \\frac{\\vec{p}_n}{\\hbar}\n\\cdot \\Delta \\vec{r}_n} e^{-\\frac{i}{\\hbar} \\frac{p_n^2}{2 m} \\Delta\nt_n} \\mathrm{~d} \\vec{p}_n \\\\\n&amp; =\\frac{1}{(2 \\pi \\hbar)^3} \\int e^{\\frac{i}{\\hbar}\\left[\\vec{p}_n\n\\cdot \\frac{\\Delta \\vec{r}_n}{\\Delta t_n}-H\\left(\\vec{r}_n, \\vec{p}_n,\nt_n\\right)\\right] \\Delta t_n} \\mathrm{~d} \\vec{p}_n \\\\\n&amp; =\\frac{1}{(2 \\pi \\hbar)^3} \\int e^{\\frac{i}{\\hbar}\\left[\\vec{p}_n\n\\cdot \\vec{r}_n-H\\left(\\vec{r}_n, \\vec{p}_n, t_n\\right)\\right] \\Delta\nt_n} \\mathrm{~d} \\vec{p}_n \\\\\n&amp; =\\frac{1}{(2 \\pi \\hbar)^3} \\int e^{i \\frac{L\\left(\\vec{r}_n,\n\\vec{p}_n, t_n\\right) \\Delta t_n}{\\hbar}} \\mathrm{d} \\vec{p}_n\n\\end{align}$$\n将上式代回传播子的表达式就得到相空间的路径积分:\n$$\\begin{align}\nK\\left(\\vec{r}, t ; \\vec{r}_0, t_0\\right) &amp; =\\int\\left[\\prod_{n=1}^N\n\\mathcal{K}\\left(\\vec{r}_n, t_n ; \\vec{r}_{n-1}, t_{n-1}\\right)\\right]\n\\mathrm{d} \\vec{r}_1 \\cdots \\mathrm{d} \\vec{r}_{N-1} \\\\\n&amp; =\\int \\prod_{n=1}^N\\left[\\frac{1}{(2 \\pi \\hbar)^3} \\int\ne^{\\frac{i}{\\hbar} L\\left(\\vec{r}_n, \\vec{p}_n, t_n\\right) \\Delta t_n}\n\\mathrm{~d} \\vec{p}_n\\right] \\mathrm{d} \\vec{r}_1 \\cdots \\mathrm{d}\n\\vec{r}_{N-1} \\\\\n&amp; =\\frac{1}{(2 \\pi \\hbar)^{3 N}} \\int\\left[\\int e^{\\frac{i}{\\hbar}\n\\sum_{n=1}^N L\\left(\\vec{r}_n, \\vec{p}_n, t_n\\right) \\Delta t_n}\n\\mathrm{~d} \\vec{p}_1 \\cdots \\mathrm{d} \\vec{p}_N\\right] \\mathrm{d}\n\\vec{r}_1 \\cdots \\mathrm{d} \\vec{r}_{N-1} \\\\\n&amp; \\stackrel{\\text { limit }}{=} \\frac{1}{(2 \\pi \\hbar)^{3 N}} \\int\ne^{\\frac{i}{\\hbar} \\int L(\\vec{r}, \\vec{p}, \\tau) \\mathrm{d} \\tau}\n\\mathrm{d} \\vec{r}_1 \\cdots \\mathrm{d} \\vec{r}_{N-1} \\mathrm{~d}\n\\vec{p}_1 \\cdots \\mathrm{d} \\vec{p}_N \\\\\n&amp; =\\frac{1}{(2 \\pi \\hbar)^{3 N}} \\int \\mathcal{D} \\vec{r}\n\\mathcal{D} \\vec{p} e^{i \\frac{S(\\vec{r}, \\vec{p}, t)}{\\hbar}}\n\\end{align}$$\n其中的 𝒟\n表征对各种怪异路径进行积分。注意位置积分比动量积分少一重，因为端点是固定的。\n位形空间的路径积分\n位形空间的路径积分，就是把动量先积掉：\n$$\\begin{align}\n\\mathcal{K}\\left(\\vec{r}_n, t_n ; \\vec{r}_{n-1}, t_{n-1}\\right) &amp;\n=\\frac{1}{(2 \\pi \\hbar)^3} \\int e^{-\\frac{i}{\\hbar} V\\left(\\vec{r}_n,\nt_n\\right) \\Delta t_n} e^{i \\frac{\\vec{p}_n}{\\hbar} \\cdot \\Delta\n\\vec{r}_n} e^{-\\frac{i}{\\hbar} \\frac{p_n^2}{2 m} \\Delta t_n} \\mathrm{~d}\n\\vec{p}_n \\\\\n&amp; =\\frac{1}{(2 \\pi \\hbar)^3} e^{-\\frac{i}{\\hbar} V\\left(\\vec{r}_n,\nt_n\\right) \\Delta t_n} \\int e^{i \\frac{\\vec{p}_n}{\\hbar} \\cdot \\Delta\n\\vec{r}_n} e^{-\\frac{i}{\\hbar} \\frac{p_n^2}{2 m} \\Delta t_n} \\mathrm{~d}\n\\vec{p}_n\n\\end{align}$$\n显然后面的积分在自由粒子的格林函数中求解过, 这里直接而代入结论:\n$$\n\\frac{1}{(2 \\pi \\hbar)^3} \\int e^{i \\frac{\\vec{p}_n}{\\hbar} \\cdot \\Delta\n\\vec{r}_n} e^{-\\frac{i}{\\hbar} \\frac{p_n^2}{2 m} \\Delta t_n} \\mathrm{~d}\n\\vec{p}_n=\\left(\\frac{m}{2 \\pi i \\hbar \\Delta t_n}\\right)^{\\frac{3}{2}}\n\\exp \\left[i \\frac{m\\left(\\Delta \\vec{\\Delta}_n\\right)^2}{2 \\hbar \\Delta\nt_n}\\right]\n$$\n将上式代回无穷小间隔传播子表达式得:\n$$\\begin{align}\n\\mathcal{K}\\left(\\vec{r}_n, t_n ; \\vec{r}_{n-1}, t_{n-1}\\right) &amp;\n=\\frac{1}{(2 \\pi \\hbar)^3} \\int e^{-\\frac{i}{\\hbar} V\\left(\\vec{r}_n,\nt_n\\right) \\Delta t_n} e^{i \\frac{\\vec{p}_n}{\\hbar} \\cdot \\Delta\n\\vec{r}_n} e^{-\\frac{i}{\\hbar} \\frac{p_n^2}{2 m} \\Delta t_n} \\mathrm{~d}\n\\vec{p}_n \\\\\n&amp; =\\left(\\frac{m}{2 \\pi i \\hbar \\Delta t_n}\\right)^{\\frac{3}{2}}\ne^{-\\frac{i}{\\hbar} V\\left(\\vec{r}_n, t_n\\right) \\Delta t_n} e^{i\n\\frac{m\\left(\\Delta \\vec{F}_n\\right)^2}{2 \\hbar \\Delta t_n}} \\\\\n&amp; =\\left(\\frac{m}{2 \\pi i \\hbar \\Delta t_n}\\right)^{\\frac{3}{2}}\ne^{\\frac{i}{\\hbar}\\left[\\frac{1}{2} m \\frac{\\left(\\Delta\n\\vec{r}_n\\right)^2}{\\left(\\Delta t_n\\right)^2}-V\\left(\\vec{r}_n,\nt_n\\right)\\right] \\Delta t_n} \\\\\n&amp; =\\left(\\frac{m}{2 \\pi i \\hbar \\Delta t_n}\\right)^{\\frac{3}{2}}\ne^{\\frac{i}{\\hbar}\\left[\\frac{1}{2} m\n\\dot{\\vec{r}}_n^2-V\\left(\\vec{r}_n, t_n\\right)\\right] \\Delta t_n}\n\\end{align}$$\n将上述结果代回传播子的表达式得到位形空间的路径积分:\n$$\\begin{align}\nK\\left(\\vec{r}, t ; \\vec{r}_0, t_0\\right) &amp; =\\int\\left[\\prod_{n=1}^N\n\\mathcal{K}\\left(\\vec{r}_n, t_n ; \\vec{r}_{n-1}, t_{n-1}\\right)\\right]\n\\mathrm{d} \\vec{r}_1 \\cdots \\mathrm{d} \\vec{r}_{N-1} \\\\\n&amp; =\\int\\left[\\prod_{n=1}^N\\left(\\frac{m}{2 \\pi i \\hbar \\Delta\nt_n}\\right)^{\\frac{3}{2}} e^{\\frac{i}{\\hbar}\\left[\\frac{1}{2} m\n\\dot{\\vec{r}}_n^2-V\\left(\\vec{r}_n, t_n\\right)\\right] \\Delta t_n}\\right]\n\\mathrm{d} \\vec{r}_1 \\cdots \\mathrm{d} \\vec{r}_{N-1} \\\\\n&amp; =\\prod_{n=1}^N\\left(\\frac{m}{2 \\pi i \\hbar \\Delta\nt_n}\\right)^{\\frac{3}{2}} \\int e^{\\frac{i}{\\hbar}\n\\sum_{n=1}^N\\left[\\frac{1}{2} m \\dot{\\vec{r}}_n^2-V\\left(\\vec{r}_n,\nt_n\\right)\\right] \\Delta t_n} \\mathrm{~d} \\vec{r}_1 \\cdots \\mathrm{d}\n\\vec{r}_{N-1} \\\\\n&amp; \\stackrel{\\text { limit }}{=} \\prod_{n=1}^N\\left(\\frac{m}{2 \\pi i\n\\hbar \\Delta t_n}\\right)^{\\frac{3}{2}} \\int e^{\\frac{i}{\\hbar}\n\\int_{t_0}^t \\frac{1}{2} m \\dot{\\vec{r}}_n^2-V(\\vec{r}, \\tau) \\mathrm{d}\n\\tau} \\mathrm{d} \\vec{r}_1 \\cdots \\mathrm{d} \\vec{r}_{N-1} \\\\\n&amp; =\\prod_{n=1}^N\\left(\\frac{m}{2 \\pi i \\hbar \\Delta\nt_n}\\right)^{\\frac{3}{2}} \\int \\mathcal{D} \\vec{r} e^{i\n\\frac{S\\left(\\vec{r}, \\vec{r}_t, t\\right)}{\\hbar}}\n\\end{align}$$\n传播子的两类表达式\n综上所述, 路径积分中的传播子就表达为: $$\\begin{align}\nK\\left(\\vec{r}, t ; \\vec{r}_0, t_0\\right)= &amp; \\frac{1}{(2 \\pi\n\\hbar)^{3 N}} \\int \\mathcal{D} \\vec{r} \\mathcal{D} \\vec{p} e^{i\n\\frac{S(\\vec{r}, \\vec{p}, t)}{\\hbar}} \\\\\nK\\left(\\vec{r}, t ; \\vec{r}_0, t_0\\right)= &amp;\n\\prod_{n=1}^N\\left(\\frac{m}{2 \\pi i \\hbar \\Delta\nt_n}\\right)^{\\frac{3}{2}} \\int \\mathcal{D} \\vec{r} e^{i \\frac{S(\\vec{r},\n\\vec{r}, t)}{\\hbar}} \\label{1_weixin}\n\\end{align}$$\n实际运算中需要用到:\n$$\n\\left\\{\\begin{array}{l}\nK\\left(\\vec{r}, t ; \\vec{r}_0, t_0\\right)=\\frac{1}{(2 \\pi \\hbar)^{3 N}}\n\\int e^{\\frac{i}{\\hbar} \\sum_{n=1}^N\\left[\\vec{p}_n \\cdot\n\\dot{\\vec{r}}_n-H\\left(\\vec{r}_n, \\vec{p}_n, t_n\\right)\\right] \\Delta\nt_n} \\mathrm{~d} \\vec{r}_1 \\cdots \\mathrm{d} \\vec{r}_{N-1} \\mathrm{~d}\n\\vec{p}_1 \\cdots \\mathrm{d} \\vec{p}_N \\\\\nK\\left(\\vec{r}, t ; \\vec{r}_0, t_0\\right)=\\prod_{n=1}^N\\left(\\frac{m}{2\n\\pi i \\hbar \\Delta t_n}\\right)^{\\frac{3}{2}} \\int e^{\\frac{i}{\\hbar}\n\\sum_{n=1}^N\\left[\\frac{1}{2} m \\dot{\\vec{r}}_n^2-V\\left(\\vec{r}_n,\nt_n\\right)\\right] \\Delta t_n} \\mathrm{~d} \\vec{r}_1 \\cdots \\mathrm{d}\n\\vec{r}_{N-1}\n\\end{array}\\right.\n$$\n其中 $\\left\\{\\begin{array}{l}\\Delta\nt_n=t_n-t_{n-1} \\\\ \\Delta \\vec{r}_n=\\vec{r}_n-\\vec{r}_{n-1} \\\\\n\\dot{\\vec{r}}_n=\\Delta \\vec{r}_n / \\Delta t_n \\\\ n \\in\\{1,2,3, \\cdots,\nN\\}\\end{array} \\quad\\right.$ 且规定 $\\left\\{\\begin{array}{l}\\vec{r}_N=\\vec{r} \\\\ t_N=t\n\\\\ t_0&lt;t_n \\leq t \\\\ a&gt;b \\Leftrightarrow t_a&gt;t_b \\\\ \\min\n\\left\\{t_n-t_{n-1}\\right\\} \\rightarrow 0\\end{array}\\right.$\n根号下的虚数单位 i 定义为\nexp [iπ/2]。\n自由粒子 -\n利用对角化求解路径积分\n\n已完成内容： 1. 路径积分的两种形式 2. 自由粒子的路径积分\n本部分的目标： 1.\n讨论自由粒子在位形空间的路径积分，得到传播子的具体形式 2.\n讨论自由粒子在相空间的路径积分，得到传播子的具体形式所属\n\n对时间采用平均分割的方案$\\Delta\nt_n=\\frac{t-t_0}{N}=\\varepsilon$，在极限情况下讨论N → ∞  or  ε → ∞。由$\\eqref{1_weixin}$可知自由粒子位形空间传播子为：\n$$\\begin{align}\nK\\left(x, t ; x_0, t_0\\right)&amp;=\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\int \\mathrm{D} x e^{i\n\\frac{S}{\\hbar}} \\\\\nS&amp;=\\int \\frac{1}{2} m v^2 dt\\\\\n&amp;=\\sum_{n=1}^N \\frac{1}{2} m \\frac{\\left(\\Delta\nx_n\\right)^2}{\\varepsilon^2} \\varepsilon \\\\\n&amp;=\\frac{m}{2 \\varepsilon} \\sum_{n=1}^N\\left(x_n-x_{n-1}\\right)^2\n\\label{free_partial_S}\n\\end{align}$$\n将位置xn表示成经典路径xnc与路径扰动yn两个部分，其中下标表示时刻tn：\n$$\\begin{align}\nx_n&amp;=x_n^c+y_n \\\\\nx_n^{\\mathrm{c}}&amp;=x^{\\mathrm{c}}\\left(t_n\\right)=x^{\\mathrm{c}}\\left(t_0+n\n\\varepsilon\\right) \\\\\n\\end{align}$$\n并且有边界条件，在端点是固定不动的：\n$$\\begin{align}\n\\left\\{\n    \\begin{array}\n    {l}x_0^{\\mathrm{c}}=x^{\\mathrm{c}}\\left(t_0\\right)=x_0 \\\\\n    x_N^{\\mathrm{c}}=x^{\\mathrm{c}}\\left(t_N\\right)=x_N=x\n    \\end{array}\n\\right.\n\\end{align}$$\n以及关系：\n$$\\begin{aligned}\nt_N&amp;=t_0+N \\varepsilon \\\\\n\\Delta t_2+\\Delta t_1&amp;=t_2-t_0 \\Rightarrow \\sum_{n=1}^N \\Delta t_n=N\n\\varepsilon=t_N-t_0\n\\end{aligned}$$\n代入$\\eqref{free_partial_S}$后：\n$$\\begin{align}\nS&amp;=\\frac{m}{2 \\varepsilon} \\sum_{n=1}^N\\left(\\Delta x_n\\right)^2 \\\\\n&amp;=\\frac{m}{2 \\varepsilon} \\sum_{n=1}^N\\left(\\Delta\nx_n^{\\mathrm{c}}+\\Delta y_n\\right)^2\\\\\n&amp;=\\frac{m}{2 \\varepsilon} \\sum_{n=1}^N\\left(\\Delta\nx_n^{\\mathrm{c}}\\right)^2+\\frac{m}{2 \\varepsilon}\n\\sum_{n=1}^N\\left(\\Delta y_n\\right)^2+\\frac{m}{\\varepsilon} \\sum_{n=1}^N\n\\Delta x_n^{\\mathrm{c}} \\Delta y_n\n\\end{align}$$\n分为三个部分：\n$$\\begin{align}\nS^{\\mathrm{c}}&amp;= \\frac{m}{2 \\varepsilon} \\sum_{n=1}^N\\left(\\Delta\nx_n^{\\mathrm{c}}\\right)^2 \\\\\nS^{\\prime} &amp;= \\frac{m}{2 \\varepsilon} \\sum_{n=1}^N\\left(\\Delta\ny_n\\right)^2 \\\\\nS^{\\times} &amp;= \\frac{m}{\\varepsilon} \\sum_{n=1}^N \\Delta\nx_n^{\\mathrm{c}} \\Delta y_n\n\\end{align}$$\n\n\nPath Integral\n\n如上图所示，表示在固定初始与终点的路径积分，每条线表示可能的路径，其中红线为经典路径。\n针对交叉项：\n$$\\begin{align}\nS^{\\times} &amp;= \\frac{m}{\\varepsilon} \\sum_{n=1}^N \\Delta\nx_n^{\\mathrm{c}} \\Delta y_n \\\\\n&amp;=m \\sum_{n=1}^N \\dot{x}_n^{\\mathrm{c}}\\left(y_n-y_{n-1}\\right) \\\\\n&amp; =m\\left(\\sum_{n=1}^N \\dot{x}_n^{\\mathrm{c}} y_n-\\sum_{n=1}^N\n\\dot{x}_n^{\\mathrm{c}} y_{n-1}\\right) \\\\\n&amp; \\stackrel{y_{N=0}}{=} m\\left(\\sum_{n=1}^{N-1}\n\\dot{x}_n^{\\mathrm{c}} y_n-\\sum_{n=0}^{N-1} \\dot{x}_{n+1}^{\\mathrm{c}}\ny_n\\right) \\\\\n&amp; \\stackrel{y_{0=0}}{=} m\\left(\\sum_{n=1}^{N-1}\n\\dot{x}_n^{\\mathrm{c}} y_n-\\sum_{n=1}^{N-1} \\dot{x}_{n+1}^{\\mathrm{c}}\ny_n\\right) \\\\\n&amp;=-m \\varepsilon \\sum_{n=1}^{N-1} \\frac{\\Delta\n\\dot{x}_{n+1}^{\\mathrm{c}}}{\\varepsilon} y_n \\\\\n&amp;=-m \\varepsilon \\sum_{n=1}^{N-1} \\ddot{x}_{n+1}^{\\mathrm{c}} y_n\n\\end{align}$$\n考虑到自由粒子$F=ma=m\\ddot{x}^{\\mathrm{c}}=0$，因此交叉项S× = 0。\n对于经典路径项Sc：\n$$\\begin{align}\nS^{\\mathrm{c}}&amp;=\\frac{m}{2 \\varepsilon} \\sum_{n=1}^N\\left(\\Delta\nx_n^{\\mathrm{c}}\\right)^2 \\\\\n&amp;=\\frac{m \\varepsilon}{2} \\sum_{n=1}^N \\frac{\\left(\\Delta\nx_n^{\\mathrm{c}}\\right)^2}{\\varepsilon^2} \\\\\n&amp;=\\frac{m \\varepsilon}{2}\n\\sum_{n=1}^N\\left(\\dot{x}_n^{\\mathrm{c}}\\right)^2 \\\\\n&amp;\\stackrel{\\varepsilon \\rightarrow 0}{=} \\frac{m}{2}\n\\int_{t_0}^t\\left(\\dot{x}^{\\mathrm{c}}\\right)^2 \\mathrm{~d} \\tau\n\\end{align}$$\n经典自由粒子解的 ẋc 是一个常数,\n且知道 $\\dot{x}^{\\mathrm{c}}=\\frac{x-x_0}{t-t_0}$。所以：\n$$\\begin{align}\nS^{\\mathrm{c}}&amp;=\\frac{m}{2}\n\\int_{t_0}^t\\left(\\dot{x}^{\\mathrm{c}}\\right)^2 \\mathrm{~d} \\tau \\\\\n&amp;=\\frac{m}{2}\\left(\\frac{x-x_0}{t-t_0}\\right)^2 \\int_{t_0}^t\n\\mathrm{~d} \\tau\\\\\n&amp;=\\frac{m\\left(x-x_0\\right)^2}{2\\left(t-t_0\\right)}\n\\end{align}$$\n端点给定，并且把经典路径分离出来，因此可以将传播子写为：\n$$\\begin{align}\nK\\left(x, t ; x_0, t_0\\right)=e^{i\n\\frac{S^{\\mathrm{c}}}{\\hbar}}\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\int e^{\\frac{i}{\\hbar} S^{\\prime}}\n\\mathrm{d} y_1 \\cdots \\mathrm{d} y_{N-1}\n\\end{align}$$\n接下来要化简的是S′，考虑到在两端点附近y0 = yN = 0：\n$$\\begin{align}\nS^{\\prime} &amp; =\\frac{m}{2 \\varepsilon}\n\\sum_{n=1}^N\\left(y_n-y_{n-1}\\right)^2 \\\\\n&amp; =\\frac{m}{2\n\\varepsilon}\\left[y_1^2+\\left(y_2-y_1\\right)^2+\\cdots+\\left(y_{N-1}-y_{N-2}\\right)^2+y_{N-1}^2\\right]\n\\\\\n&amp; =\\frac{m}{2 \\varepsilon}\\left(2 \\sum_{n=1}^{N-1} y_n^2-2\n\\sum_{n=1}^{N-1} y_n y_{n-1}\\right) \\\\\n&amp; =\\frac{m}{2 \\varepsilon} \\sum_{n=1}^{N-1}\\left(2 y_n^2-2 y_n\ny_{n-1}\\right) \\\\\n&amp;=\\frac{m}{2 \\varepsilon} \\sum_{n, m=1}^{N-1} y_m A_{m n}\ny_n=\\frac{m}{2 \\varepsilon} y^{\\mathrm{T}} A y\n\\end{align}$$\n其中A是一个实对称矩阵，Amn = 2δm, n − δm, n − 1 − δm − 1, n，如果不去掉端点的话，就会造成不是一个实对称矩阵。既然已经写成对称矩阵的形式了，那接下来就是精确对角化，将其耦合项解耦，从而方便积分。\n$$\\begin{align}\nR^{\\mathrm{T}} A R=\\Lambda=\\operatorname{diag}\\left(\\lambda_1,\n\\lambda_2, \\cdots, \\lambda_{N-1}\\right),\n\\end{align}$$\n其中 R 是正交矩阵，满足\nRTR = |R| = 1\n同时注意么正变换不改变本征值:\n$$\\begin{align}\n&amp;A \\varphi=\\lambda \\varphi \\\\\n&amp;\\Rightarrow R^{\\mathrm{T}} A R R^{\\mathrm{T}} \\varphi=\\lambda\nR^{\\mathrm{T}} \\varphi \\\\\n&amp;\\Rightarrow \\Lambda \\varphi^{\\prime}=\\lambda \\varphi^{\\prime}\n\\end{align}$$\n令:\n$$\\begin{align}\ny=R u \\Rightarrow y^{\\mathrm{T}} A y=u^{\\mathrm{T}} R^{\\mathrm{T}} A R\nu=u^{\\mathrm{T}} \\Lambda u=\\sum_{n=1}^{N-1} \\lambda_n u_n^2\n\\end{align}$$\n再进行变量代换:\n$$\\begin{align}\n\\mathrm{d} y_1 \\cdots \\mathrm{d} y_{N-1}&amp;=|\\operatorname{det} R|\n\\mathrm{d} u_1 \\cdots \\mathrm{d} u_{N-1} \\\\\n&amp;=\\mathrm{d} u_1 \\cdots \\mathrm{d} u_{N-1}\n\\end{align}$$\n因此传播子可以写为：\n$$\\begin{align}\nK\\left(x, t ; x_0, t_0\\right) &amp; =e^{i\n\\frac{S^c}{\\hbar}}\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\int e^{i \\frac{m}{2 \\hbar\n\\varepsilon} \\sum_{n=1}^{N-1} \\lambda_n u_n^2} \\mathrm{~d} u_1 \\cdots\n\\mathrm{d} u_{N-1} \\\\\n&amp; =e^{i \\frac{S^c}{\\hbar}}\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\prod_{n=1}^{N-1} \\int e^{-\\frac{m\n\\lambda_n}{2 i \\hbar \\varepsilon} u_n^2} \\mathrm{~d} u_n \\\\\n&amp; =e^{i \\frac{S^c}{\\hbar}}\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\prod_{n=1}^{N-1} \\sqrt{\\frac{2 \\pi i\n\\hbar \\varepsilon}{m \\lambda_n}}\\\\\n&amp;=e^{i \\frac{s^c}{\\hbar}} \\sqrt{\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}}\\left(\\prod_{n=1}^{N-1} \\lambda_n\\right)^{-\\frac{1}{2}}\n\\label{3_propagator}\n\\end{align}$$\n从$\\eqref{3_propagator}$可以看出，传播子最后只与特征值的连乘积有关，下面就是求解$\\prod_{n=1}^{N-1}\n\\lambda_n$的值。求解本征的可通过本征多项式直接得到。根据A 的本征多项式 |A − λI| = PN − 1(λ)，构造多项式：\n$$\\begin{align}\nP_n(\\lambda)=\\left|\\begin{array}{cccccc}\n2-\\lambda &amp; -1 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\\n-1 &amp; 2-\\lambda &amp; -1 &amp; 0 &amp; \\cdots &amp; 0 \\\\\n0 &amp; -1 &amp; 2-\\lambda &amp; -1 &amp; \\cdots &amp; 0 \\\\\n0 &amp; 0 &amp; -1 &amp; 2-\\lambda &amp; \\cdots &amp; 0 \\\\\n\\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\n\\\\\n0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 2-\\lambda\n\\end{array}\\right|\n\\end{align}$$\n将Pn(λ)从第一行展开得到：\n$$\\begin{align}\n&amp;P_n = (2-\\lambda)P_{n-1}-P_{n-2} \\\\\n&amp;P_n + (\\lambda-2)P_{n+1}+P_{n+2} = 0 \\label{2_P}\n\\end{align}$$\n定义一个能提升多项式阶数的线性算子L : LPn − 1 = Pn，然后将其代入递推关系$\\eqref{2_P}$：\n$$\\begin{align}\n0&amp;=[L^2+(\\lambda-2)L+1]P_n \\\\\n&amp;= (L-\\alpha)(L-\\beta)P_n \\\\\n\\alpha &amp;= \\frac{2-\\lambda+\\sqrt{\\lambda^2-4\\lambda}}{2} \\\\\n\\beta &amp;= \\frac{2-\\lambda-\\sqrt{\\lambda^2-4\\lambda}}{2} \\\\\n\\end{align}$$\n接下来分别求解(L − α)Pn = 0与(L − β)Pn = 0：\n$$\\begin{align}\n(L-\\alpha)P_n&amp;=0 \\\\\nLP_n&amp;=\\alpha P_n \\\\\nP_n&amp;=\\alpha P_{n-1}=\\alpha^2 P_{n-2} \\\\\n&amp;=\\alpha^n P_0^n = c_1\\alpha^n\n\\end{align}$$\n同理可得：\n$$\\begin{align}\nP_n&amp;=c_2\\beta^n\n\\end{align}$$\n因此通解为：\n$$\\begin{align}\nP_n&amp;=c_1\\alpha^n + c_2\\beta^n\n\\end{align}$$\n根据多项式P1 = 2 − λ与P2 = (2 − λ)2 − 1可知P1 = 1，由此解得：\n$$\\begin{align}\nc_1 &amp;= \\frac{\\alpha}{\\alpha-\\beta} \\\\\nc_2 &amp;= \\frac{-\\beta}{\\alpha-\\beta} \\\\\nP_n&amp;= \\frac{\\alpha^{n+1}-\\beta^{n+1}}{\\alpha-\\beta} \\\\\n&amp;=\\alpha^n+\\alpha^{n-1}\\beta+\\alpha^{n-2}\\beta^2+\\cdots+\\alpha\\beta^{n-1}+\\beta^n\n\\end{align}$$\n对于连乘积有$\\prod_{n=1}^{N-1}\n\\lambda_n=|A|$，根据|A − λI| = PN − 1(λ)可得到|A| = PN − 1(0) = N，并将结论代入$\\eqref{3_propagator}$：\n$$\\begin{align}\nK\\left(x, t ; x_0, t_0\\right) &amp;=e^{i \\frac{s^c}{\\hbar}}\n\\sqrt{\\frac{m}{2 \\pi i \\hbar \\varepsilon}}\\frac{1}{\\sqrt{N}} \\\\\n&amp;=e^{i \\frac{s^c}{\\hbar}} \\sqrt{\\frac{m}{2 \\pi i \\hbar (t-t_0)}} \\\\\n&amp;=\\sqrt{\\frac{m}{2 \\pi i \\hbar (t-t_0)}}\\exp{\\left[i\n\\frac{m(x-x_0)^2}{2\\hbar(t-t_0)}\\right]}\n\\end{align}$$\n谐振子 -\n利用对角化求解路径积分\n\n已完成内容：\n\n自由粒子的路径积分\n\n本部分的目标：\n\n讨论谐振子的路径积分\n\n\n对于一维谐振子势$V=\\frac{1}{2}m\\omega^2X^2$，研究从t0 → t的演化结果。位形空间传播子：\n$$\\begin{align}\nK\\left(x, t ; x_0, t_0\\right)&amp;=\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\int \\mathrm{D} x e^{i\n\\frac{S}{\\hbar}} \\\\\nS&amp;=\\int \\frac{1}{2} m v^2 - \\frac{1}{2}m\\omega^2X^2 dt\\\\\n&amp;=\\sum_{n=1}^N \\left[\\frac{1}{2} m \\frac{\\left(\\Delta\nx_n\\right)^2}{\\varepsilon^2} - \\frac{1}{2}m\\omega^2x_n^2\n\\right]\\varepsilon\n\\end{align}$$\n同样进行代换，分离为经典路径和扰动项xn = xnc + yn：\n$$\\begin{align}\nS&amp;=\\sum_{n=1}^N \\left[\\frac{1}{2} m \\frac{\\left(\\Delta\nx_n\\right)^2}{\\varepsilon^2} - \\frac{1}{2}m\\omega^2x_n^2\n\\right]\\varepsilon \\\\\n&amp;= \\sum_{n=1}^N \\left[\\left(\\Delta x_n\\right)^2 - \\omega^2x_n^2\n\\varepsilon^2\\right]\\frac{m}{2\\varepsilon} \\\\\n&amp;= \\sum_{n=1}^N \\left[\\left(\\Delta x_n^{\\mathrm{c}}+\\Delta\ny_n\\right)^2 - \\omega^2(x_n^{\\mathrm{c}}+y_n)^2\n\\varepsilon^2\\right]\\frac{m}{2\\varepsilon} \\\\\n&amp; \\begin{aligned}\n=&amp;\\sum_{n=1}^N \\left[\\left(\\Delta x_n^{\\mathrm{c}}\\right)^2 -\n\\omega^2(x_n^{\\mathrm{c}})^2 \\varepsilon^2\\right]\\frac{m}{2\\varepsilon}\n\\\\\n&amp;+ \\sum_{n=1}^N \\left[\\left(\\Delta y_n\\right)^2 - \\omega^2(y_n)^2\n\\varepsilon^2\\right]\\frac{m} {2\\varepsilon} \\\\\n&amp;+ \\sum_{n=1}^N \\left[2\\Delta x_n^{\\mathrm{c}}\\Delta y_n - 2\\omega^2\nx_n^{\\mathrm{c}}y_n \\varepsilon^2\\right]\\frac{m}{2\\varepsilon}\\\\\n\\end{aligned}\n\\end{align}$$\n同样分为三部分：\n$$\\begin{align}\n&amp; S^{\\mathrm{c}}=\\frac{m}{2 \\varepsilon}\n\\sum_{n=1}^N\\left[\\left(\\Delta x_n^{\\mathrm{c}}\\right)^2-\\varepsilon^2\n\\omega^2\\left(x_n^{\\mathrm{c}}\\right)^2\\right] \\\\\n&amp; S^{\\prime}=\\frac{m}{2 \\varepsilon} \\sum_{n=1}^N\\left[\\left(\\Delta\ny_n\\right)^2-\\varepsilon^2 \\omega^2 y_n^2\\right] \\\\\n&amp; S^{\\times}=\\frac{m}{2 \\varepsilon} \\sum_{n=1}^N\\left(2 \\Delta\nx_n^{\\mathrm{c}} \\Delta y_n-\\varepsilon^2 \\omega^2 2 x_n^{\\mathrm{c}}\ny_n\\right)\n\\end{align}$$\n先利用yn的边界条件计算交叉项S×：\n$$\\begin{align}\nS^{\\times} &amp; =\\frac{m}{2 \\varepsilon} \\sum_{n=1}^N\\left(2 \\Delta\nx_n^{\\mathrm{c}} \\Delta y_n-\\varepsilon^2 \\omega^2 2 x_n^{\\mathrm{c}}\ny_n\\right) \\\\\n&amp; =m\n\\sum_{n=1}^N\\left[\\dot{x}_n^{\\mathrm{c}}\\left(y_n-y_{n-1}\\right)-\\varepsilon\n\\omega^2 x_n^{\\mathrm{c}} y_n\\right] \\\\\n&amp; =m \\sum_{n=1}^N \\dot{x}_n^{\\mathrm{c}} y_n-m \\sum_{n=1}^N\n\\dot{x}_n^{\\mathrm{c}} y_{n-1}-m \\sum_{n=1}^N \\varepsilon \\omega^2\nx_n^{\\mathrm{c}} y_n \\\\\n&amp; \\stackrel{y_{N=0}}{=} m \\sum_{n=1}^{N-1} \\dot{x}_n^{\\mathrm{c}}\ny_n-m \\sum_{n=0}^{N-1} \\dot{x}_{n+1}^{\\mathrm{c}} y_n-m \\sum_{n=1}^{N-1}\n\\varepsilon \\omega^2 x_n^{\\mathrm{c}} y_n \\\\\n&amp; \\stackrel{y_{0=0}}{=} m \\sum_{n=1}^{N-1} \\dot{x}_n^{\\mathrm{c}}\ny_n-m \\sum_{n=1}^{N-1} \\dot{x}_{n+1}^{\\mathrm{c}} y_n-m \\sum_{n=1}^{N-1}\n\\varepsilon \\omega^2 x_n^{\\mathrm{c}} y_n \\\\\n&amp; =-\\left(m \\varepsilon \\sum_{n=1}^{N-1}\n\\frac{\\dot{x}_{n+1}^{\\mathrm{c}}-\\dot{x}_n^{\\mathrm{c}}}{\\varepsilon}\ny_n+\\sum_{n=1}^{N-1} m \\varepsilon \\omega^2 x_n^{\\mathrm{c}} y_n\\right)\n\\\\\n&amp; =-\\varepsilon \\sum_{n=1}^{N-1}\\left(m\n\\ddot{x}_{n+1}^{\\mathrm{c}}+m \\omega^2 x_n^{\\mathrm{c}}\\right) y_n\n\\end{align}$$\n根据经典方程$m\\ddot{x}^{\\mathrm{c}}=-\\frac{\\partial V}{\\partial\nx^{\\mathrm{c}}}=-m\\omega^2x^\\mathrm{c}$，则有S× = 0。\n再计算经典路径Sc：\n$$\\begin{align}\nS^{\\mathrm{c}} &amp; =\\frac{m}{2 \\varepsilon}\n\\sum_{n=1}^N\\left[\\left(\\Delta x_n^{\\mathrm{c}}\\right)^2-\\varepsilon^2\n\\omega^2\\left(x_n^{\\mathrm{c}}\\right)^2\\right] \\\\\n&amp; =\\frac{m \\varepsilon}{2}\n\\sum_{n=1}^N\\left[\\left(\\dot{x}_n^{\\mathrm{c}}\\right)^2-\\omega^2\\left(x_n^{\\mathrm{c}}\\right)^2\\right]\n\\\\\n&amp;=\\frac{m}{2}\n\\int_{t_0}^t\\left[\\left(\\dot{x}^{\\mathrm{c}}\\right)^2-\\omega^2\\left(x^{\\mathrm{c}}\\right)^2\\right]\n\\mathrm{d} \\tau \\label{3_classical}\n\\end{align}$$\n接下来计算经典路径的形式：\n$$\\begin{align}\nm\\ddot{x}^{\\mathrm{c}}&amp;=-m\\omega^2 x^{\\mathrm{c}} \\\\\nx^{\\mathrm{c}}(t_0) &amp;= x_0 \\\\\nx^{\\mathrm{c}}(t) &amp;= x\n\\end{align}$$\nDSolve[&#123;m D[x[t], &#123;t, 2&#125;] == -m \\[Omega]^2 x[t], x[t0] == x0,    x[tend] == xend&#125;, x[t], t] // Simplify\n得到结果：\n$$\\begin{align}\nx^{\\mathrm{c}} &amp; =\\frac{x \\sin\n\\left[\\omega\\left(\\tau-t_0\\right)\\right]-x_0 \\sin [\\omega(\\tau-t)]}{\\sin\n\\left[\\omega\\left(t-t_0\\right)\\right]} \\label{classical}\n\\end{align}$$\n将经典路径的表达形式$\\eqref{classical}$代入经典路径的路径积分中$\\eqref{3_classical}$，可以得到路径积分的具体表达式。\nx[t] = -Csc[(t0 - tend) \\[Omega]] (xend Sin[(t - t0) \\[Omega]] -      x0 Sin[(t - tend) \\[Omega]]);Integrate[  m/2 (D[x[t], &#123;t, 1&#125;]^2 - \\[Omega]^2 x[t]^2), &#123;t, t0,    tend&#125;] // FullSimplify\n$$\\begin{align}\nS^{\\mathrm{C}}&amp;=\\frac{m \\omega}{2}\\left\\{\\left(x^2+x_0^2\\right) \\cot\n\\left[\\omega\\left(t-t_0\\right)\\right]-2 x x_0 \\csc\n\\left[\\omega\\left(t-t_0\\right)\\right]\\right\\} \\\\\nK\\left(x, t ; x_0, t\\right)&amp;=\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\int e^{i\n\\frac{\\left(S^c+S^{\\prime}+S^{\\times}\\right)}{\\hbar}} \\mathrm{d} x_1\n\\cdots \\mathrm{d} x_{N-1} \\\\\n&amp; =e^{i \\frac{S^c}{\\hbar}}\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\int e^{i \\frac{S^{\\prime}}{\\hbar}}\n\\mathrm{d} y_1 \\cdots \\mathrm{d} y_{N-1}\n\\end{align}$$\n路径 xnc = xc(tn)\n都是给定的,故: dxnc = 0 ⇒ dxn = d(xnc + yn) = dyn\n接下来需要解决的是：\n$$\\begin{align}\nS^{\\prime}=\\frac{m}{2 \\varepsilon} \\sum_{n=1}^N\\left[\\left(\\Delta\ny_n\\right)^2-\\varepsilon^2 \\omega^2 y_n^2\\right] \\label{3_Sprime}\n\\end{align}$$\n首先将Δyn利用差分的办法改写为矩阵形式：\n$$\\begin{align}\n\\sum_{n=1}^N\\left(\\Delta y_n\\right)^2 &amp;\n=\\sum_{n=1}^N\\left(y_n-y_{n-1}\\right)^2 \\\\\n&amp; =\\sum_{n=1}^N y_n^2+\\sum_{n=1}^N y_{n-1}^2-2 \\sum_{n=1}^N y_n\ny_{n-1} \\\\\n&amp; \\stackrel{y_{N=0}}{=} \\sum_{n=1}^{N-1} y_n^2+\\sum_{n=0}^{N-1}\ny_n^2-2 \\sum_{n=1}^{N-1} y_n y_{n-1} \\\\\n&amp; \\stackrel{y_0=0}{=} \\sum_{n=1}^{N-1} y_n^2+\\sum_{n=1}^{N-1}\ny_n^2-2 \\sum_{n=1}^{N-1} y_n y_{n-1}\\\\\n&amp; =\\sum_{n=1}^{N-1}\\left(2 y_n^2-2 y_n y_{n-1}\\right)=y^{\\mathrm{T}}\nA y \\\\\nA_{mn}&amp;= 2\\delta_{m,n}-\\delta_{m-1,n}-\\delta_{m,n-1}\n\\end{align}$$\n与自由粒子一样，因为是实正定矩阵，可以将其对角化。\n$$\\begin{align}\nK\\left(x, t ; x_0, t\\right) = &amp; e^{i\n\\frac{S^c}{\\hbar}}\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\int e^{i \\frac{m}{2 \\hbar\n\\varepsilon}\\left(y^{\\mathrm{T}} A y-\\varepsilon^2 \\omega^2\ny^{\\mathrm{T}} y\\right)} \\mathrm{d} y_1 \\cdots \\mathrm{d} y_{N-1} \\\\\n= &amp; e^{i \\frac{S^c}{\\hbar}}\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\int e^{i \\frac{m}{2 \\hbar\n\\varepsilon} \\sum_{n=1}^{N-1}\\left(\\lambda_n-\\varepsilon^2\n\\omega^2\\right) u_n^2} \\mathrm{~d} u_1 \\cdots \\mathrm{d} u_{N-1} \\\\\n= &amp; e^{i \\frac{S^c}{\\hbar}}\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\prod_{n=1}^{N-1} \\int\ne^{-\\frac{m\\left(\\lambda_n-\\varepsilon^2 \\omega^2\\right)}{2 i \\hbar\n\\varepsilon} u_n^2} \\mathrm{~d} u_n \\\\\n= &amp; e^{i \\frac{S^c}{\\hbar}}\\left(\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}\\right)^{\\frac{N}{2}} \\prod_{n=1}^{N-1} \\sqrt{\\frac{2 \\pi i\n\\hbar \\varepsilon}{m\\left(\\lambda_n-\\varepsilon^2 \\omega^2\\right)}}\\\\\n=&amp;e^{i \\frac{S^c}{\\hbar}} \\sqrt{\\frac{m}{2 \\pi i \\hbar\n\\varepsilon}}\\left[\\prod_{n=1}^{N-1}\\left(\\lambda_n-\\varepsilon^2\n\\omega^2\\right)\\right]^{-\\frac{1}{2}}\n\\end{align}$$\n接下来解决连乘积$\\prod_{n=1}^{N-1}\\left(\\lambda_n-\\varepsilon^2\n\\omega^2\\right)$，对$\\eqref{3_Sprime}$的本征多项式入手，与自由粒子的区别在于对角线上会多出来一项：\n$$\\begin{align}\nP_n(\\lambda)=\\left|\\begin{array}{cccccc}\n2-\\varepsilon^2 \\omega^2-\\lambda &amp; -1 &amp; 0 &amp; 0 &amp; \\cdots\n&amp; 0 \\\\\n-1 &amp; 2-\\varepsilon^2 \\omega^2-\\lambda &amp; -1 &amp; 0 &amp; \\cdots\n&amp; 0 \\\\\n0 &amp; -1 &amp; 2-\\varepsilon^2 \\omega^2-\\lambda &amp; -1 &amp; \\cdots\n&amp; 0 \\\\\n0 &amp; 0 &amp; -1 &amp; 2-\\varepsilon^2 \\omega^2-\\lambda &amp; \\cdots\n&amp; 0 \\\\\n\\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\n\\\\\n0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 2-\\varepsilon^2\n\\omega^2-\\lambda\n\\end{array}\\right|\n\\end{align}$$\n对第一行进行展开，可以得到递推关系：\n$$\\begin{align}\n&amp; P_n(\\lambda) = (2-\\varepsilon^2\n\\omega^2-\\lambda)P_{n-1}(\\lambda)-P_{n-2}(\\lambda) \\\\\n&amp; P_{n+2}(\\lambda)+ P_{n}(\\lambda) + (\\varepsilon^2\n\\omega^2+\\lambda-2)P_{n+1}(\\lambda) = 0 \\label{3_ditui}\n\\end{align}$$\n定义线性算子LPn(λ) = Pn + 1(λ)，并将其代入递推关系可以得到：\n$$\\begin{align}\n&amp;\\left[L^2+ (\\varepsilon^2\n\\omega^2+\\lambda-2)L+1\\right]P_{n}(\\lambda) = 0\n\\end{align}$$\n进行分解：\n$$\\begin{align}\n(L-\\alpha)(L-\\beta)P_{n}(\\lambda) &amp;= \\left[L^2+ (\\varepsilon^2\n\\omega^2+\\lambda-2)L+1\\right]P_{n}(\\lambda) \\\\\n\\alpha &amp;= \\frac{1}{2} \\left(-\\lambda +\\sqrt{\\left(\\lambda +\\omega ^2\n\\varepsilon ^2-2\\right)^2-4}-\\omega ^2 \\varepsilon ^2+2\\right) \\\\\n\\beta &amp;= \\frac{1}{2} \\left(-\\lambda -\\sqrt{\\left(\\lambda +\\omega ^2\n\\varepsilon ^2-2\\right)^2-4}-\\omega ^2 \\varepsilon ^2+2\\right)\n\\end{align}$$\n接下来分别求解(L − β)Pn = 0与(L − α)Pn = 0:\n$$\\begin{aligned}\n(L-\\alpha)P_{n}&amp;=0 \\\\\nLP_{n} &amp;= \\alpha P_{n}\\\\\nP_{n+1} &amp;=\\alpha P_{n} \\\\\nP_{n} &amp;= \\alpha P_{n-1} = \\alpha^n P_0(\\alpha) \\\\\nP_{n} &amp;= \\beta P_{n-1} = \\beta^n P_0(\\beta) \\\\\n\\end{aligned}$$\n因此P通项写为：\nPn = c1αn + c2βn\n代入初始条件：\n$$\\begin{align}\nP_1(\\lambda) &amp;= 2-\\varepsilon^2 \\omega^2-\\lambda \\\\\nP_2(\\lambda) &amp;= (2-\\varepsilon^2 \\omega^2-\\lambda)^2 - 1 \\\\\n\\end{align}$$\n由递推关系$\\eqref{3_ditui}$可以得到P0 = 1，Pn的表达式：\n$$\\begin{align}\nc_1 &amp;= -\\frac{\\beta +\\lambda +\\omega ^2 \\varepsilon ^2-2}{\\alpha\n-\\beta }\\\\\nc_2 &amp;= \\frac{\\alpha +\\lambda +\\omega ^2 \\varepsilon ^2-2}{\\alpha\n-\\beta } \\\\\nP_{n}(\\lambda) &amp;= c_1 \\alpha^n+ c_2 \\beta^n \\\\\n&amp;= \\frac{\\beta ^n \\left(\\alpha -1\\right)-\\alpha ^n \\left(\\beta\n-1\\right)}{\\alpha-\\beta }\n\\end{align}$$\n通过以上讨论已经成功将特征多项$\\eqref{3_ditui}$通项表达形式写出来。接下来需要具体写出\nα 与 β\n的表达形式。结合需要具体求解的问题$\\prod_{n=1}^{N-1}\\left(\\lambda_n-\\varepsilon^2\n\\omega^2\\right)=|P_{N-1}(\\lambda=0)|$，可知λ = 0:\n$$\\begin{align}\n\\lambda &amp;= 0 \\\\\n\\alpha &amp;= \\frac{1}{2} \\left(\\sqrt{\\left(\\omega ^2 \\varepsilon\n^2-2\\right)^2-4}-\\omega ^2 \\varepsilon ^2+2\\right) \\\\\n&amp;\\stackrel{\\varepsilon \\to 0}{=} \\frac{1}{2}\n\\left(\\omega  \\varepsilon\\sqrt{-4}+2\\right)\\\\\n\\beta &amp;= \\frac{1}{2} \\left( -\\sqrt{\\left(\\omega ^2 \\varepsilon\n^2-2\\right)^2-4}-\\omega ^2 \\varepsilon ^2+2\\right) \\\\\n&amp;\\stackrel{\\varepsilon \\to 0}{=} \\frac{1}{2} \\left(-\\omega\n\\varepsilon\\sqrt{-4}+2\\right)\\\\\n\\end{align}$$\n可以得到：\n$$\\begin{align}\n\\prod_{n=1}^{N-1}\\left(\\lambda_n-\\varepsilon^2\n\\omega^2\\right)&amp;=P_{N-1}(\\lambda=0) \\\\\n&amp;= \\frac{(1+i \\omega \\varepsilon)^N-(1-i \\omega \\varepsilon)^N}{1+i\n\\omega \\varepsilon-1+i \\omega \\varepsilon} \\\\\n&amp;= \\frac{1}{2 i \\omega \\varepsilon}\\left\\{\\left[1+\\frac{i\n\\omega\\left(t-t_0\\right)}{N}\\right]^N-\\left[1-\\frac{i\n\\omega\\left(t-t_0\\right)}{N}\\right]^N\\right\\} \\\\\n&amp; \\stackrel{N \\rightarrow \\infty}{=} \\frac{1}{2 i \\omega\n\\varepsilon}\\left[e^{i \\omega\\left(t-t_0\\right)}-e^{-i\n\\omega\\left(t-t_0\\right)}\\right] \\\\\n&amp;=\\frac{\\sin \\left[\\omega\\left(t-t_0\\right)\\right]}{\\omega\n\\varepsilon}\n\\end{align}$$\n所以谐振子的传播子写为：\n$$\\begin{align}\nK\\left(x, t ; x_0, t_0\\right)&amp;=e^{i \\frac{S^c}{\\hbar}} \\sqrt{\\frac{m\n\\omega}{2 \\pi i \\hbar \\sin \\left[\\omega\\left(t-t_0\\right)\\right]}} \\\\\nS^{\\mathrm{c}}&amp;=\\frac{m \\omega}{2}\\left\\{\\left(x^2+x_0^2\\right) \\cot\n\\left[\\omega\\left(t-t_0\\right)\\right]-2 x x_0 \\csc\n\\left[\\omega\\left(t-t_0\\right)\\right]\\right\\}\n\\end{align}$$\n应该考虑相位了，但现在还没出现问题，之再说吧。详细讨论看上面引用的内容。\n路径积分蒙特卡洛\n参考： * 路径积分蒙特卡洛\nPIMC\n考虑量子力学中的哈密顿量以及波函数：\n$$\\begin{align}\nH&amp;=-\\hbar^2 \\sum_i \\frac{1}{2 m_i} \\frac{\\partial^2}{\\partial\n\\mathbf{r}_i^2}+V(\\mathcal{R}) \\\\\n\\psi(\\mathcal{R}, t)&amp;=\\left\\langle\\mathcal{R}\\left|e^{-i t H /\n\\hbar}\\right| \\psi\\right\\rangle\n\\end{align}$$\n在使用蒙卡数值计算的过程中存在两个问题： *\n指数是复数，不能用使用正实数概率分布表示 * H是量子力学算符，动能与势能不对易\nContinuing to Imaginary Time\n解决复数问题。\n通过引入虚时τ = −it，将复数变为一个实数处理，这种做法也出现在扩散蒙特卡洛（diffusion\nMonte Carlo, DMC）。通过定义配分函数，产生与统计力学的联系：\n$$\\begin{align}\nZ(\\beta)&amp;=\\int d^{N d}\n\\mathcal{R}\\left\\langle\\mathcal{R}\\left|e^{-\\tau H / \\hbar}\\right|\n\\mathcal{R}\\right\\rangle=\\operatorname{Tr} e^{-\\beta H}, \\quad\n\\beta=\\frac{\\tau}{\\hbar} \\\\\nk_{\\mathrm{B}} T&amp;=1 / \\beta=\\hbar / \\tau\n\\end{align}$$\nDiscretizing the Time\nDimension\n解决不对易的问题。\n将时间t放在M的时间格点上，Δτ = τ/M，这样有M − 1个中间时间。在每一个中间的时间步骤中都有完整的本征态：\n$$\\begin{align}\n\\mathbf{1}=\\int d^{N d}\n\\mathcal{R}_i\\left|\\mathcal{R}_i\\right\\rangle\\left\\langle\\mathcal{R}_i\\right|,\n\\quad i=1, \\ldots, M-1\n\\end{align}$$\n然后沿着时间的顺序将配分函数分解：\n$$\\begin{align}\n&amp; Z(\\beta)= \\int d^{N d}\n\\mathcal{R}\\left\\langle\\mathcal{R}\\left|e^{-\\tau H / \\hbar}\\right|\n\\mathcal{R}\\right\\rangle \\\\\n&amp;=\\int d \\mathcal{R}_0 \\int d \\mathcal{R}_1 \\ldots \\int d\n\\mathcal{R}_{M-1}\\left\\langle\\mathcal{R}_0\\left|e^{-\\Delta \\tau H /\n\\hbar}\\right| \\mathcal{R}_{M-1}\\right\\rangle\\times\n\\ldots\\times\\left\\langle\\mathcal{R}_2\\left|e^{-\\Delta \\tau H /\n\\hbar}\\right|\n\\mathcal{R}_1\\right\\rangle\\left\\langle\\mathcal{R}_1\\left|e^{-\\Delta \\tau\nH / \\hbar}\\right| \\mathcal{R}_0\\right\\rangle\n\\end{align}$$\n根据时间分割，将一段时间的演化过程，转变为几个“瞬间”的演化过程Δτ → 0。这其实就是路径积分的思想。\n接下来通过这样的小量，解决不对易的关系。根据 Baker-Campbell-Hausdorff\n(BCH)定理：\n$$\\begin{align}\ne^{\\mathcal{A}} e^{\\mathcal{B}}&amp;=e^{\\mathcal{C}} \\\\\n\\mathcal{C}&amp;=\\mathcal{A}+\\mathcal{B}+\\frac{1}{2}[\\mathcal{A},\n\\mathcal{B}]+\\cdots\n\\end{align}$$\n把这个关系用在短时演化的过程中：\n$$\\begin{align}\n\\mathcal{C}&amp;=-\\Delta \\tau H / \\hbar\\\\\n\\mathcal{B}&amp;=-\\Delta \\tau V / \\hbar\\\\\n\\mathcal{A}&amp;=-\\Delta \\tau K / \\hbar \\\\\nK&amp;=-\\hbar^2 \\sum_i \\frac{1}{2 m_i} \\frac{\\partial^2}{\\partial\n\\mathbf{r}_i^2}\n\\end{align}$$\n通过BCH定理可以知道，将H分为两项，需要计算交叉项。但是这个交叉项是Δτ的高阶小量可以直接忽略。\n$$\\begin{align}\n\\left\\langle\\mathcal{R}_1\\left|e^{-\\Delta \\tau H / \\hbar}\\right|\n\\mathcal{R}_0\\right\\rangle\n&amp;\\simeq\\left\\langle\\mathcal{R}_1\\left|e^{-\\Delta \\tau K / \\hbar}\ne^{-\\Delta \\tau V / \\hbar}\\right|\n\\mathcal{R}_0\\right\\rangle=\\left\\langle\\mathcal{R}_1\\left|e^{-\\Delta\n\\tau K / \\hbar}\\right| \\mathcal{R}_0\\right\\rangle e^{-\\Delta \\tau\nV\\left(\\mathcal{R}_0\\right) / \\hbar} \\\\\n\\left\\langle\\mathcal{R}_1\\left|e^{-\\Delta \\tau K / \\hbar}\\right|\n\\mathcal{R}_0\\right\\rangle &amp; =\\int d \\mathcal{P}_0 \\int d\n\\mathcal{P}_1\\left\\langle\\mathcal{R}_1 \\mid\n\\mathcal{P}_1\\right\\rangle\\left\\langle\\mathcal{P}_1\\left|e^{-\\Delta \\tau\nK / \\hbar}\\right| \\mathcal{P}_0\\right\\rangle\\left\\langle\\mathcal{P}_0\n\\mid \\mathcal{R}_0\\right\\rangle \\\\\n&amp; =\\left(\\frac{m}{2 \\pi \\hbar \\Delta \\tau}\\right)^{N d / 2} \\exp\n\\left[-\\frac{m \\Delta \\tau}{2 \\hbar} \\sum_i\\left(\\frac{\\mathbf{r}_{i\n1}-\\mathbf{r}_{i 0}}{\\Delta \\tau}\\right)^2\\right]\n\\end{align}$$\nPath Integral Monte Carlo\nAlgorithm\n配分函数的最终表达式为：\n$$\\begin{align}\nZ(\\beta) \\simeq\\left(\\frac{m}{2 \\pi \\hbar \\Delta \\tau}\\right)^{M N d /\n2} \\int d \\mathcal{R}_0 \\int d \\mathcal{R}_1 \\ldots \\int d\n\\mathcal{R}_{M-1} \\quad \\times \\exp \\left\\{-\\frac{\\Delta \\tau}{\\hbar}\n\\sum_{j=0}^{M-1}\\left[\\frac{m}{2}\\left(\\frac{\\mathcal{R}_{j+1}-\\mathcal{R}_j}{\\Delta\n\\tau}\\right)^2+V\\left(\\mathcal{R}_j\\right)\\right]\\right\\}\n\\end{align}$$\n看这个形式，对比统计晶格中的形式。具有一定的对应关系，路径积分等价于晶格所有构型的求和，因此真正需要关心的是“能量项”：\n$$\\begin{align}\n\\sum_{j=0}^{M-1}\\left[\\frac{m}{2}\\left(\\frac{\\mathcal{R}_{j+1}-\\mathcal{R}_j}{\\Delta\n\\tau}\\right)^2+V\\left(\\mathcal{R}_j\\right)\\right]\n\\end{align}$$\n将每一格运动区间进行计算，从而得出最终的“能量”，更准确应该是作用量。然后利用\nMetropolis algorithm 进行重要性抽样，将不同权重的路径进行加权运算。\nCode\n以下是一个对于一维谐振子的实现，核心部分在sample模块中。这个实现，每次只对前一次路径中一步进行修改，然后接受概率设为exp(-DeltaE * Delta_t / hbar)，这里作者将ℏ = 1进行无量纲化了。\nclass PathIntegral:    def __init__(self, nt=100, tmax = 2*np.pi):        self.nt = nt        self.tmax = tmax        self.t = np.linspace(0, self.tmax, nt)        self.sample_idx = []            def sample(self, steps=100000):        # 1. initialize the path        x = np.zeros_like(self.t)        dt = self.t[1] - self.t[0]        ilist = np.random.choice(range(1, self.nt-1), size=steps)        dxlist = np.random.uniform(-1, 1, size=steps)        sampled = []                   # randomly pick x[i]        # do random walk x[i] -&gt; x[i] + r         # if DeltaE &lt; 0: accept        # elif DeltaE &gt; 0: accept with probability exp(-DeltaE * Delta_t / hbar)        for n in tqdm(range(steps)):            i = ilist[n]            dx = dxlist[n]                        #if x[i] + dx &lt;= 0.0: continue            ds = (self.kinetic_energy(x[i-1], x[i]+dx, dt) -                  self.kinetic_energy(x[i-1], x[i], dt) +                  self.kinetic_energy(x[i]+dx, x[i+1], dt) -                  self.kinetic_energy(x[i], x[i+1], dt) +                   self.potential(x[i]+dx) -                  self.potential(x[i])                 ) * dt                        if ds &lt; 0:                 x[i] = x[i] + dx            else:                r = np.random.rand()                if r &lt; np.exp(-ds):                    x[i] = x[i] + dx            sampled.append(x[i])                        self.sample_idx.append(i)        return sampled, self.sample_idx        def kinetic_energy(self, x1, x2, dt):        return 0.5 * (x2 - x1)**2 / dt**2        def potential(self, x):        return 0.5 * x**2        def plot(self):        tmax = self.tmax        plt.vlines(self.t, ymin=-tmax, ymax=tmax, color=&#x27;k&#x27;, linestyles=&#x27;dotted&#x27;, alpha=0.9)        dt = self.t[1] - self.t[0]        xi = np.random.uniform(-1, 1, self.nt)        xi[0] = 0        xi = np.cumsum(xi)        xi[-1] = 0        plt.plot(self.t, xi)        plt.ylabel(r&#x27;x $\\rightarrow$&#x27;, loc=&#x27;center&#x27;)        plt.xlabel(r&#x27;t $\\rightarrow$&#x27;, loc=&#x27;center&#x27;)\n","categories":["Physics"],"tags":["Quantum Field Theory","Path Integrals","Path Integrals Monte Carlo"]},{"title":"Replica in Random Matrix","url":"/2024/07/03/Phys/replica/replica_math/","content":"\nStieltjes变换概述\n定义\nStieltjes变换是一个用于分析和研究实数轴上测度（或函数）性质的工具。对于一个实数轴上的测度\nμ，它的Stieltjes变换 $ G(z) $\n定义为：\n$$ G(z) = \\int_{-\\infty}^{\\infty}\n\\frac{d\\mu(x)}{x - z} $$\n其中，$ z $ 是复平面上的一个点，且不在实数轴上的支撑集（即测度 μ 为零的区域）内。\n对于一个函数 $ f(x) $\n来说，如果我们把它视为测度的密度函数，则Stieltjes变换可以写成：\n$$ G(z) = \\int_{-\\infty}^{\\infty}\n\\frac{f(x) \\, dx}{x - z} $$\n逆变换\nStieltjes变换的逆变换用于从变换后的函数恢复原始测度或密度函数。对于谱密度\n$ (x) $，我们有：\n$$ \\rho(x) = \\lim_{\\epsilon \\to 0^+}\n\\frac{1}{\\pi} \\Im[G(x + i\\epsilon)] $$\n其中，$ $ 表示 $ G(z) $ 在 $ z = x + i$ 处的虚部。\n应用示例：Wigner矩阵的谱密度\n背景\nWigner矩阵是一个对称的随机矩阵，其元素是独立同分布的随机变量。设 $ W\n$ 是一个 $ N N $ 的Wigner矩阵，其元素 $ W_{ij} $ 满足以下条件： - $\nW_{ij} = W_{ji} $ - 对于 $ i j $， $ W_{ij} $ 是均值为零、方差为 $ $\n的独立随机变量 - 对角元素 $ W_{ii} $ 是均值为零、方差为 $ $\n的独立随机变量\nWigner半圆定律描述了在 $ N $\n的极限下，Wigner矩阵的特征值分布趋向于一个半圆分布。\n自洽方程推导\n随机矩阵 $ W $ 的Stieltjes变换 $ G(z) $ 定义为： $$ G_N(z) = \\frac{1}{N} \\sum_{i=1}^N\n\\frac{1}{\\lambda_i - z} $$\n在大尺寸极限下， $ G_N(z) $ 的期望值趋向于一个确定的值 $ G(z) ，满足自洽方程：$\nG(z) = $$\n这个方程通过以下步骤推导： 1. 将Stieltjes变换定义为矩阵的特征值求和。\n2. 利用矩阵的迹和逆矩阵的关系，展开逆矩阵。 3.\n在大尺寸极限下，假设矩阵元素足够小，进行平均场近似。 4.\n得到自洽方程，并通过二次方程求解。\n解析自洽方程\n解自洽方程 $ G(z) = ：$ G(z)^2 +\nzG(z) + 1 = 0 $$\n解得： $$ G(z) = \\frac{-z \\pm \\sqrt{z^2 -\n4}}{2} $$\n选择满足 $ $ 的分支： $$ G(z) = \\frac{-z +\n\\sqrt{z^2 - 4}}{2} $$\n恢复谱密度\n根据逆Stieltjes变换公式，谱密度 $ (x) $ 为： $$ \\rho(x) = \\frac{1}{\\pi} \\text{Im}[G(x +\ni\\epsilon)] $$\n代入 $ G(z) $ 的表达式，计算得： $$\n\\rho(x) = \\frac{1}{2\\pi} \\sqrt{4 - x^2} $$\n这正是Wigner半圆分布的谱密度。\n总结\nStieltjes变换在随机矩阵理论中是一个强大的工具，特别适用于谱密度的计算。通过Stieltjes变换，可以将实数轴上的谱密度问题转化为复平面上的解析问题，利用其逆变换可以从复平面上的函数恢复原始的谱密度，从而简化了复杂的计算过程。\n","categories":["Physics"],"tags":["Spin Glass","Replica Method","Random Matrix"]},{"title":"Do Two AI Scientists Agree?","url":"/2025/05/29/ai4sci/AISciAgree/AISciAgree/","content":"神经网络通过数据学习规律，会学习到什么规律？本文提出了新的神经网络MASS（Multi-physics\nAI Scalar\nScientist）用以学习网络从数据中学到的模型信息。这篇工作属于PINN。\n文献： * Do Two AI\nScientists Agree? * 源代码GitHub * Hamiltonian Neural Networks\n* HNN GitHub *\nLagrangian Neural\nNetworks * LNN GitHUb\n\n这篇文章主要是模型融合工作，在 PINNs 中有两个经典工作—— Hamiltonian\nNeural Networks 和 Lagrangian Neural\nNetworks，这两个网络分别基于哈密顿力学和拉格朗日力学构建。适用于处理不同的力学体系。在这两个模型的基础上，作者提出了融合的算法新思路——MASS。\nHamiltonian Neural Networks\n\n传统思路，是将运动轨迹视为时间序列，通过神经网络直接预测之后轨迹。现在减少神经网络的压力，让其预测哈密顿量，通过哈密顿方程更新之后的运动轨迹。如上图所示，模型预测输出为Hθ。\n&#x27;&#x27;&#x27;NEURAL HAMILTONIAN-STLE VECTOR FIELD&#x27;&#x27;&#x27;F1, F2 = self.forward(x) # traditional forward passconservative_field = torch.zeros_like(x) # start out with both components set to 0solenoidal_field = torch.zeros_like(x)if self.field_type != &#x27;solenoidal&#x27;:    dF1 = torch.autograd.grad(F1.sum(), x, create_graph=True)[0] # gradients for conservative field    conservative_field = dF1 @ torch.eye(*self.M.shape)if self.field_type != &#x27;conservative&#x27;:    dF2 = torch.autograd.grad(F2.sum(), x, create_graph=True)[0] # gradients for solenoidal field    solenoidal_field = dF2 @ self.M.t()\nLagrangian Neural Networks\n\n神经网络直接预测$\\ddot{q}$。\nMASS\n\n这篇文章的作者构建三种层次的网络，首先将数据处理为特征数据，然后将特征数据进行“理论”处理，得到最后结果。这里所谓“理论”，是网络通过不同例子学习之后得到的能力。\n实际上没有脱离最原始堆数据量、寄希望于网络拟合能力的思路，通过混合架构，大量例子通过不同子网络和主要网络（所谓的理论网络）训练，得到最后的拟合能力。\n","categories":["Largent language Model","Physics-Informed Neural Networks"],"tags":["Multi-Agent","Prompt"]},{"title":"Design Topological Materials by Reinforcement Fine-Tuned Generative Model","url":"/2025/05/26/ai4sci/TopolRFT/TopolRFT/","content":"通过强化学习微调生成模型，使得生成的拓扑绝缘体和拓扑材料结构准确率上升。\nReference: * Design\nTopological Materials by Reinforcement Fine-Tuned Generative\nModel\n\n使用生成模型生成材料，其中有一些基本的问题： 1. 使用的是什么模型？ 2.\n输入和输出是什么？ 3. 数据如何得到以及数据规模大小？ 4.\n强化学习的reward是什么？ 5. 通过哪些实验指标说明有效性？\n数据集\n这篇文章采用了两种数据集： 文献Con-CDVAE:\nA method for the conditional generation of crystal\nstructures数据集Topological\nCrystals Database，该项目的代码仓库。\n文献A generative\nmodel for inorganic materials design数据集和代码链接Alex-MP datasets。\n模型\n采用模型SPACE GROUP\nCONSTRAINED CRYSTAL GENERATION，代码地址DiffCSP-PP。\n输入信息： &#123;    &quot;spacegroup_number&quot;: 58,    &quot;wyckoff_letters&quot;: [&quot;2a&quot;,&quot;2d&quot;,&quot;4g&quot;],    &quot;atom_types&quot;: [&quot;Mn&quot;,&quot;Li&quot;,&quot;O&quot;]&#125; 输出信息为结构文件。\nWorkflow\n\n\nworkflow\n\n使用生成扩散过程，逐步还原最初的模型。并且，为了增强正确率，结合PPO算法：\n$$\nJ^{\\mathrm{off}}(\\theta)=\\mathbb{E}_{\\tau\\sim\np_{\\theta^{\\prime}}}\\left[\\sum_{t=1}^{T}\\frac{p_{\\theta}({\\mathcal{M}}_{t-1}|{\\mathcal{M}}_{t})}{p_{\\theta^{\\prime}}({\\mathcal{M}}_{t-1}|{\\mathcal{M}}_{t})}r({\\mathcal{M}}_{0})\\right]\n$$\nResult\n  \n","categories":["AI for Science"],"tags":["Reinforcement Learning","Large Language Model","Fine Tuning"]},{"title":"Machine Learning with Graphs 读书笔记","url":"/2024/05/01/book/Machine_Learning_with_Graphs/Machine_Learning_with_Graphs/","content":"占位内容：整理《Machine Learning with\nGraphs》的读书笔记与要点摘录，稍后补充。\n","categories":["Book Notes"],"tags":["Graph Neural Networks","GNN"]},{"title":"Machine learning renormalization group for statistical physics","url":"/2024/08/21/ai4sci/MLRG/MLRG/","content":"通过构建三个网络学习实空间重整化过程中的参数变化。\nReference: * Machine learning\nrenormalization group for statistical physics\n\nNetwork\n\n\narchitecture of algorithm\n\n一共有三个网络，其中两个是 RBM，另一个是深度网络。这两个 RBM\n分别表示重整化前与重整化后的模型，可以给出波尔兹曼分布。在重整化变换前后分布应当是不变的，因此通过KL散度衡量这两个网络之间的距离，然而衡量KL散度存在困难，使用CD散度进行替代。\n那么这两个网络之间的重整化参数是如何确定的呢？这里引入了三个网络\nmoderator，用以将第一个网络参数转化为第第二个网络的参数，是学习重整化流的主要网络。\nAlgorithm\n算法流程为： 1. 通过参数J进行采样（HMC），得到一些用于训练的 sample。\n2. J 作为 fine-grained RBM 的参数。 3. 这些sample输入 fine-grained\nRBM，产生根据其概率分布的sample1。 4. 通过 Moderator 将 J 变化为\nJ’，输入进 corase-grained RBM。 5. 将 sample1 输入 corase-grained\nRBM，产生根据其概率分布的sample2。 6.\n根据sample2和sample1之间的概率分布区别作为loss。 7. 利用loss训练\nModerator。 8. 将 J’ 作为下一次循环的 J。\nRG\n\n\nlattice\n\n这里的重整化变换见上图中的阴影部分，a、b分别表示变换前后，绿色格点是sample的位置，蓝色和红色表示相互作用J。\n\n\ntensor\n\n这里存在一个问题，两个不同的网络结构，相互作用是如何进行转化的？上图将这个相互用进行分解，将自旋、对称性、相互作用系数进行分解。\nResult\n\n\nresult\n\n绘制出 RG flow，并且能够准确找到鞍点。\n","categories":["AI for Science"],"tags":["Spin Glass","Reinforcement Learning","Combinatorial Optimization Methods"]},{"title":"Policy Gradients In Reinforcement","url":"/2024/03/08/RL/PPO/PPO/","content":"文中有一些问题仍未处理，缺失具体代码的解读，对于TRPO算法的认知仍然存在不清楚的地方，高阶梯度怎么算的\nAbstract\n这是一篇关于策略梯度算法的总结。首先给出梯度策略，介绍其基本含义，但是初始方案存在一个问题，可以知道梯度变化的方向，不知道梯度的步长。然后，提出自然梯度算法，通过加入约束的方案计算出梯度的步长。接下来，Trust\nRegion Policy\nOptimization（TRPO）算法在此基础上进一步优化，进一步提出约束，使得满足该约束条件的样本可以稳定提升策略性能。最后，虽然TRPO十分优秀，但是大量的计算使其效率不高，因此进行简化提出Proximal\nPolicy Optimization（PPO）算法。\n基于值函数的强化学习：通过递归，求解bellman\n方程维护Q值（离散列表或者神经网络），每次选择动作会选择该状态下对应Q值最大的动作。使得期望奖励值最大。\n基于策略的强化学习：不再通过价值函数确定动作，而是直接学习策略本身，通过一组参数θ对策略进行参数化，并通过神经网络优化θ。\n\nReference: * 十分推荐的博客，其延伸阅读有很多关于策略梯度的资料Policy\nGradients In Reinforcement Learning Explained *\n基于策略强化学习的开篇鼻祖Simple\nStatistical Gradient-Following Algorithms for Connectionist\nReinforcement Learning * 自然梯度算法Natural\nGradient Works Efficiently in Learning * 对自然梯度算法很好的总结Natural Policy Gradients In\nReinforcement Learning Explained * CMU深度强化学习课程主页GitHub地址\n* Trust Region Policy\nOptimization * Proximal\nPolicy Optimization Algorithms * Approximately\nOptimal Approximate Reinforcement Learning * Berkeley深度强化学习课程主页 *\nEfficiently\nComputing the Fisher Vector Product in TRPO * 代码库Spinning Up in\nDeep RL\nPolicy\napproximation methods : Moving to stochastic policies\n在策略近似的方法中，忽略传统的价值函数，直接调整策略本身。通过θ（可能是神经网络参数）参数化策略πθ。\n需要解决的问题： 1. 如何评估策略的质量 2. 如何更新θ\n策略梯度算法有很多种，这篇文章聚焦于likelihood ratio policy\ngradients。这种算法的核心思想是将策略转化为一种概率分布πθ(a|s) = P(a|s; θ)，从而返回的不是一个单一的结果，而是动作的分布概率，然后进行采样。\nEstablishing the objective\nfunction\n在进行一系列决策之后，得到状态-动作轨迹τ = (s1, a1⋯sT, aT)，每一条轨迹有相应的概率P(τ)和积累回报R(τ) = ∑γtRt（γ是折扣率，Rt是t时刻回报），同时定义目标函数：\n$$\\begin{align}\nJ(\\theta)&amp;=\\mathbb{E}_{\\tau \\sim\\pi_{\\theta}}R(\\tau)=\\sum_\\tau\nP(\\tau;\\theta)R(\\tau) \\\\\n\\max_{\\theta}J(\\theta)&amp;=\\max_{\\theta}E_{\\tau\n\\sim\\pi_{\\theta}}R(\\tau)=\\max_{\\theta}\\sum_\\tau P(\\tau;\\theta)R(\\tau)\n\\end{align}$$\nDefining trajectory\nprobabilities\n接下来的主要任务是如何计算P(τ; θ)。\n需要处理两类概率： * 策略概率分布：πθ(a|s) = P(a|s; θ)，描述在给定状态与参数下，动作的概率。\n* 概率转移分布：P(st + 1|st, at)。在相同的状态下，作出相同的动作，环境也会以概率返回不同的状态。该参数描述在相同环境中，同一动作，下一状态分布的几率。\n轨迹τ在策略πθ(a|s)下发生的概率定义为：\n$$\\begin{align}\nP(\\tau;\\theta)=\\left[\\prod_{t=0}^T P(s_{t+1}|s_t,a_t)\\cdot\n\\pi_{\\theta}(a_t|s_t) \\right]\n\\end{align}$$\nDeriving the policy gradient\n为了得到maxθJ(θ)，可以利用求极值的方法（一阶导数为零），方法采用牛顿梯度迭代法。\n为了优化θ，计算目标参数J(θ)对θ的导数。\n$$\\begin{align}\n\\nabla_{\\theta}J(\\theta) &amp;= \\nabla_{\\theta} \\mathbb{E}_{\\tau\n\\sim\\pi_{\\theta}}R(\\tau)\\\\\n&amp;= \\sum_\\tau \\nabla_{\\theta} P(\\tau;\\theta)R(\\tau) \\\\\n&amp;= \\sum_\\tau P(\\tau;\\theta)\\frac{\\nabla_{\\theta}\nP(\\tau;\\theta)}{P(\\tau;\\theta)}R(\\tau) \\\\\n&amp;= \\sum_\\tau P(\\tau;\\theta) \\nabla_{\\theta} \\ln P(\\tau;\\theta)\nR(\\tau) \\\\\n&amp;= \\mathbb{E}_{\\tau \\sim\\pi_{\\theta}} R(\\tau)  \\nabla_{\\theta} \\ln\nP(\\tau;\\theta) \\\\\n&amp;= \\mathbb{E}_{\\tau \\sim\\pi_{\\theta}} R(\\tau)\n\\nabla_{\\theta}\\ln\\left[\\prod_{t=0}^T P(s_{t+1}|s_t,a_t)\\cdot\n\\pi_{\\theta}(a_t|s_t) \\right] \\\\\n&amp;= \\mathbb{E}_{\\tau \\sim\\pi_{\\theta}} R(\\tau)\n\\left[\\nabla_{\\theta}\\sum_{t=0}^T \\ln P(s_{t+1}|s_t,a_t)+\n\\nabla_{\\theta}\\sum_{t=0}^T\\ln\\pi_{\\theta}(a_t|s_t) \\right] \\\\\n&amp;= \\mathbb{E}_{\\tau \\sim\\pi_{\\theta}} R(\\tau)\n\\nabla_{\\theta}\\sum_{t=0}^T\\ln\\pi_{\\theta}(a_t|s_t) \\\\\n\\end{align}$$\n直接计算存在困难，需要近似处理： $$\\begin{align}\n\\nabla_{\\theta}J(\\theta) &amp;= \\mathbb{E}_{\\tau \\sim\\pi_{\\theta}}\nR(\\tau)  \\nabla_{\\theta} \\ln P(\\tau;\\theta) \\\\\n&amp;\\approx \\frac{1}{m}\\sum_{i=0}^m R(\\tau^i)  \\nabla_{\\theta} \\ln\nP(\\tau^i;\\theta) \\\\\n&amp;= \\frac{1}{m}\\sum_{i=0}^m R(\\tau^i) \\sum_{t^i=0}^{T^i}\n\\nabla_{\\theta} \\ln \\pi_{\\theta}(a_{t^i}|s_{t^i})\\\\\n&amp;\\approx \\frac{1}{n} \\sum_{i=1}^n R(t^i) \\nabla_{\\theta} \\ln\n\\pi_{\\theta}(a_{t^i}|s_{t^i})\n\\end{align}$$\n现在梯度完全可以计算，只需要给出策略πθ的定义，就可以计算出∇θJ(θ)，从而用策略梯度更新规则：\n$$\\begin{align}\n\\theta \\leftarrow \\theta + \\alpha \\nabla_{\\theta}J(\\theta)\n\\end{align}$$\nExamples: Softmax and\nGaussian policies\n为了说明以上策略的可行性，下面给出离散空间与连续空间的两个例子。其中ϕ(s, a)一个包含基本信息的向量，包含当前状态的信息与动作信息，θ为权重因子。假设一个最简单的网络：ϕ(s, a)T ⋅ θ，乘积结果就是对当前状态与动作的评估。\n基于以上假设，下面两种常见策略： * Softmax策略\n对于离散动作空间，多使用Softmax策略。定义如下： $$\\begin{align}\n  \\pi_{\\theta}(a|s) &amp;= \\frac{e^{\\phi(s,a)^T \\cdot\n\\theta}}{\\sum_{a'\\in A}e^{\\phi(s,a)^T \\cdot \\theta}}\n  \\end{align}$$\n对应策略的梯度为： $$\\begin{align}\n  \\nabla_\\theta \\ln \\pi_{\\theta}(a|s) = \\phi(s,a)- \\sum_{a'\\in\nA}\\pi_\\theta(a|s)\\phi(s,a')\n  \\end{align}$$\n\n高斯策略 对于连续动作空间，经常使用高斯策略。定义如下： $$\\begin{align}\n\\pi_{\\theta}(a|s) &amp;=\n\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(a-\\mu_\\theta)^2}{2\\sigma^2}}\n\\end{align}$$ 其中μθ是正态分布的均值，σθ是标准差（这里假设为一个不依赖于θ的超参），实践中均值和方差（一般生成的是对数方差）均是由神经网络生成，具体论述参见VAE相关内容。对应的策略梯度为：\n$$\\begin{align}\n\\nabla_\\theta \\ln\\pi_{\\theta}(a|s) =\n\\frac{(a-\\mu_\\theta)\\phi(s)}{\\sigma^2}\n\\end{align}$$\n\nLoss\nfunctions and Algorithmic implementation (REINFORCE)\n在实际的计算中不需要计算梯度，只需要设置损失函数，计算机自动求导就行（r是reward）： $$\\begin{align}\n\\cal L(a,s,r) = -\\ln(\\pi_\\theta(a|s))r\n\\end{align}$$\n\n\nREINFORCE\n\nNatural Gradients\n尽管自然梯度已被TRPO和PPO等算法超越，但掌握它的基本原理对于理解这些当代RL算法至关重要。\nThe problems\nwith first-order policy gradients\n传统策略梯度算法只是提供了参数的更新方向，没有直接说明更新的步长。下面是众所周知的策略梯度更新方程：\n$$\\begin{align}\n\\theta \\leftarrow \\theta + \\alpha \\nabla_{\\theta}J(\\theta)\n\\end{align}$$ 传统方法基于目标函数梯度∇θJ(θ)与步长因子α。会导致以下两个常见的问题：\n\nOvershooting:更新直接错过目标。虽然在有监督学习中不成问题，可以通过逐步修改更新率接近目标值。但是在强化学习中，可能会因为新的值导致3梯度消失。\n\nUndershooting:步长因子α过小，无法收敛到目标位置。\n\n但是，并不能简单的限制更新步长||Δθ||（Euclidian\ndistance），例如： $$\\begin{align}\n\\Delta \\theta^* = \\arg\\max_{||\\Delta\\theta||&lt;\\epsilon}J(\\theta+\\Delta\n\\theta)\n\\end{align}$$ 因为在不同的参数中，θ对于步长的敏感性不同。\n\n\nfig2\n\nCapping the difference\nbetween policies\n因为参数对于步长的敏感性不同，因此采用KL散度衡量参数变化前后对分布的影响，将参数θ的变化限制在一定的范围内。 $$\\begin{align}\nD_{KL}(\\pi_\\theta||\\pi_{\\theta+\\Delta \\theta}) = \\sum_{x\\in \\mathcal\nx}\\pi_\\theta(x)\\ln\n\\left(\\frac{\\pi_\\theta(x)}{\\pi_{\\theta+\\Delta\\theta}(x)}\\right)\n\\end{align}$$\n调整后的更新策略限制为： $$\\begin{align}\n\\Delta \\theta^* = \\arg\\max_{D_{KL}(\\pi_\\theta||\\pi_{\\theta+\\Delta\n\\theta})&lt;\\epsilon}J(\\theta+\\Delta \\theta)\n\\end{align}$$\n这样处理之后，在参数空间进行更新，同时也能保证策略本身变化不会十分剧烈。但是遇到一个问题，在计算KL散度的时候需要对所有动作空间进行运算，这会对计算带来问题，下面是简化方法。\n使用Lagrangian方法，将约束项变成惩罚项： $$\\begin{align}\n\\Delta \\theta^* = \\arg\\max_{\\Delta\\theta}J(\\theta+\\Delta\n\\theta)-\\lambda(D_{KL}(\\pi_\\theta||\\pi_{\\theta+\\Delta \\theta})-\\epsilon)\n\\end{align}$$\n进行Taylor展开，为了记号统一，以下将θ = θold + Δθ：\n$$\\begin{align}\n\\Delta \\theta^* &amp;\\approx \\arg\\max_{\\Delta\\theta}\\left[\nJ(\\theta_{old})+ \\nabla_\\theta J(\\theta)|_{\\theta=\\theta_{old}}\\cdot\n\\Delta\\theta-\\frac{1}{2}\\lambda(\\Delta\\theta^T \\nabla_{\\theta}^2\nD_{KL}(\\pi_{\\theta_{old}}||\\pi_{\\theta}|_{\\theta=\\theta_{old}\n})\\Delta\\theta+\\lambda \\epsilon\\right]\\\\\n\\end{align}$$\n这里只计算DKL的二阶项，因为其零阶与一阶项均为零，证明如下：\n$$\\begin{align}\nD_{KL}(p_{\\theta_{old}}||p_{\\theta}）&amp;\\approx\nD_{KL}(p_{\\theta_{old}}||p_{\\theta_{old}})+\\Delta\\theta^T\\nabla_{\\theta}D_{KL}(p_{\\theta_{old}}|p_{\\theta})+\\frac{1}{2}\\Delta\\theta^T\n\\nabla_{\\theta}^2\nD_{KL}(\\pi_{\\theta_{old}}||\\pi_{\\theta}|_{\\theta=\\theta_{old}\n})\\Delta\\theta \\\\\n\\nabla_{\\theta}D_{KL}(p_{\\theta_{old}}|p_{\\theta})|_{\\theta=\\theta_{old}}\n&amp; = -\\nabla_{\\theta}\\mathbb{E}_{x\\sim p_{\\theta_{old}}}\\ln\np_{\\theta}(x)|_{\\theta=\\theta_{old}}+\\nabla_{\\theta}\\mathbb{E}_{x\\sim\np_{\\theta_{old}}}\\ln p_{\\theta_{old}}(x)|_{\\theta=\\theta_{old}} \\\\\n&amp;= -\\mathbb{E}_{x\\sim p_{\\theta_{old}}}\\nabla_{\\theta}\\ln\np_{\\theta}(x)|_{\\theta=\\theta_{old}} \\\\\n&amp;= -\\mathbb{E}_{x\\sim\np_{\\theta_{old}}}\\frac{1}{p_{\\theta_{old}}}\\nabla_{\\theta}\np_{\\theta}(x)|_{\\theta=\\theta_{old}} \\\\\n&amp;= -\\int_x p_{\\theta_{old}}\\frac{1}{p_{\\theta_{old}}}\\nabla_{\\theta}\np_{\\theta}(x)|_{\\theta=\\theta_{old}} \\\\\n&amp;= -\\int_x \\nabla_{\\theta} p_{\\theta}(x)|_{\\theta=\\theta_{old}} \\\\\n&amp;= -\\nabla_{\\theta} \\int_x p_{\\theta}(x)|_{\\theta=\\theta_{old}} \\\\\n&amp;= 0 \\\\\n\\nabla_{\\theta}^2\nD_{KL}(\\pi_{\\theta_{old}}||\\pi_{\\theta}|_{\\theta=\\theta_{old}\n})|_{\\theta=\\theta_{old}} &amp;= -\\mathbb{E}_{x\\sim\np_{\\theta_{old}}}\\nabla_{\\theta}^2\\ln\np_{\\theta}(x)|_{\\theta=\\theta_{old}}  \\\\\n&amp;= -\\mathbb{E}_{x\\sim\np_{\\theta_{old}}}\\nabla_{\\theta}\\left(\\frac{\\nabla_{\\theta}\np_{\\theta}(x)}{p_{\\theta}(x)}\\right)|_{\\theta=\\theta_{old}}  \\\\\n&amp;= -\\mathbb{E}_{x\\sim p_{\\theta_{old}}}\\nabla_{\\theta}\\ln\np_{\\theta}\\nabla_{\\theta}\\ln p_{\\theta}^T|_{\\theta=\\theta_{old}}  \\\\\n\\end{align}$$\n二阶导数可以表述为Hessian matrix，等价于Fisher\ninformation matrix（这两个矩阵有什么样的含义？）。\n$$\\begin{align}\nF(\\theta) &amp;= \\mathbb{E}_{\\theta}\\nabla_{\\theta}\\ln\np_{\\theta}\\nabla_{\\theta}\\ln p_{\\theta}^T\\\\\nF(\\theta_{old}) &amp;=\\nabla^2_\\theta\nD_{KL}(p_{\\theta_{old}}||p_{\\theta})|_{\\theta=\\theta_{old}} \\\\\nD_{KL}(p_{\\theta_{old}}||p_{\\theta}）&amp;\\approx\n\\frac{1}{2}\\Delta\\theta^T F(\\theta_{old})\\Delta\\theta \\\\\n&amp;= \\frac{1}{2}(\\theta-\\theta_{old})^T\nF(\\theta_{old})(\\theta-\\theta_{old}) \\\\\n\\end{align}$$\n根据以上证明可知： $$\\begin{align}\n\\Delta \\theta^* &amp;\\approx \\arg\\max_{\\Delta\\theta}\\left[\nJ(\\theta_{old})+ \\nabla_\\theta J(\\theta)|_{\\theta=\\theta_{old}}\\cdot\n\\Delta\\theta-\\frac{1}{2}\\lambda(\\Delta\\theta^T \\nabla_{\\theta}^2\nD_{KL}(\\pi_{\\theta_{old}}||\\pi_{\\theta}|_{\\theta=\\theta_{old}\n})\\Delta\\theta+\\lambda \\epsilon \\right ]\\\\\n&amp;= \\arg\\max_{\\Delta\\theta} \\left[ \\nabla_\\theta\nJ(\\theta)|_{\\theta=\\theta_{old}}\\cdot\n\\Delta\\theta-\\frac{1}{2}\\lambda\\Delta\\theta^T\nF(\\theta_{old})\\Delta\\theta\\right]\\\\\n\\end{align}$$\n计算梯度为零的点： $$\\begin{align}\n0 &amp;= \\frac{\\partial}{\\partial \\Delta \\theta} \\left[ \\nabla_\\theta\nJ(\\theta)|_{\\theta=\\theta_{old}}\\cdot\n\\Delta\\theta-\\frac{1}{2}\\lambda\\Delta\\theta^T\nF(\\theta_{old})\\Delta\\theta\\right] \\\\\n&amp;= \\nabla_\\theta J(\\theta)|_{\\theta=\\theta_{old}}-\\frac{1}{2}\\lambda\nF(\\theta_{old})\\Delta\\theta \\\\\n\\Delta\\theta &amp;= \\frac{2}{\\lambda}F^{-1}(\\theta_{old})\\nabla_\\theta\nJ(\\theta)|_{\\theta=\\theta_{old}}\n\\end{align}$$\n其中$\\frac{1}{\\lambda}$是一个常数，可以收缩进学习率α。并且根据对更新步长的限制关系，可以得到学习率表达式：\n$$\\begin{align}\nD_{KL}(p_{\\theta_{old}}||p_{\\theta}）&amp;\\approx\n\\frac{1}{2}(\\Delta\\theta)^T F(\\theta_{old})(\\Delta \\theta) \\\\\n&amp;= \\frac{1}{2}(\\alpha g_N)^T F(\\theta_{old})(\\alpha g_N)\n&lt;\\epsilon \\\\\n\\alpha &amp;=\\sqrt{\\frac{2\\epsilon}{(g_N^TFg_N)}} \\\\\n\\end{align}$$ 其中gN = F−1(θ)∇θJ(θ)。自然梯度与更新权重可写为：\n$$\\begin{align}\n\\tilde\\nabla J(\\theta) &amp;= F^{-1}(\\theta)\\nabla_\\theta J(\\theta) \\\\\n\\Delta \\theta &amp;= \\alpha \\tilde\\nabla J(\\theta) \\\\\n\\theta &amp;= \\theta_{old}+\\alpha \\tilde\\nabla J(\\theta)\n\\end{align}$$\n该方案的核心思想在于通过引入KL散度，对不同参数的步长进行限制，缓解了Overshoot与Undershoot问题。\nAlgorithm\n\n\nAlgorithm\n\n自然梯度方法在两个方面不同于传统的策略梯度算法： *\n考虑到策略对局部变化的敏感性，策略梯度由逆Fisher矩阵校正，而传统的梯度方法假定更新为欧几里得距离。\n* 更新步长 α\n具有适应梯度和局部敏感性的动态表达式，确保无论参数化如何，策略变化幅度为\nϵ。在传统方法中，通常设置为一些标准值，如0.1或0.01。\n但是这个算法也存在缺陷： *\nTaylor提供了一个局域二阶近似，这会导致Hessian可能非正定（为什么？）。\n* Fisher information matrix\n计算量过大，尤其是神经网络这种大量参数的情况。\nTrust Region Policy\nOptimization\nTrust Region Policy\nOptimization（TRPO）算法保证了策略梯度算法每次更新始终会提升策略。\n定义η为期望折扣奖励（此处符号发生改变）：\n$$\\begin{align}\n\\eta(\\pi)=\\mathbb{E}_{s_0, a_0, \\ldots}\\left[\\sum_{t=0}^{\\infty}\n\\gamma^t r\\left(s_t\\right)\\right]\n\\end{align}$$\n定义状态-动作价值函数Qπ(st, at)和价值函数Vπ，以及优势函数Aπ:\n$$\\begin{align}\nQ_\\pi\\left(s_t, a_t\\right)&amp;=\\mathbb{E}_{s_{t+1}, a_{t+1},\n\\ldots}\\left[\\sum_{l=0}^{\\infty} \\gamma^l r\\left(s_{t+l}\\right)\\right]\n\\\\ V_\\pi\\left(s_t\\right)&amp;=\\mathbb{E}_{a_t, s_{t+1},\n\\ldots}\\left[\\sum_{l=0}^{\\infty} \\gamma^l r\\left(s_{t+l}\\right)\\right]\n\\\\\nA_\\pi(s, a)&amp;=Q_\\pi(s, a)-V_\\pi(s) \\\\\n\\quad a_t \\sim \\pi\\left(a_t \\mid s_t\\right), &amp;s_{t+1} \\sim\nP\\left(s_{t+1} \\mid s_t, a_t\\right) \\text { for } t \\geq 0\n\\end{align}$$\n其中优势函数，是在给定的策略和状态下，计算特定动作a的期望累积奖励与总体期望值（该状态的期望奖励）的差值。\n下面的式子表达了策略π与优势策略π̃之间的差异（详细证明参见原始论文附录A）：\n$$\\begin{equation}\n\\eta(\\tilde{\\pi})=\\eta(\\pi)+\\mathbb{E}_{s_0, a_0, \\cdots \\sim\n\\tilde{\\pi}}\\left[\\sum_{t=0}^{\\infty} \\gamma^t A_\\pi\\left(s_t,\na_t\\right)\\right]\n\\end{equation}$$ 其中at的采样概率为π̃(⋅|st)，st的采样概率依赖于ρπ这里本质上是重要性采样:\nρπ(s) = P(s0 = s) + γP(s1 = s) + γ2P(s2 = s) + …\n因此将式改写为： $$\n\\begin{align}\n\\eta(\\tilde{\\pi}) &amp; =\\eta(\\pi)+\\sum_{t=0}^{\\infty} \\sum_s\nP\\left(s_t=s \\mid \\tilde{\\pi}\\right) \\sum_a \\tilde{\\pi}(a \\mid s)\n\\gamma^t A_\\pi(s, a) \\\\\n&amp; =\\eta(\\pi)+\\sum_s \\sum_{t=0}^{\\infty} \\gamma^t P\\left(s_t=s \\mid\n\\tilde{\\pi}\\right) \\sum_a \\tilde{\\pi}(a \\mid s) A_\\pi(s, a) \\\\\n&amp; =\\eta(\\pi)+\\sum_s \\rho_{\\tilde{\\pi}}(s) \\sum_a \\tilde{\\pi}(a \\mid\ns) A_\\pi(s, a) \\\\\n&amp;= \\eta(\\pi)+\\sum_s \\rho_{\\tilde{\\pi}}(s) \\sum_a\n\\pi(a|s)\\frac{\\tilde{\\pi}(a \\mid s)}{\\pi(a|s)} A_\\pi(s, a) \\\\\n&amp;=\n\\eta(\\pi)+\\mathbb{E}_{s\\sim\\rho_{\\theta_{old}},a\\sim\\pi_{\\theta_{old}}}\\left[\\frac{\\tilde{\\pi}(a\n\\mid s)}{\\pi(a|s)} A_\\pi(s, a)\\right]\n\\end{align}\n$$ 如果能够保证∑aπ̃(a ∣ s)Aπ(s, a) ≥ 0，策略将会始终得以提升或者等价，然而并不能保证为非负，因为一些动作可能导致A为负。而且由于ρπ̃的存在，使得很难直接去优化，因此采用近似，用ρπ替换ρπ̃： $$\\begin{align}\nL_\\pi(\\tilde{\\pi})=\\eta(\\pi)+\\sum \\rho_\\pi(s) \\sum \\tilde{\\pi}(a \\mid s)\nA_\\pi(s, a)\n\\end{align}$$\n可以证明该近似在一阶导数下是精确的，存在以下的关系proof\nit： $$\n\\begin{align}\nL_{\\pi_{\\theta_0}}\\left(\\pi_{\\theta_0}\\right) &amp;\n=\\eta\\left(\\pi_{\\theta_0}\\right) \\\\\n\\left.\\nabla_\\theta\nL_{\\pi_{\\theta_0}}\\left(\\pi_\\theta\\right)\\right|_{\\theta=\\theta_0} &amp;\n=\\left.\\nabla_\\theta\n\\eta\\left(\\pi_\\theta\\right)\\right|_{\\theta=\\theta_0}\n\\end{align}\n$$\n从实际含义上可以理解，如果策略不变，那么前后策略应当是相同的。第二部分保证，只要能提升Lπθ0，也会提升η。\n文献Approximately\nOptimal Approximate Reinforcement\nLearning有时间看看，给出了一种混合更新策略，并且证明了更新后的策略的下界。\n$$\n\\begin{aligned}\n\\pi_{\\text {new }}(a \\mid s)&amp;=(1-\\alpha) \\pi_{\\text {old }}(a \\mid\ns)+\\alpha \\pi^{\\prime}(a \\mid s) \\\\\n\\eta\\left(\\pi_{\\text {new }}\\right) &amp; \\geq L_{\\pi_{\\text {old\n}}}\\left(\\pi_{\\text {new }}\\right)-\\frac{2 \\epsilon\n\\gamma}{(1-\\gamma)^2} \\alpha^2 \\\\\n\\epsilon&amp;=\\max _s\\left|\\mathbb{E}_{a \\sim \\pi^{\\prime}(a \\mid\ns)}\\left[A_\\pi(s, a)\\right]\\right|\n\\end{aligned}\n$$\nMonotonic\nImprovement Guarantee for General Stochastic Policies\n文章 Approximately Optimal Approximate Reinforcement Learning\n提出的混合策略过强不够普适用，同时不便于实践，不具备一般性。TRPO算法在此基础上进行弱化，但是同时要保证下界不变。\n引入总变差（Total Variation Distance）：$D_{T V}(p \\| q)=\\frac{1}{2}\n\\sum_i\\left|p_i-q_i\\right|$，将α定义如下：\n$$ $$\n上面计算下界的证明参见原文附录。根据TV与KL散度的关系证明它：\n$$\\begin{align}\nD_{T V}(p \\| q)^2 \\leq D_{\\mathrm{KL}}(p \\| q)\n\\end{align}$$ 令DTVmax(π, π̃)2 = maxsDKL(π(⋅|s)∥π̃(⋅|s))，可以得到如下的下界：\n$$\n\\begin{align}\n\\eta(\\tilde{\\pi}) &amp;\\geq L_\\pi(\\tilde{\\pi})-C D_{\\mathrm{KL}}^{\\max\n}(\\pi, \\tilde{\\pi}) \\\\\nC&amp;=\\frac{4 \\epsilon \\gamma}{(1-\\gamma)^2}\n\\end{align}\n$$\n令Mi(π) = Lπi(π) − CDKLmax(πi, π)，利用这个下界证明单调性。\n首先: η(πi + 1) ≥ Mi(πi + 1)\n并且: η(πi) = Mi(πi)\n则： η(πi + 1) − η(πi) ≥ Mi(πi + 1) − M(πi)\n如果新策略πi + 1能使得Mi最大，就有Mi(πi + 1) − M(πi) ≥ 0，从而就保证了策略必然稳步提升。\n这样通过优化下界便可以使得策略得到稳定的提升。\n算法流程如下： \nOptimization of\nParameterized Policies\n下面将要基于以上的理论基础，在有限的空间以及任意参数下，给出具体的算法。首先更改符号注记，用θ表示重要的参数，而非策略πθ。η(θ) := η(πθ), Lθ(θ̃) := Lπθ(πθ̃), DKL(θ∥θ̃) := DKL(πθ∥πθ̃)\n可以将： $$\\begin{equation}\n\\underset{\\theta}{\\operatorname{maximize}}\\left[L_{\\theta_{\\text {old\n}}}(\\theta)-C D_{\\mathrm{KL}}^{\\max }\\left(\\theta_{\\text {old }},\n\\theta\\right)\\right]\n\\end{equation}$$ 改写为： $$\\begin{aligned}\n&amp; \\underset{\\theta}{\\operatorname{maximize}} L_{\\theta_{\\text {old\n}}}(\\theta) \\\\\n&amp; \\text { subject to } D_{\\mathrm{KL}}^{\\max }\\left(\\theta_{\\text\n{old }}, \\theta\\right) \\leq \\delta\n\\end{aligned}$$ 由于DKLmax的计算过于麻烦，采用带权重的近似替代：\nD̄KLρ(θ1, θ2) := 𝔼s ∼ ρ[DKL(πθ1(⋅ ∣ s)∥πθ2(⋅ ∣ s))]\n基于此最终解决的优化问题形式是： $$\\begin{equation}\n\\begin{aligned}\n&amp; \\underset{\\theta}{\\operatorname{maximize}} L_{\\theta_{\\text {old\n}}}(\\theta) \\\\\n&amp; \\text { subject to } \\bar{D}_{\\mathrm{KL}}^{\\rho_{\\theta_{\\text\n{old }}}}\\left(\\theta_{\\text {old }}, \\theta\\right) \\leq \\delta .\n\\end{aligned}\n\\end{equation}$$\nConnections with Natural\nGradients\n从TRPO算法最终解决问题的形式可以看出，这是一种针对特定形式优化问题的解决方案。通过计算惩罚因子，从而保证在每一次更新迭代之后就能保证策略得到稳定的提升。为了实现这个目标，引入了两个重要的机制：\n* Advantage Estimates *\n检查机制：随机采样并不能确定结果是否得到提升，但是可以检查采样结果，选取确实提升效果的样本，对于其他样本则直接放弃。\n对于自然梯度算法，也是其一个特例。 $$\\begin{equation}\n\\begin{aligned}\n&amp;\n\\underset{\\theta}{\\operatorname{maximize}}\\left[\\left.\\nabla_\\theta\nL_{\\theta_{\\text {old }}}(\\theta)\\right|_{\\theta=\\theta_{\\text {old }}}\n\\cdot\\left(\\theta-\\theta_{\\text {old }}\\right)\\right] \\\\\n&amp; \\text { subject to } \\frac{1}{2}\\left(\\theta_{\\text {old\n}}-\\theta\\right)^T A\\left(\\theta_{\\text {old\n}}\\right)\\left(\\theta_{\\text {old }}-\\theta\\right) \\leq \\delta \\\\\n&amp; \\text { where } A\\left(\\theta_{\\text {old }}\\right)_{i j}= \\left.\n\\frac{\\partial}{\\partial \\theta_i} \\frac{\\partial}{\\partial \\theta_j}\n\\mathbb{E}_{s \\sim \\rho_\\pi}\\left[D_{\\mathrm{KL}}\\left(\\pi\\left(\\cdot\n\\mid s, \\theta_{\\text {old }}\\right) \\| \\pi(\\cdot \\mid s,\n\\theta)\\right)\\right]\\right|_{\\theta=\\theta_{\\text {old }}}\n\\end{aligned}\n\\end{equation}$$ 其中参数更新为$\\theta_{\\text {new }}=\\theta_{\\text {old\n}}+\\left.\\frac{1}{\\lambda} A\\left(\\theta_{\\text {old }}\\right)^{-1}\n\\nabla_\\theta L(\\theta)\\right|_{\\theta=\\theta_{\\text {old\n}}}$，利用TRPO算法，可以限制惩罚项$\\frac{1}{\\lambda}$，虽然这只是一个很小的算法参数，但是在大问题上显著提升了算法表现能力。\n缺失共轭梯度法，与算法简化的实现\n\n\nTRPO structure\n\nProximal Policy\nOptimization Algorithms\nTRPO算法保证了稳定提升，但是由于计算二阶梯度，运算量十分巨大。为了解决运算量大的问题，提出了一种近似方法，通过对惩罚因子进行限制，大幅减少运算量。\nClipped Surrogate Objective\n在TRPO中优化的目标为： $$\\begin{equation}\nL^{C P I}(\\theta)=\\hat{\\mathbb{E}}_t\\left[\\frac{\\pi_\\theta\\left(a_t \\mid\ns_t\\right)}{\\pi_{\\theta_{\\text {old }}}\\left(a_t \\mid s_t\\right)}\n\\hat{A}_t\\right]=\\hat{\\mathbb{E}}_t\\left[r_t(\\theta) \\hat{A}_t\\right]\n\\end{equation}$$ 其中$r_t(\\theta)=\\frac{\\pi_\\theta\\left(a_t \\mid\ns_t\\right)}{\\pi_{\\theta_{\\text {old }}}}$，CPI指的是conservative\npolicy iteration。\n调整TRPO的优化目标为： $$\\begin{equation}\nL^{C L I P}(\\theta)=\\hat{\\mathbb{E}}_t\\left[\\min \\left(r_t(\\theta)\n\\hat{A}_t, \\operatorname{clip}\\left(r_t(\\theta), 1-\\epsilon,\n1+\\epsilon\\right) \\hat{A}_t\\right)\\right]\n\\end{equation}$$ 其中ϵ为超参。该式的第一项表示LCPI，第二项利用剪切权重调整了优势函数，将rt限制在一个范围内。最后返回剪切与非剪切之后的较小值，这样将会返回一个下界。\n\n\nclip\n\n算法框架如下：\n\n\nPPO Clip\n\nAdaptive KL Penalty\nCoefficient\n另一种优化方案是针对惩罚项： $$\\begin{equation}\nL^{K L P E N}(\\theta)=\\hat{\\mathbb{E}}_t\\left[\\frac{\\pi_\\theta\\left(a_t\n\\mid s_t\\right)}{\\pi_{\\theta_{\\text {old }}}\\left(a_t \\mid s_t\\right)}\n\\hat{A}_t-\\beta \\operatorname{KL}\\left[\\pi_{\\theta_{\\text {old\n}}}\\left(\\cdot \\mid s_t\\right), \\pi_\\theta\\left(\\cdot \\mid\ns_t\\right)\\right]\\right]\n\\end{equation}$$ 然后计算KL散度，从而确定惩罚因子的大小。 $$\n\\begin{aligned}\n&amp;d=\\hat{\\mathbb{E}}_t\\left[\\operatorname{KL}\\left[\\pi_{\\theta_{\\text\n{old }}}\\left(\\cdot \\mid s_t\\right), \\pi_\\theta\\left(\\cdot \\mid\ns_t\\right)\\right]\\right] \\\\\n&amp; \\quad-\\text { If } d&lt;d_{\\text {targ }} / 1.5, \\beta \\leftarrow\n\\beta / 2 \\\\\n&amp; \\quad-\\text { If } d&gt;d_{\\text {targ }} \\times 1.5, \\beta\n\\leftarrow \\beta \\times 2\n\\end{aligned}\n$$ 其中1.5, 2是启发式得到，初始值β也是一个超参，但是对结果影响不大。\n","categories":["Machine Learning"],"tags":["Reinforcement Learning","Natural Gradients","PPO","TRPO","Policy Gradients"]},{"title":"Student of Games:Aunified learning algorithm forboth perfect andimperfect information games","url":"/2024/08/24/RL/SoG/SoG/","content":"在之前的游戏引擎中存在仅适用于单一游戏的问题，虽然AlphaZero解决对于完全完美信息的通用性，但是对于扑克等依旧不存在通用算法。这篇文章提出一种新的通用算法Student\nof\nGames（SoG），该算法类似于AlphaZero通过自博弈的方式完成训练，同时拓展了适用边界——适用于非完全信息博弈，例如扑克。\n这个算法结合了很多内容，并没有读懂\nLink: * Student\nof Games:Aunified learning algorithm forboth perfect andimperfect\ninformation games\n\nIntroduction\n对于完全完美信息博弈，在理论上存在最优策略，难点在于如何找到该策略。对于不完全信息博弈，是否存在最优策略呢？因为不知道别人的信息，自己作出的选择可能因为对方的信息得到截然不同的结果，因此在这种情况下如何判断不同策略之间哪一个是最优策略？解答这个问题，需要换一个角度从纳什均衡出发，如果存在一种策略使得处于纳什均衡，一旦脱离该策略，那么必然会使得其处于更糟糕的点，那么这个策略就是最优策略。但是可能存在多个均衡策略，哪一个策略是最优的呢？\n对于不完全信息博弈，已有的算法是counterfactual\nregretminimiza tion (CFR)，以及后续衍生的DeepStack算法。\n这篇文章结合了AlphaZero与DeepStack算法，与AlphaZero的区别在于自博弈的记录可以用于训练非完全信息博弈；与DeepStack的区别在于使用更少的domain\nknowledge，单个网络对于所有策略。与该算法接近的算法是Recurr entBelief-based Learning\n(ReBeL)\nSoG algorithm\n\n\nCVPN\n\n将参数给入网络得到私有策略。\n\n\nGT-CFR\n\n包含后悔值的搜索树。\n\n\nTrain\n\n","categories":["Machine Learning"],"tags":["Reinforcement Learning","Student of Games"]},{"title":"统计物理读书笔记","url":"/2024/01/28/book/statistical_physics_CMB/statistical_physics_CMB/","content":"本笔记为阅读陈敏伯《统计物理》的读书笔记，包含大量基本概念与公式推导。按照本书前言所著，这本书大量使用变分原理进行推理基本公式。\n\n\n\n脉络体系\n\n第一章：引言\n量子力学用以构建原子分子的微观性质，统计力学根据此微观性质进行解释从而得到理解体系的宏观性质，这就是统计力学的任务所在。\n宏观量的统计性质\n体系的宏观量（可直接或者间接观测的物理量）：\n\n热力学变量（温度、密度、压强等）\n热力学函数（内能、熵等）\n体系的电磁性质\n输运性质（扩散、粘度、热传导等）\n速度分布和流体密度相关函数\n\n宏观量应该是相应微观量的统计平均值。宏观量应该具备两个特征：\n\n在空间尺度上，宏观量在宏观上足够小从而可以看出在宏观体系上的不均匀性质；但同时在微观上应该足够大，包含足够多的粒子，从而统计平均富有意义。\n在时间尺度上，宏观量在宏观尺度上应该足够小，可以反应出在宏观尺度上随时间变化的情况；另一方在微观上应该是足够长的，包含了足够多次的微观变化。\n\n基本概念\n体系：物质世界中普遍存在着相互作用，从相互作用的众多物体中划分出来进行研究的那一部分称为体系。\n环境：所有与上述体系存在相互作用而又不属于该体系的物体，统称为环境。体系与环境的划分由如何解决问题的方便决定。\n体系分类： *\n孤立体系：体系与环境无物质与能量的交换。 *\n封闭体系：体系与环境仅有能量的交换，无物质交换。 *\n开放体系：体系与环境存在物质与能量的交换。\n广义坐标：描述问题的最小变量。即确定体系的独立变量，称为广义坐标（广义位置、lagrange位形）。记为：\nq(t) = (q1(t), q2(t)⋯qs(t))\n广义动量：为确定整个体系在t时刻的力学状态，除了知道广义动量坐标以外还需要知道其下一时刻的运动方向，称为广义运动向量,记作q̇(t) = (q̇1(t), q̇2(t)⋯q̇s(t))。Hamilton更深刻的反应力学本质，除广义位移以外引入广义动量，定义为：\n$$\\begin{equation}p(t)=\\frac{\\partial\nL}{\\partial \\dot{q}(t)}\\end{equation}$$\n相空间：由x = (q, q̇)构成的空间称为相空间，记为Γ。描述一个粒子的相空间称为μ空间。\n力学量：体系中任意可观测量（记为B）在体系的每个微观状态下都有确定的数值。\n体系的宏观量：描述体系的平衡态实际上只要用少数宏观量即可。体积、压强、温度、能量、外磁场、外电场、电极化强度、磁极化强度等。\n涨落：由于微观状态在剧烈变化，宏观会在平均值附近随机变动，这种变动称为涨落。\n非平衡定态：经验表明，体系处于环境不变的情况下，经过一段时间后，体系必将达到一个宏观上不随时间变化的状态，尽管不一定是平衡态，但体系将长久的保持这种状态，这种状态称为非平衡定态（定态、稳态、定常态stationary\nstate），描述为：$\\frac{\\partial \\langle\nB\\rangle}{\\partial t}=\n0$（注意，只是时间的偏导，而不是全导），例如：在两个具有稳定温差中形成的热流，是定态。\n平衡态：处于定态体系，并且其环境的宏观状态宏观状态也不变，则这个体系称为处于平衡态。体系的所有宏观性质随时间不变化：$\\frac{\\partial \\langle B\\rangle}{\\partial\nt}=0$。处于平衡态的体系，内部允许出现某种微观不均匀，但是不允许出现流（热流、粒子流等）。\n非平衡态：体系所处的宏观状态，非上述的平衡态，均处于非平衡态。\n弛豫过程：处于非平衡态的体系有自发趋向平衡态的趋势，这种从非平衡态到平衡态的过程称为弛豫过程。\n广延量与强度量：描述体系所需的所有宏观参量。与体系质量有关的称为广延量，与体系质量无关的称为强度量。\n外参量与内参量：宏观参量的另一种分类方法，只取决于环境而与体系无关的宏观量称为外参量，例如：体系体积、体系外形、外电场、外磁场；取决于体系内部粒子的特性以及运动状态的宏观参量，例如：体系的压力。\n物态方程：系统处于平衡态时，内参量依赖于外参量。例如气体存在的关系：f(p, V, T) = 0。物质在其他形态下的物态方程，在工程界有时候也称为本构方程。\n统计力学中体系力学描述的三种不同层次\nBogoliubov提出关于空间、时间上大致有三种不同尺度的描述方法，又称为三种标度。粒子间的相互作用力程Lint，粒子平均自由程Lτ和体系温度、密度等非均匀的量程Lh。\n\n\n\n\n\n\n\n\n\n描述层次\n特征长度\n特征时间\n以常温、常压氢气为例\n\n\n\n\n微观层次\n粒子间作用力程Lint\n相互作用持续时间τint\nLint = 10−8cm, τ = 5 × 10−14s\n\n\n动理学层次\n粒子平均自由程Lτ\n弛豫时间τ\nLτ = 10−5cm, τ = 5 × 10−11s\n\n\n流体力学层次\n非均匀性量程Lh\n非均匀性特征时间τh\nLh = 1cm, τh = 5 × 10−6s\n\n\n\n第二章：经典动力学\nLagrange函数\nL(q, q̇, t) = T − U\n以下讨论保守力体系，即F = −∇U，Lagrange函数可以写为：\n$$\\begin{align}\nL(q,\\dot q)&amp;=T(\\dot q)-U(q)=\\frac{1}{2}\\sum_{i=1}^{3N} m_i\n\\dot{x_i}^2-U \\\\\n&amp;= \\frac{1}{2}\\sum_{i=1}^{3N}\\sum_{k,l=1}^{s^2} m_i \\frac{\\partial\nx_i}{\\partial q_k}\\frac{\\partial x_i}{\\partial\nq_l}\\dot{q}_k\\dot{q}_l-U(q) \\\\\n&amp;= \\frac{1}{2}\\sum_{k,l=1}^{s^2} M_{kl} \\dot{q}_k\\dot{q}_l-U(q) \\\\\n\\end{align}$$\n其中{x}称为d’Alembert位形，广义质量Nkl定义为：\n$$M_{kl}= \\sum_{i=1}^{3N}m_i\\frac{\\partial\nx_i}{\\partial q_k}\\frac{\\partial x_i}{\\partial q_l}$$\n最小作用量原理和lagrange方程\n从最小作用量原理（Hamilton）导出Lagrange形式的经典力学。在相空间中，设体系在t1时刻从A点出发，经过某路径q(t)在t2时刻到达点B。对于每条可能的路径q(t)，可以定义作用量（action）为：\nS[q(t)] = ∫t1t2L(q̇, q)𝕕t\n可以看出作用量是一个标量，为路径的泛函。\n最小作用量原理在理论上有很多条路径可以实现从A点到B点的目的，但是实际上只存在一条真是的路径，这条路径应当满足如下要求：\nqtrue = argminq{S[q(t)]}\n从物理上理解，因为从A到B需要在相空间上需要满足能量最低原理。因此最小作用量原理本质上就是满足前者要求。\n故而此问题成为一个有约束的变分问题。考虑路径上可能存在一个虚位移q(t) → q(t) + δq(t)，在A、B两点由于固定的原因，不存在虚位移δq(tA) = δq(tB) = 0。对作用量公式进行变分：\n$$\\begin{align}\n\\delta S &amp;=\\int_{t_1}^{t_2}\\mathbb{d}t\\sum_{i=1}^{s}\\{\n\\frac{\\partial L}{\\partial q_i}\\delta q_i+\\frac{\\partial L}{\\partial\n\\dot{q}_i}\\delta \\dot{q}_i\\} \\\\\n&amp;= \\int_{t_1}^{t_2}\\mathbb{d}t\\sum_{i=1}^{s}\\{ \\frac{\\partial\nL}{\\partial q_i}\\delta q_i+\\frac{\\partial L}{\\partial \\dot{q}_i}\\delta\n\\frac{d q_i}{dt}\\} \\\\\n&amp;= \\delta\\frac{\\partial L}{\\partial \\dot{q}_i} \\frac{d\nq_i}{dt}|_{t_1}^{t_2} + \\int_{t_1}^{t_2}\\mathbb{d}t\\sum_{i=1}^{s}\\{\n\\frac{\\partial L}{\\partial q_i}\\delta q_i-\\frac{d}{dt}\\frac{\\partial\nL}{\\partial \\dot{q}_i}\\delta q_i \\} \\\\\n&amp;= \\int_{t_1}^{t_2}\\mathbb{d}t\\sum_{i=1}^{s}\\{ \\frac{\\partial\nL}{\\partial q_i}-\\frac{d}{dt}\\frac{\\partial L}{\\partial \\dot{q}_i} \\}\n\\delta q_i\\\\\n\\end{align}$$\n得到最终的Lagrange方程： $$\\frac{\\partial\nL}{\\partial q_i}-\\frac{d}{dt}\\frac{\\partial L}{\\partial \\dot{q}_i}=0,\n\\forall i=1,2,\\cdots s$$\n如果受到外力fiext，只需要在右边加上外力项：\n$$\\frac{\\partial L}{\\partial\nq_i}-\\frac{d}{dt}\\frac{\\partial L}{\\partial \\dot{q}_i}=f^{ext}_i,\n\\forall i=1,2,\\cdots s$$\nHamilton正则方程\n利用勒让德变换（Legendre），将一组变量转化为另一组变量。将L(q̇, q, t)中的变量q̇变为$p_i\n= \\frac{\\partial L}{\\partial \\dot q_i}$，记p = {pi}，定义哈密顿量（Hamiltonian）：\n$$\\begin{equation}H(q,p,t)=\\sum_{t=1}^{s}\\dot\nq_ip_i - L(\\dot q, q, t) \\end{equation}$$\n存在以下关系： $$\\begin{align}\n\\frac{\\partial H}{\\partial t}&amp;=\\frac{\\partial (\\dot\nq_ip_i)}{\\partial t} -\\frac{\\partial L}{\\partial t} \\\\\n&amp;= -\\frac{\\partial L}{\\partial t} \\\\\n\\frac{\\partial H}{\\partial q_i}&amp;=-\\frac{\\partial L}{\\partial q_i} \\\\\n\\frac{\\partial H}{\\partial \\dot q_i}&amp;=0 =  p_i -\\frac{\\partial\nL}{\\partial \\dot q_i} \\\\\n\\frac{\\partial H}{\\partial p_i}&amp;= \\dot q_i\\\\\n\\end{align}$$\n将前两式代入Lagrange方程，可以得到： $$\\begin{align}\n-\\frac{\\partial H}{\\partial q_i}-\\frac{d}{dt}p_i&amp;=0, \\forall\ni=1,2,\\cdots s  \\\\\n\\dot p_i &amp;= -\\frac{\\partial H}{\\partial q_i}\n\\end{align}$$\n得到Hamiltonian正则方程： $$\\begin{align}\n\\dot p_i &amp;= -\\frac{\\partial H}{\\partial q_i} \\\\\n\\dot q_i &amp;= \\frac{\\partial H}{\\partial p_i}\n\\end{align}$$\n最小作用量原理与Hamilton正则方程\nHamilton正则方程的导出，同样可以利用最小作用量原理得到。由式（7）、（8）和（13）可以得到：\n$$\\begin{align}\n\\delta S &amp;= \\delta\\int_{t_1}^{t_2}L\\mathbb{d}t \\\\\n&amp;= \\delta\\int_{t_1}^{t_2}(\\sum_{i=1}^{s}\\dot q_ip_i-H)\\mathbb{d}t \\\\\n&amp;= \\int_{t_1}^{t_2}\\mathbb{d}t\\left( \\sum_{i=1}^{s}\\left(\\delta \\dot\nq_ip_i+\\dot q_i\\delta p_i\\right)-\\delta H\\right) \\\\\n&amp;= \\int_{t_1}^{t_2}\\mathbb{d}t\\left( \\sum_{i=1}^{s}\\left(\\delta \\dot\nq_ip_i+\\dot q_i\\delta p_i\\right)-\\left(\\frac{\\delta H}{\\delta p}\\delta\np+\\frac{\\delta H}{\\delta q}\\delta q\\right)\\right) \\\\\n&amp;= \\int_{t_1}^{t_2}\\mathbb{d}t \\sum_{i=1}^{s}\\left(\\delta \\dot\nq_ip_i+\\dot q_i\\delta p_i-\\frac{\\delta H}{\\delta p_i}\\delta\np_i-\\frac{\\delta H}{\\delta q_i}\\delta q_i\\right)\\\\\n&amp;= \\int_{t_1}^{t_2}\\mathbb{d}t \\sum_{i=1}^{s}\\left(\\delta \\dot\nq_ip_i+\\dot q_i\\delta p_i-\\dot q_i\\delta p_i-\\frac{\\delta H}{\\delta\nq_i}\\delta q_i\\right)\\\\\n&amp;= \\int_{t_1}^{t_2}\\mathbb{d}t \\sum_{i=1}^{s}\\left(\\delta \\dot\nq_ip_i-\\frac{\\delta H}{\\delta q_i}\\delta q_i\\right)\\\\\n&amp;= \\int_{t_1}^{t_2}\\mathbb{d}t \\sum_{i=1}^{s}\\left(-\\delta q_i\\dot\np_i-\\frac{\\delta H}{\\delta q_i}\\delta q_i\\right)\\\\\n\\end{align}$$\n根据δS = 0可以得出： $$\\dot p_i=-\\frac{\\delta H}{\\delta\nq_i}$$\n概率分布函数与Liouville方程\n把香农熵（shannon）作为统计力学基础，自然的把纯态和混合态的概念联合在一起。\n经典力学的纯态和混合态\n在经典力学中有两种描述方法：\n\n纯态方法：将微观状态看为是相空间中的的一个相点，体系随时间的演化就是相空间中的一条曲线。这种观点把体系瞬时间所处的微观状态看成是单个纯粹的微观状态。\n混合态方法：引入概率的思想，将体系瞬时间所处的状态，认为是以概率分布在一组微观状态的概率云上，用相空间的概率密度函数f(q(t), p(t), t)来描述。体系随时间的变化，就是这团概率云（概率密度函数）随时间的变化。\n\n混合态描述是纯态描述的推广，纯态描述是混合态描述的特例。\n从混合态的角度分析，概率的分布应该存在不确定度H。如果是纯态，那么必然是确定的Hmin = 0，不存在不确定度；如果是均匀的混合态，那么此时不确定度应改是最大的。因此不确定度应改满足以下的条件：\n\n最小条件。当{pi}中只有一个结果的概率为1，其余均为0时，得到最大的信息量，最小的不确定度Hmin = 0。\n最大值条件。当pi均为常数，信息量必为0，即最大不确定度H = Hmax。\n对称条件。若交换两个结果的次序，不确定度不发生改变： H(⋯pi⋯pj⋯) = H(⋯pj⋯pi⋯)\n加性条件。若将两个独立的随机变量A和B看成是一个联合事件，则联合事件给出的不确定性应当是各随机事件不确定性之和：\nH(A ∪ B) = H(A) + H(B)\n\n针对以上条件shannon证明唯一解是： $$H=-K\\sum_{j=1}^{n}p_j\\ln p_j$$ K为任意常数。\n概率分布函数\n测不准原理表明，粒子微观状态在相空间中一个自由度上是占有一个宽度的△pi △ qi = h。对于自由度为s的粒子，一个粒子在微观状态中占有的体积，即“相胞”体积为$\\prod_{i=1}^{s}\\bigtriangleup p_i\\bigtriangleup\nq_i=h^s$。只要粒子落入这个相胞内，便无法区分。\n对于三维体系中N个粒子的体系，其体系相空间的相胞为h3N，再因为是全同的体系，可以得到一个相体积元代表的微观粒子数：\n$$\\mathbb{d}\\Gamma=\\frac{dpdq}{h^{3N}N!}=\\frac{1}{h^{3N}N!}\\prod_{1}^{N}dp_i\ndq_i$$\n设t时刻体系微观状态在Γ相空间的相体积元dΓ中出现的概率为：\ndw = f(q, p, t)dΓ\n其中f(q, p, t)称为Γ相空间体系状态的概率分布函数，也称为系综分布函数，简称分布函数或者概率密度。\n$$\\begin{align}\n\\int_{\\Gamma}f(p,q,t)d\\Gamma &amp;= 1 \\\\\n&lt;A(t)&gt;&amp;=\\int_{\\Gamma}A(p,q)f(p,q,t)d\\Gamma\n\\end{align}$$\nLiouvile方程\nLiouvile方程：概率密度函数f(p, q, t)随时间的变化规律。\n相点的速度为 $$v=\\sum_{i=1}^{3N}\\dot\nq_i\\hat{q}_i+\\sum_{i=1}^{3N}\\dot p_i\\hat{p}_i$$ 其中q̂, p̂是方向向量。\n固定区域V内的状态点的增速：\n$$\\frac{\\partial}{\\partial t}\\int_V f\nd\\Gamma$$\n从固定区域V中流出的状态点速度： ∮Sds ⋅ vf = ∫VdΓ∇ ⋅ (fv)\n其中ds是表面向量，规定方向为外法向。\n因为Γ空间中不存在生成状态的源，也不存在消灭状态的黑洞。因此在一个区域中，流出的状态与增加的状态应该是一样的。因此存在关系：\n$$0=\\frac{\\partial}{\\partial t}\\int_V f\nd\\Gamma+\\int_V d\\Gamma \\nabla\\cdot(fv)=\\int_V\nd\\Gamma\\left(\\frac{\\partial f}{\\partial\nt}+\\nabla\\cdot(fv)\\right)$$\n对于任意区域均成立，需要满足： $$\\frac{\\partial f}{\\partial\nt}+\\nabla\\cdot(fv)=0$$\n而$\\frac{\\partial f}{\\partial\nt}=-\\nabla\\cdot(fv)=-\\sum_{i=1}^{3N}\\left(\\frac{\\partial (f\\dot\nq_i)}{\\partial q_i}+\\frac{\\partial (f\\dot p_i)}{\\partial\np_i}\\right)=-\\sum_{i=1}^{3N}\\left(\\frac{\\dot q_i\\partial f}{\\partial\nq_i}+\\frac{f\\partial \\dot q_i}{\\partial q_i}+\\frac{\\dot p_i\\partial\nf}{\\partial p_i}+\\frac{f\\partial \\dot p_i}{\\partial\np_i}\\right)=-\\sum_{i=1}^{3N}\\left(\\frac{\\dot q_i\\partial f}{\\partial\nq_i}+\\frac{\\dot p_i\\partial f}{\\partial\np_i}\\right)$再根据Hamilton正则方程可以得到：\n$$\\begin{align}\n\\frac{\\partial f}{\\partial t} &amp;= -\\sum_{i=1}^{3N}\\left(\\frac{\\dot\nq_i\\partial f}{\\partial q_i}+\\frac{\\dot p_i\\partial f}{\\partial\np_i}\\right) \\\\\n&amp;= -\\sum_{i=1}^{3N}\\left(\\frac{ \\partial f}{\\partial\nq_i}\\frac{\\partial H}{\\partial p_i}-\\frac{\\partial f}{\\partial\np_i}\\frac{\\partial H}{\\partial q_i}\\right) \\\\\n&amp;= \\{H,f\\}\n\\end{align}$$\n上述方程称为Liouvile方程。其中Poisson括号定义为$\\{A, B\\}=\\sum_{i=1}^{3N}\\left(\\frac{ \\partial\nA}{\\partial q_i}\\frac{\\partial B}{\\partial p_i}-\\frac{\\partial\nA}{\\partial p_i}\\frac{\\partial B}{\\partial q_i}\\right)$\n经典Liouville算符的形式解\n形式解就是解析解。如果经典Liouville算符L与时间无关，并且f(q, p, t = 0)已知，可以得到$\\frac{\\partial f}{\\partial\nt}|_{t=0}=(-iL)f|_{t=0}$，重复计算∞次得到$\\frac{\\partial^n f}{\\partial t^n}|_{t=0}=(-iL)^n\nf|_{t=0}$，接下来将f(q, p, t)展开：\n$$\\begin{align}\nf(q,p,t)&amp;=\\sum_{n=0}^{\\infty}\\frac{t^n}{n!}(\\frac{\\partial^n\nf}{\\partial t^n})_{t=0} \\\\\n&amp;=\\sum_{n=0}^{\\infty}\\frac{t^n}{n!}(-iL)^nf|_{t=0} \\\\\n&amp;= e^{-iLt}f(q,p,0)\n\\end{align}$$\n因此：\nf(q, p, t) = e−iLtf(q, p, 0)\n力学量的时间演化\n任意力学量A = A(q(t), p(t), t)的时间演化可以写为：\n$$\\begin{align}\n\\frac{d A}{dt}&amp;=\\frac{\\partial A}{\\partial\nt}+\\sum_{i=1}^{3N}(\\frac{\\partial A}{\\partial q_i}\\dot q_i +\n\\frac{\\partial A}{\\partial p_i}\\dot p_i) \\\\\n&amp;= \\frac{\\partial A}{\\partial t}+\\sum_{i=1}^{3N}(\\frac{\\partial\nA}{\\partial q_i}\\frac{\\partial H}{\\partial p_i} + \\frac{\\partial\nA}{\\partial p_i}\\frac{\\partial H}{\\partial q_i}) \\\\\n&amp;= \\frac{\\partial A}{\\partial t}+ \\{A, H\\} \\\\\n&amp;= \\frac{\\partial A}{\\partial t}+ iLA\n\\end{align}$$\n任意力学量的平均值\n$$\\begin{align}\n\\frac{d \\langle A\\rangle}{dt}=\\langle \\frac{dA}{dt} \\rangle\n\\end{align}$$\n不显含时间的物理量\n如果A = A(q(t), p(t))那么：\n$$\\begin{align}\n\\frac{d A}{d t}&amp;=iLA \\\\\nA(q(t), p(t)) &amp;= e^{iLt}A(q(0),p(0))\n\\end{align}$$\n经典演化算符、时间反演对称性\n针对三维N粒子体系，Hamilton写为：\n$$H(p,q)=\\sum_{j=1}^{N}\n\\frac{P_j^2}{2m_j}+U(q)$$\n\nLiouville算符的Hermite性 L† = L\n典微观状态的时间演化。\n\n演化状态的解析解为： x(t) = eiLtx(0)\n其中，将eiLt称为经典传播子（classical\nprograpator），与量子力学中的e−iHt/ℏ相对应。传播子又称为演化算符。\n记演化算符U(t1, t2) = U(t2 − t1) = eiL(t2 − t1)，即：\nU(t) = eiLt\n于是有x(t) = U(t)x(0)\n\n演化算符U(t)为酉算符。 U†(t)U(t) = 1\n时间反演对称性。\n\n时间反演对称：时间从0 → t的演化过程，与时间从t → 0的过程，满足相同的运动方程，称为具有时间反演对称性。\nHamilton方程具有时间反演对称性。传播子与时间反演对称性等价。\n考虑正向过程x(t) = U(t, 0)x(0)，在考虑反向的传播过程：\nx(0) = U(0, t)x(t) = U(−t)U(t)x(0) = U†(t)U(t)x(0) = x(0)\n约化分布函数\n全同粒子体系的力学量的平均值\n⟨B(t)⟩ = ∫B(x1, x2⋯xN)f(x1, x2⋯xN)dx1dx2⋯dxN\n在处理全同体系的时候，任意交换两个粒子的时候，体系不变，具备如下的条件：\nB(x1⋯xi⋯xj⋯xN) = B(x1⋯xj⋯xi⋯xN), ∀i ≠ j\n这种交换对称性可以展开为： $$\\begin{equation}\nB(x_1, x_2 \\cdots x_N) = \\sum_{n=0}^N B_n(x_1,x_2\\cdots x_n)\n\\end{equation}$$\n其中： $$\\begin{align}\nB_0 &amp;= b_0 \\\\\nB_1 &amp;= b_1(x_1)+b_1(x_2)+\\cdots +b_1(x_N)=Nb_1(x) \\\\\nB_2 &amp;= b_2(x_1, x_2)+\\cdots+b_2(x_1, x_N)+b_2(x_2,\nx_3)+\\cdots+b_2(x_2, x_N)+\\cdots+b_2(x_{N-1}, x_N) \\\\\n&amp;= C_N^2 b_2(x_1, x_2)=\\frac{N!}{2!(N-1)!}b_2(x_1, x_2) \\\\\nB_n &amp;= \\frac{N!}{n!(N-n)!}b_n(x_1,x_2\\cdots x_n)\n\\end{align}$$\nb2(x1, x2)是不能再分解为x1或者x2的单变量函数，直到，bn(x1, x2⋯xn)不能再分解为更少变量的函数。通过以上的构造，可以理解为转化为一种具备轮换对称性的基底，进行函数的展开。\n在计算力学量平均值的时候： $$\\begin{align}\n\\langle B(t)\\rangle &amp;=  \\sum_{n=0}^N \\langle B_n(x_1,x_2\\cdots\nx_n)\\rangle \\\\\n&amp;= \\sum_{n=0}^N \\frac{N!}{n!(N-n)!}\\langle b_n(x_1,x_2\\cdots\nx_n)\\rangle \\\\\n&amp;= \\sum_{n=0}^N \\frac{N!}{n!(N-n)!} \\int b_n(x_1, x_2\\cdots\nx_n)f_n(x_1, x_2\\cdots x_n)dx_1 dx_2\\cdots dx_n\n\\end{align}$$\nBogoliubov-Born-Green-Kirkwood-Yvon级联方程\nLiouvile方程是关于N粒子的运动方程，涉及3N + 1个变量，蕴含的信息远超过宏观观测量需要的信息，有必要进行进一步的提取关键信息，即从分布函数f的规律求导n阶约化分布函数的fn的规律。\nHN为该N粒子体系的Hamilton量，即： $$\\begin{align}\nH_N=\\sum_{i=1}^{N}\\left [ \\frac{p_i^2}{2m}+V_{ext}(r_i)\\right\n]+\\sum_{i&lt;j&gt;}^{N}V_{i j}(r_i,r_j)\n\\end{align}$$\n其中Vext(ri)为第i个粒子受到的外势，Vij表示存在一个两体的相互作用。以下导出n阶约化分布函数fn的时间演化规律。\n$$\\begin{align}\n\\frac{\\partial f_n}{\\partial t} &amp;= \\frac{\\partial }{\\partial t}\\int\nf_N(x_1, x_2 \\cdots x_N, t)d x_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\int \\frac{\\partial }{\\partial t}f_N(x_1, x_2 \\cdots x_N, t)d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\int \\left \\{ H_N, f_N\\right \\}d x_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\int \\left \\{ \\sum_{i=1}^{N}\\left [\n\\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ], f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} +\\int \\left \\{ \\sum_{i&lt;j}^{N}V_{i\nj}(r_i,r_j), f_N\\right \\}d x_{n+1}dx_{n+2}\\cdots dx_{N}\n\\end{align}$$\n其中第一项有$\\sum_{i=1}^N(\\cdot)=\\sum_{i=1}^n(\\cdot)+\\sum_{i=n+1}^N(\\cdot)$，将上式第一项进行化简：\n$$\\begin{align*}\n&amp;\\int \\left \\{ \\sum_{i=1}^{N}\\left [\n\\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ], f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;=\\int \\left \\{ \\sum_{i=1}^{n}\\left [\n\\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ]+\\sum_{i=n+1}^{N}\\left [\n\\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ], f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\int \\left \\{ \\sum_{i=1}^{n}\\left [\n\\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ], f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;+ \\sum_{i=n+1}^{N}\\int \\left \\{ \\left [\n\\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ], f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\int \\left \\{ \\sum_{i=1}^{n}\\left [\n\\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ], f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;+ \\sum_{i=n+1}^{N}\\int \\left \\{ V_{ext}(r_i), f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;+ \\sum_{i=n+1}^{N}\\int \\left \\{ \\frac{p_i^2}{2m}, f_N\\right \\} d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\int \\left \\{ \\sum_{i=1}^{n}\\left [\n\\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ], f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;+ \\sum_{i=n+1}^{N}\\int \\sum_{k=1}^{N} \\left [ \\nabla_{r_k}\nV_{ext}(r_i)\\nabla_{p_k}f_N - \\nabla_{p_k}\nV_{ext}(r_i)\\nabla_{r_k}f_N\\right ]d x_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;+ \\sum_{i=n+1}^{N}\\int \\sum_{k=1}^{N}\\left [\n\\nabla_{r_k}\\frac{p_i^2}{2m}\\nabla_{p_k}f_N-\\nabla_{p_k}\\frac{p_i^2}{2m}\\nabla_{r_k}f_N\\right\n] d x_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\int \\left \\{ \\sum_{i=1}^{n}\\left [\n\\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ], f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;+ \\sum_{i=n+1}^{N}\\int \\sum_{k=1}^{N}\\left [ \\nabla_{r_k}\nV_{ext}(r_i)\\nabla_{p_k}f_N\n-\\nabla_{p_k}\\frac{p_i^2}{2m}\\nabla_{r_k}f_N\\right ] d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\int \\left \\{ \\sum_{i=1}^{n}\\left [\n\\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ], f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;+ \\sum_{i=n+1}^{N}\\int \\left [ \\nabla_{r_i}\nV_{ext}(r_i)\\nabla_{p_i}f_N -\\frac{p_i}{m}\\nabla_{r_i}f_N\\right ] d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\text{使用Guass公式消去}\\\\\n&amp;= \\int \\left \\{ \\sum_{i=1}^{n}\\left [\n\\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ], f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n\\end{align*}$$\n接下来讨论第二项，存在$\\sum_{i &lt;\nj}^N(\\cdot)=\\sum_{i &lt;\nj}^n(\\cdot)+\\sum_{i=1}^n\\sum_{j=n+1}^{N}(\\cdot)$，那么：\n$$\\begin{align*}\n&amp;\\int \\left \\{ \\sum_{i&lt;j}^{N}V_{i j}(r_i,r_j), f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\int \\left \\{ \\sum_{i&lt;j}^{N}V_{i j}(r_i,r_j), f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;+ \\int \\left \\{ \\sum_{i=1}^{n}\\sum_{j=n+1}^{N}V_{i j}(r_i,r_j),\nf_N\\right \\}d x_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\int \\left \\{ \\sum_{i&lt;j}^{N}V_{i j}(r_i,r_j), f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;+ \\int  \\sum_{i=1}^{n}\\sum_{j=n+1}^{N}\\nabla_{r_i}V_{i\nj}(r_i,r_j)\\cdot\\nabla_{p_i}f_Nd x_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n\\end{align*}$$\n最后得到： $$\\begin{align}\n\\frac{\\partial f_n}{\\partial t} &amp;= \\int \\left \\{ \\sum_{i=1}^{n}\\left\n[ \\frac{p_i^2}{2m}+V_{ext}(r_i)\\right ], f_N\\right \\}d\nx_{n+1}dx_{n+2}\\cdots dx_{N} + \\int \\left \\{ \\sum_{i&lt;j}^{N}V_{i\nj}(r_i,r_j), f_N\\right \\}d x_{n+1}dx_{n+2}\\cdots dx_{N} +\n\\int  \\sum_{i=1}^{n}\\sum_{j=n+1}^{N}\\nabla_{r_i}V_{i\nj}(r_i,r_j)\\cdot\\nabla_{p_i}f_Nd x_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\int \\left \\{ H_n, f_N\\right \\}d x_{n+1}dx_{n+2}\\cdots dx_{N} +\n\\int  \\sum_{i=1}^{n}\\sum_{j=n+1}^{N}\\nabla_{r_i}V_{i\nj}(r_i,r_j)\\cdot\\nabla_{p_i}f_Nd x_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\left \\{ H_n, f_n\\right \\} +\n(N-n)\\int  \\sum_{i=1}^{n}\\nabla_{r_i}V_{i,j=(n+1)}\\cdot\\nabla_{p_i}f_Nd\nx_{n+1}dx_{n+2}\\cdots dx_{N} \\\\\n&amp;= \\left \\{ H_n, f_n\\right \\} +\n(N-n)\\int  \\sum_{i=1}^{n}\\nabla_{r_i}V_{i,j=(n+1)}\\cdot\\nabla_{p_i}f_{n+1}dx_{n+1}\n\\\\\n\\end{align}$$\n上述方程为级联方程，其将fn与fn + 1联系在一起。\n平衡态系综\n平衡态的系综原理，解决达到平衡态的体系热力学性质的微观解释。\n微正则系综\n等概率原理和微正则系综\n孤立系统：体系与环境不存在任何形式的相互作用。\n等概率原理（平衡态统计力学的唯一假设）：处于平衡态下的孤立系统，体系的各个可能的微观状态出现的概率相等。表现为：\n$$\\begin{align}\nf=C\\delta(E-H(q,p))\n\\end{align}$$ 其中C的定义为： $$\\begin{align}\n1=\\int_{\\tau}fdpdq=\\lim_{\\Delta E\\to 0}C\\int_{\\Delta E} dqdp\n\\end{align}$$\n任意力学量的⟨B(q, p)⟩的系综平均值为：\n$$\\begin{align}\n\\langle B(q,p)\\rangle=\\int_{\\tau}fB(q,p)dpdq=\\lim_{\\Delta E\\to\n0}C\\int_{\\Delta E} B(q,p)dqdp\n\\end{align}$$\nPoinacre定理\nPoinacre回归定理：对于等能面内的体积有限大的宏观系统，假定其Hamilton量有界，则其|p|,|q|均有界。若时间t = 0时，体系从τ相空间的某点P0出发，则体系在一有限的时间T内，必然会经过P0点足够近的邻近点P′0，其距离小于任意小的预设正数ϵ，即|P0P′0| &lt; ϵ。\n等概率原理和最大熵原理\n本节主要证明：最大熵原理等价于孤立系统达到平衡态后，体系微观状态在等能面上呈等概率分布的假设。\n时刻t系综处于i态的样本数目Ni在dt时间中，离开与增加的变化量以及净变化量：\n$$\\begin{align}\n(dN_i)_{-} &amp;= \\sum_{j(\\neq i)}N_i P_{i\\to j}dt \\\\\n(dN_i)_{+} &amp;= \\sum_{j(\\neq i)}N_j P_{j\\to i}dt \\\\\ndN_i &amp;= (dN_i)_{+} - (dN_i)_{-} \\\\\n&amp;= \\sum_{j(\\neq i)}(N_j-N_i) P_{j\\to i}dt \\\\\n\\frac{dN_i}{dt} &amp;= \\sum_{j(\\neq i)}(N_j-N_i) P_{j\\to i} \\\\\n\\end{align}$$\n其中Pi → j表示从i跃迁到j的概率。同样可以得到： $$\\begin{align}\n\\dot p_i = \\frac{dp_i}{dt} = \\sum_{j(\\neq i)}(p_j-p_i) P_{j\\to i}\n\\end{align}$$ 根据信息熵的定义，定义体系的量S:\n$$\\begin{align}\nS(t) &amp;= -k_B\\sum_i p_i(t)\\ln p_i(t)=-k_B \\langle \\ln p_i(t) \\rangle\n\\\\\n\\dot S &amp;= -k_B\\sum_i \\dot p_i（\\ln p_i+1）\\\\\n&amp;=-k_B\\sum_i \\dot p_i\\ln p_i \\\\\n&amp;= -k_B\\sum_i \\sum_{j(\\neq i)}(p_j-p_i) P_{j\\to i}\\ln p_i \\\\\n&amp;= -k_B\\sum_i \\sum_{j}(p_j-p_i) \\ln p_i P_{j\\to i}\\\\\n&amp;= \\frac{-k_B}{2}\\sum_i \\sum_{j} \\left [ (p_j-p_i) \\ln p_i P_{j\\to\ni} +(p_i-p_j) \\ln p_j P_{i\\to j}\\right ]\\\\\n&amp;= \\frac{k_B}{2}\\sum_i \\sum_{j} (p_i-p_j) (\\ln p_i -\\ln p_j)P_{i\\to\nj}\\\\\n\\end{align}$$\n因为Pi → j &gt; 0，可知Ṡ &gt; 0，S是一个恒增的量。当任意的跃迁量之间满足:\n$$\\begin{align}\np_i=p_j=\\cdots=\\frac{1}{\\Omega}\n\\end{align}$$ 就会有Ṡ = 0，达到最终的平衡态。即得到S的最大值，Gibbs熵： $$\\begin{align}\nS=k_B \\ln \\Omega\n\\end{align}$$\n正则系综\n正则系综：体积V、粒子数N和温度T恒定的体系，也称为(N, V, T)体系。\n设{Hi}为体系的Hamilton量，对所有样本求和得到系综的Hamilton量Hens：\n$$\\begin{align}\nH_{ens}=\\sum_{i=1}^{N}H_i+\\text{热交换项}\n\\end{align}$$\n当体系粒子数不太少，热交换项可以小到忽略。设样本的体系第j种状态的能量为Ej，又设系综中同属于第j种状态的样本体系数为nj。因此，对所有体系状态求和得到系综的总能量：\n$$\\begin{align}\n\\epsilon=\\sum_{j}^{\\text{state}}n_j E_j\n\\end{align}$$\n因为整个正则体系是孤立的，因此系综的能量ϵ是不变的。又对所有的体系状态nj求和，得到系综中的样本样本体系总数N，即： $$\\begin{align}\nN=\\sum_j^{\\text{state}}n_j\n\\end{align}$$\n正则系综的最可几分布\n在给定样本总数N和系综能量ϵ的约束条件下，寻找分布{nj}可以使得正则系综的微观状态W达到最大。按照排列组合的原理，给定分布{nj}，N个样本构成的正则系综的微观状态数为：\n$$\\begin{align}\nW=\\frac{N!}{\\prod_j n_j !}\n\\end{align}$$\n本质是解决一个变分问题，在满足能量与样本数约束的条件下，寻找{ni}分布，使得W最大，可以写为： $$\\begin{align}\n\\Omega = \\ln W-\\alpha (\\sum_j n_j-N)-\\beta (\\sum_j n_j E_j-\\epsilon)\n\\end{align}$$\n利用Lagrange乘子法，极值时应满足： $$\\begin{align}\n\\frac{\\delta \\Omega}{\\delta n_j}&amp;=0,\\forall j \\\\\n\\ln W &amp;= \\ln \\left (\\frac{N!}{\\prod_j n_j !}\\right) \\\\\n&amp;\\simeq N\\ln N-N-\\sum_j (n_j\\ln n_j-n_j) \\\\\n\\frac{\\partial \\ln W}{\\partial n_j} &amp;= -\\ln n_j \\\\\n\\frac{\\delta \\Omega}{\\delta n_j}&amp;= -\\ln n_j-\\alpha-\\beta E_j =0  \\\\\nn_j^* &amp;= e^{-\\alpha-\\beta E_j} \\\\\n\\end{align}$$\n其中nj*表示最可几分布。因此，体系处于第j个态的概率为：\n$$\\begin{align}\nP_j &amp;= \\frac{n_j}{N} = \\frac{e^{-\\alpha-\\beta\nE_j}}{\\sum_i^{\\text{state}}e^{-\\alpha-\\beta E_i}} \\\\\n&amp;= \\frac{e^{-\\beta E_j}}{\\sum_i^{\\text{state}}e^{-\\beta E_i}} \\\\\n&amp;= \\frac{e^{-\\beta E_j}}{Z}\n\\end{align}$$\n其中Z是配分函数。\n具体的物理量计算可以写为： $$\\begin{align}\n\\langle B\\rangle = \\sum_j P_j B_j = \\frac{1}{Z}\\sum_j B_j e^{-\\beta E_j}\n\\end{align}$$\n正则系综中的热力学关系\n\n体系平均能量 $$\\begin{align}\n\\langle E\\rangle  = \\frac{1}{Z}\\sum_j E_j e^{-\\beta E_j} =\n-\\left(\\frac{\\partial \\ln Z}{\\partial \\beta}\\right)_{N,V}\n\\end{align}$$\nHelmholtz自由能 $$\\begin{align}\n\\langle F\\rangle  = -\\frac{1}{\\beta}\\ln Z\n\\end{align}$$\n\n平均压强 $$\\begin{align}\n\\langle p\\rangle  = \\frac{1}{\\beta}\\left(\\frac{\\partial \\ln Z}{\\partial\nV}\\right)_{N,T}\n\\end{align}$$\n熵的期望值 $$\\begin{align}\n\\langle S\\rangle  &amp;= \\frac{\\langle E\\rangle}{Z}+k_B\\ln Z =\n\\frac{1}{\\beta}\\left(\\frac{\\partial \\ln Z}{\\partial T}\\right)_{N,V} +\nk_B\\ln Z \\\\\n&amp;= k_B \\left [\\frac{\\partial (T\\ln Z)}{\\partial T}\\right]_{N,V}\n\\end{align}$$\n正则系综的微观状态数 $$\\begin{align}\nW^*  &amp;=\\frac{N!}{\\prod_j n_j^* !}= Z^N e^{-\\beta \\epsilon}\n\\end{align}$$\n化学势 $$\\begin{align}\n\\mu = \\frac{-1}{\\beta}\\left(\\frac{\\partial \\ln Z}{\\partial\nN}\\right)_{V,T}\n\\end{align}\n$$\n\n巨正则系综\n巨正则系综：体积V固定，与环境存在能量与粒子数交换。体系的不变量为体积V、温度T、化学势μ。\n设H(N)为该粒子数N的体系的Hamilton量，|N, j⟩为该体系第j个本征态，对应的能量为EN, j，存在：\n$$\\begin{align}\nH(N)|N,j\\rangle = |N,j\\rangle E_{N,j}\n\\end{align}$$\n设{Hi}为样本体系的Hamilton量，对所有样本求和得到系综的Hamilton量HGCE为：\n$$\\begin{align}\nH_{GCE}=\\sum_{i=1}^A+\\text{相互作用}\n\\end{align}$$\n当样本足够大的时候，可以认为相互作用项小到可以忽略。\n设巨正则系综中同属于体系粒子数为N的第j个状态（能量为EN, j）的样本体系个数为aN, j，于是在巨正则系综中的所有样本都可以归属于不同的(N, j)值，所有的“GCE的量子态”可以用分布{aN, j}来表征。GCE态可以记为|{aN, j}⟩。由于整个巨正则系综可以看成一个孤立体系，所以根据统计力学假定，各个GCE的量子态|{aN, j}⟩出现的概率是相等的。\n单组分GCE的最可几分布\n单组分体系构成巨正则含有的微观状态数为： $$W(\\{a_{N,j}\\})=\\frac{A!}{\\prod_N\\prod_j\na_{N,j}!}$$\n需要解决的问题是在怎样的分布下W达到最大？\n已经巨正则守恒条件（系综样本数𝒜、系综能量ϵ、系综总粒子数𝒩）为： $$\\begin{align}\n\\sum_N \\sum_j a_{N,j} &amp;= \\mathcal A \\\\\n\\sum_N \\sum_j a_{N,j} E_{N,j} &amp;= \\epsilon \\\\\n\\sum_N \\sum_j a_{N,j}N &amp;= \\mathcal N\n\\end{align}$$\n数学目标为： maxaN, j(ln W)\nLagrange乘子法： $$\\begin{align}\n\\ln \\Omega &amp;= \\ln W -\\alpha\\left( \\sum_{N,j}a_{N,j}-\\mathcal\nA\\right)-\\beta \\left( \\sum_N \\sum_j a_{N,j} E_{N,j} - \\epsilon\\right)\n-\\gamma \\left( \\sum_N \\sum_j a_{N,j}N - \\mathcal N\\right) \\\\\n\\frac{\\delta \\ln \\Omega}{\\delta a_{N,j}} &amp;= 0 \\quad \\forall N,j \\\\\n\\frac{\\delta \\ln W}{\\delta a_{N,j}} &amp;= \\frac{\\delta }{\\delta\na_{N,j}} \\left[ \\ln \\mathcal A!-\\sum_{N,j} (a_{N,j}\\ln\na_{N,j}-a_{N,j})\\right]=-\\ln a_{N,j} \\\\\n\\frac{\\delta \\ln \\Omega}{\\delta a_{N,j}} &amp;= -\\ln a_{N,j}-\\alpha\n-\\beta E_{N,j}-\\gamma N = 0 \\quad \\forall N,j \\\\\n\\end{align}$$\n因此最可几分布为：\naN, j* = e−(α + βEN, j + γN)  ∀N, j\n其中利用样本数守恒计算e−α： $$\\begin{align}\n\\sum_{N,j} a_{N,j} &amp;= \\mathcal A=e^{-\\alpha}\\sum_{N,j} e^{-(\\beta\nE_{N,j}+\\gamma N)} \\\\\ne^{-\\alpha} &amp;= \\frac{\\mathcal A}{\\sum_{N,j} e^{-(\\beta\nE_{N,j}+\\gamma N)}} \\\\\n\\end{align}$$\n定义巨配分函数Ξ为： Ξ(V, β, γ) = ∑N, je−(βEN, j + γN)\n因此系综的最可几分布： $$a_{N,j} =\n\\mathcal A \\frac{e^{-(\\beta E_{N,j}+\\gamma N)}}{\\Xi}$$\n粒子数为N的第j个状态出现的概率为： $$P_{N,j} = \\frac{e^{-(\\beta E_{N,j}+\\gamma\nN)}}{\\Xi}$$\n多组分GCE的最可几分布\nLagrange待定乘子β的确定\n$$\\beta = \\frac{1}{k_B T}$$ ###\nLagrange待定乘子γ的确定 $$\\gamma_i = \\frac{-\\mu_i}{k_B T}$$ ##\n等温等压系综\n近独立子体系的统计热力学\n系综理论具体应用：使用系综理论处理独立子体系和近独立子体系。\n独立子体系和近独立子体系\n从组成粒子的三个角度对宏观体系进行分类，粒子是单组份还是多组分、粒子的位置是否固定、粒子之间是否存在相互作用：\n\n按组成粒子的种类分类。单组分为全同粒子体系，多组分为混合粒子体系。\n按组成粒子的位置是否固定。位置不固定的称为离域子体系，例如气体；位置固定称为定域子体系，例如晶体。\n按有无相互作用分类。粒子之间没有相互作用称为独立子体系；微粒之间存在相互作用称为相倚子体系；粒子之间相互作用非常小，例如气体，称为近独立子体系。\n\n粒子的配分函数\n对于只有一个粒子的体系，可以认为是一个正则系综: $$\\begin{align}\nq\\equiv \\sum_j^{\\text{state}}e^{-\\beta \\epsilon_j} =\n\\sum_k^{\\text{level}}g_k e^{-\\beta \\epsilon_k}\n\\end{align}$$\n其中gk为能级简并度，前一个加和是对状态的加和，后一个加和是对能级的加和。\n现在讨论由N个单组分全同粒子组成的近独立子体系。有离域与定域两种情况，首先讨论定域的情况。\n既然不存在相互作用，每个格点处都有q个花样，因此体系的配分函数为：\nQ = qN\n对于离域的情况，由于粒子间可以轮换，因此需要排除重复计算的项： $$Q=\\frac{q^N}{N!}$$\n由上面可知，分析配分函数的关键是知道{ϵk, gk}（粒子能谱）。接下来分析单个粒子的运动\n分支骨架的运动状态、简单体系的量子力学解\n分子的运动包括分子质心的平动运动、分子绕质心的转动、分子内部组成原子之间的振动和体系电子状态跃迁。\n首先考虑电子运动，电子质量远小于核，因此当核发生变化的时候，电子可以快速运动适应核的变化，但核对电子的运动却不敏感。因此Born-Oppenheimer近似将运动其分为两部分，分别是核的薛定谔方程与固定核骨架之后的解电子的薛定谔方程。\n对于分子的平动、转动和振动都是核的运动，可以用经典力学或者量子力学求解（在经典近似之后可以得到经典的结果，离散状态变为连续状态）。这三种运动无论多么复杂都可以归结为三种基本的模型：三维盒中的只有平动粒子、刚性转子和一维简谐运动。\n此处省略对这三种情况的量子力学解。\n分子配分函数的析因子性\n假定分子的各种运动形态之间互为独立，则能量的加和性和简并度的乘积性会使子的配分函数q总可以写成各种运动形态的（子的）配分函数qk的乘积，q = ∏kqk，称之为子的配分函数的析因子性。\n根据子的配分函数析因子性，只要用量子力学求得分子的每一种运动形态的能谱{ϵj}，继而依次求得该种运动的子的配分函数qk和子的配分函数q。再求得独立定域（离域）子体系的配分函数Q。然后求出所有物理量的系综均值。\n粒子平动、振动、转动的配分函数\n讨论粒子平动、振动、转动的配分函数。\nBose子、Fermi子和Boltzmann子\n\nBose子：每个能量状态上没有容纳粒子数限制，光子、声子。\nFermi子：每个能量状态上最多只能容纳一个粒子，电子、质子、中子。\n全同离域Boltzmann子（Boltzon）：当能级简并度远大于占有该能级的粒子数，此时Bose子与Fermi子之间的差距已经不起作用，两者趋同。即量子效应消失，这时就是经典情况。\n\n配分函数的经典表述\n三维平动子配分函数的经典表述\n刚性转子配分函数的经典表述\n一维谐振子配分函数的经典表述\n平动子体系的分布函数\n理想气体的热力学量\n晶体的定容热容、Einstein与Debye模型\n双原子分子的运动成分及其对称性\n能均分定理、双原子分子气体的热容\n多原子分子气体的运动和配分函数\n多原子分子气体的分布函数\n化学平衡的统计理论\n反应速度理论中的统计理论\n平衡态系综原理在化学中的应用\n固体的状态方程\n外磁场中的气体\n气固吸附\n吸附竞争\n非理想气体\n相关函数\n\n相关或关联（correlation）：物理量在时间或者空间上存在相互联系。\n空间相关函数（space correlation function,\nSCF）：在体系的某一空间位置处的某种性质通过粒子间的相互作用，对另外一个空间位置处的另一种（或同一种）性质造成影响的程度，体现这两个量在空间上的联系。\n相关长度（correlation length）：表征一空间相关性的空间尺度。\n时间相关函数（time correlation function,\nTCF）：体系在受到环境的某种作用，造成对体系某时刻的某个物理量与此后某时刻的另一个（或同一个）物理量之间的相互影响。\n相关时间(correlation time)：表征时间相关性的时间尺度。\n空间自相关函数（auto-SCF）：与另一处的同一物理量的联系。\n空间交叉相关函数（cross-SCF）：与另一处的不同一物理量的联系。\n\n空间相关函数\n体系处于平衡态，物理量的涨落为： $$\\begin{align}\n\\Delta A(r) \\equiv A(r) - \\langle A(r) \\rangle\n\\end{align}$$ 显然处于平衡态的体系涨落为零： $$\\begin{align}\n\\langle \\Delta A(r) \\rangle = \\langle A(r) - \\langle A(r) \\rangle\n\\rangle = 0\n\\end{align}$$ 但是涨落平方的系综平均值具有确定数值，设为a，即： $$\\begin{align}\n\\langle (\\Delta A(r))^2 \\rangle = \\langle [A(r) - \\langle A(r)\n\\rangle]^2 \\rangle = a\n\\end{align}$$\n假定不存在外场，则处于平衡态的体系应当是均匀的，于是a与位置无关。\n对于体系内的两个空间位置r与r′，位置r处的物理量A(r)和另一个位置r′处的另一个物理量B(r′)的乘积的系综平均值为：\n$$\\begin{align}\n\\langle A(r) B(r')\\rangle \\equiv C_{AB}(r,r')\n\\end{align}$$\n称为这两个量的空间相关函数，描述不同位置上的两个物理量之间的联系，“乘积”反映某种平均化后的特征。\n其中一个特例，如果描述的两个物理量相同，称之为空间的自相关函数： $$\\begin{align}\n\\langle A(r) A(r')\\rangle \\equiv C_{AA}(r,r')\n\\end{align}$$\n对于平衡态来说，因为具有均匀性，相关函数的绝对位置是不重要的，重要的是相对位置（具有空间位置平移不变性）：\n$$\\begin{align}\n\\langle A(r)B(r')\\rangle = \\langle A(r-r')B(0) \\rangle\n\\end{align}$$\n进一步，如果体系是各向同性，则相关函数与位置向量无关，仅与两点间距|r − r′|有关，一般来说，在一个距离ξ内，空间相关性CAB值不小，而大于ξ之后相关性变得很小，则长度ξ可作为空间相范围的度量，称之为相关长度。\n位置的概率密度、动量的概率密度\n数密度及其涨落的空间相关函数\nN个全同粒子体系的俄数密度ρ(r)指位置r处单位体积中的粒子个数，即ρ(r)dr为体积元dr中的粒子个数，经典力学意义上可以表示为：\n$$\\rho(r)=\\sum_{i=1}^N\\delta(r-r_i)$$\n体系数密度ρ(r)的系综平均值为： $$\\begin{align}\n\\langle \\rho(r)\\rangle &amp;= \\int dr\\rho(r)f_N(r_1\\cdots r_N)=\\int dr\n\\sum_{i=1}^N\\delta(r-r_i)f_N(r_1\\cdots r_N) \\\\\n&amp;= N\\int dr_1 \\delta(r-r_i) \\int dr_2\\cdots r_N f_N(r_1\\cdots r_N)\n\\\\\n\\end{align}$$ 引入定义： f1(r1) ≡ V∫dr2⋯rNfN(r1⋯rN)\n可得： $$\\begin{align}\n\\langle \\rho(r)\\rangle &amp;= N \\int\ndr_1\\delta(r-r_1)\\frac{1}{V}f_1(r_1)=\\frac{N}{V}f_1(r) \\\\\n&amp;= \\rho f_1(r)\n\\end{align}$$\n其中f1(r)的物理含义为；不管其它粒子的分布情况，有一个粒子出现在r处的概率再乘以体积。对于均匀体系，这个概率分布显然与位置无关并且等于$\\frac{1}{V}$，即对于均匀系： $$\\begin{align*}\n\\int d_2\\cdots d_N f_N(r_1\\cdots r_N)&amp;=\\frac{1}{V} \\\\\nf_1(r) &amp;= 1\n\\end{align*}$$\n接下来讨论数密度的空间相关性。 $$\\begin{align}\n\\langle \\rho(r)\\rho(r')\\rangle &amp;= \\int dr \\rho(r)\\rho (r')\nf_N(r_1\\cdots r_N) \\\\\n&amp;= \\int dr_1\\cdots dr_N\n\\sum_{i=1}^N\\sum_{j=1}^N\\delta(r-r_i)\\delta(r'-r_j)f_N(r_1\\cdots r_N) \\\\\n&amp;= \\int dr_1\\cdots dr_N \\left[\n\\sum_{i=1}^N\\delta(r-r_i)\\delta(r'-r_i)+\\sum_{i\\neq\nj}\\delta(r-r_i)\\delta(r-r_j)\\right]f_N(r_1\\cdots r_N) \\\\\n&amp;= \\rho \\delta(r-r')+N(N-1)\\int dr_1 dr_2\n\\delta(r-r_1)\\delta(r'-r_2) \\int dr_3\\cdots dr_N f_N(r_1\\cdots r_N) \\\\\n&amp;= \\rho \\delta(r-r')+\\frac{N(N-1)}{V^2}\\int dr_1 dr_2\n\\delta(r-r_1)\\delta(r'-r_2) f_2(r_1, r_2) \\\\\n&amp;= \\rho \\delta(r-r') + \\rho^2 f_2(r_1, r_2)\n\\end{align}$$\n其中定义f2为：\nf2(r1, r2) ≡ V2∫dr3⋯drNfN(r1⋯rN)\n\n如果两点距离很大，可认为两点是独立的，即: lim|r1 − r2| → ∞f2(r1, r2) = 1\n在均匀体系中有： f2(r1, r2) = f2(r2, r1)\n进一步为各项同性体系： f2(r1, r2) = f2(|r1, r2|)\n均匀体系数密度涨落的空间自相关函数。均匀体系的数密度涨落为： $$\\begin{align}\n\\Delta \\rho(r)&amp;\\equiv \\rho(r)-\\rho \\\\\n\\langle \\Delta\\rho(r)\\Delta\\rho(r')\\rangle &amp;=\\langle\n\\rho(r)\\rho(r')\\rangle-\\rho^2 \\\\\n&amp;= \\rho \\delta(r-r') + \\rho^2 [f_2(r_1, r_2)-1]\n\\end{align}$$\n\n正则系综中的空间相关函数\n具体分析N个子的正则离域体系，其中其Hamilton为：\n$$H =\n\\frac{1}{2m}\\sum_{i=1}^Np_i^2+U_N+\\sum_{i=1}^N\\epsilon$$\n其中第一项为总动能，第二项为相互作用，第三项为粒子内部的能量项。 ###\n约化分布函数 ### 径向分布函数 ### 直接相关函数和Ornstein-Zernike方程\n时间相关函数\n\n时间相关函数（TCF）：描述前后不同时刻两个物理量之间的相关关系。\n相关时间（correlation time）：表征相关性在时间上的尺度。\n\n定义时间相关函数⟨B(0)C(t)⟩: $$\\begin{align}\n\\langle B(0)C(t)\\rangle \\equiv \\lim_{T\\to \\infty}\\frac{1}{T} d\\tau\nB(\\tau) C(\\tau+t)\n\\end{align}$$\n时间相关函数表述物质运动在时间先后上的相关关系，具备如下的性质： 1.\n由于人一物理量在本质上必须是实数，因此时间相关函数必须是实数。 2. limt → ∞⟨B(0)C(0)⟩ = 0，两个时间间隔无穷远的事件自然不相关了。\n表示怀疑，真的是这样么？\n非平衡定态时的时间相关函数\n非平衡定时，还具备如下的性质： 1.\n时间平移不变性。物理量的相关性在该种状态下，只与相对的时间差有关，而与具体的时刻无关：\n$$\\begin{align}\n   \\langle B(t_1)C(t_2) \\rangle &amp;= \\langle B(t_1-\\tau)C(t_2-\\tau)\n\\rangle \\\\\n   \\langle B(t_1)C(t_2) \\rangle &amp;= \\langle B(0)C(t_2-t_1) \\rangle\n   \\end{align}$$ 2. 非平衡定态。 $$\\begin{align}\n   \\langle \\dot B(t)C(0)\\rangle = -\\langle B(t)\\dot C(0)\\rangle\n   \\end{align}$$\n平衡态时间自相关函数的性质\n平衡态时的时间自相关函数 ⟨CBB(t1, t2) ≡ ⟨B(t1)B(t2)⟩，具有如下性质：\n1. 时间平移不变性。自相关函数只与时间间隔τ ≡ t1 − t2有关:\n$$\\begin{align*}\n   C_{BB}(t_1, t_2) &amp;\\equiv \\langle B(t_1)B(t_2)\\rangle = \\langle\nB(0)B(t_2-t_1)\\rangle \\\\\n   &amp;= \\rangle = \\langle B(0)B(\\tau)\\rangle \\equiv C_{BB}(\\tau)\n   \\end{align*}$$ 2. CBB(0) &gt; 0。\n3. 对于任意的时间τ，CBB(τ)的绝对值不可能大于τ，CBB(0)：\n|CBB(τ)| &lt; CBB(0)\n4. CBB(−τ) = CBB(τ)\n5. 相关时间τB，当间隔时间远大于相关时间之后，时间相关性趋于0：\nlimτ &gt;  &gt; τBCBB(τ) = 0\n时间相关函数的应用\n量子动力学\n连续介质力学\n非平衡态统计力学分为多种形式理论： * 微观层次 * 动理学层次 *\n流体力学层次\n以上三个层次，逐渐粗粒化。在流体力学层次，先将处理的体系设想为连续介质，然后用连续介质来研究这一层次的问题。\n基本概念\n压强张量和应力张量\n粘性液体或者固体中任意单位截面上受到的力不一定在该截面的法向上，需要拓展为张量利用9个标量描述，称为压强张量P ≡ {pαβ|α, β = x, y, z}，在直角坐标系下写为：\n$$\\begin{align}\nP=\n\\begin{bmatrix}\np_{xx} &amp; p_{xy} &amp; p_{xz}\\\\\np_{yx} &amp; p_{yy} &amp; p_{yz}\\\\\np_{zx} &amp; p_{zy} &amp; p_{zz}\\\\\n\\end{bmatrix}\n\\end{align}$$\n应力张量σ取反方向：σ ≡ −P，定义法向量$\\bf n$，该界面上面的力$\\bf\\sigma_n$为： $$\\bf{\\sigma_n} =\\sigma \\cdot \\bf n$$\n同时，应力张量为：\n$$\\sigma = \\sum_{i,j=1}^3\\sigma_{ij}e_ie_j\n\\triangleq \\sigma_{ij}e_ie_j$$\n其中≜是Einstein求和符号。\n应变张量\n以下讨论物体受力后体内粒子位置发生的相对改变。\n体内无限接近的两点P  Q，形变前向量$\\overrightarrow{PQ}\\equiv dr =\n\\sum_{i=1}^3dx_ie_i$，形变后成为向量$\\overrightarrow{P'Q'}\\equiv dr'=dr+du =\n\\sum_{i=1}^3(dx_i+du_i)e_i$，位移变量du = dr′ − dr。\n$$\\begin{align}\n|dr'|^2 &amp;= \\sum_{i=1}^3(dx_i+du_i)^2 =\n\\sum_{i=1}^3(dx_i+\\sum_{k=1}^3\\frac{\\partial u_i}{\\partial x_k}dx_k)^2\n\\\\\n&amp;= \\sum_{i=1}^3 \\left[ (dx_i)^2 +2dx_i\\sum_{k=1}^3\\frac{\\partial\nu_i}{\\partial x_k}dx_k+\\left(\\sum_{k=1}^3\\frac{\\partial u_i}{\\partial\nx_k}dx_k\\right)^2\\right] \\\\\n&amp;= |dr|^2 + 2\\sum_{i=1}^3dx_i \\sum_{k=1}^3\\frac{\\partial\nu_i}{\\partial x_k}dx_k + \\sum_{i,k,l=1}^3\\frac{\\partial u_i}{\\partial\nx_k}\\frac{\\partial u_i}{\\partial x_l}dx_kdx_l \\\\\n&amp;= |dr|^2 + 2\\frac{\\partial u_i}{\\partial x_k}dx_kdx_i +\n\\frac{\\partial u_i}{\\partial x_k}\\frac{\\partial u_i}{\\partial\nx_l}dx_kdx_l \\\\\n&amp;= |dr|^2 + \\left(\\frac{\\partial u_i}{\\partial x_k}+\\frac{\\partial\nu_k}{\\partial x_i}+\\frac{\\partial u_l}{\\partial x_l}\\frac{\\partial\nu_i}{\\partial x_i}\\right) dx_kdx_l \\\\\n&amp;= |dr|^2 + 2\\epsilon_{ij} dx_kdx_l\n\\end{align}$$\n其中令： $$\\epsilon_{ij}\\equiv\n\\left(\\frac{\\partial u_i}{\\partial x_k}+\\frac{\\partial u_k}{\\partial\nx_i}+\\frac{\\partial u_l}{\\partial x_l}\\frac{\\partial u_i}{\\partial\nx_i}\\right)$$\n对角元称为正向应变，非对角元称为切向应变或者剪应变。在应变比较小的情况下，二阶微分项远小于一阶相，可以忽略。因此：\n$$\\begin{align}\n\\epsilon_{ij} &amp;\\approx \\left(\\frac{\\partial u_i}{\\partial\nx_k}+\\frac{\\partial u_k}{\\partial x_i}\\right) \\\\\n\\epsilon &amp;= \\frac{1}{2}\\left[\\nabla u+\\nabla u^T\\right]\n\\end{align}$$\n广义Hooke定律\n在连续形变之后，应力张量σ可普世的认为是应变张量的俄ϵ函数，即σ(ϵ)。在无初应力且应变较小的情况下，略去高次项得：\n$$\\sigma_{ij}=\\left( \\frac{\\partial\n\\sigma_{ij}}{\\partial \\epsilon_{kl}}\\right)_0\\epsilon_{kl}$$\n其中下标为0表示在应变为0处取值。\n当形变较小的时候，饰演的应力与应变值之间服从Hooke定律，将偏微分关系变为线性关系：\nσij = Cijklϵlk\n形变能\n各项同性介质的形变能\n各项同性介质的应力张量\n流体力学\n流体力学就是连续介质力学。Newton粘性公式，剪切应力$\\tau\\equiv \\frac{f}{\\delta\nS}$正比于切向速度： $$\\tau=\\eta\n\\frac{dv}{dy}$$\n流体的运动方程\n流体的连续性方程：\n$$\\begin{align}\n\\frac{\\partial \\rho_m}{\\partial t}+\\nabla\\cdot \\bf j &amp;=0 \\\\\n\\bf{j}(r,t) &amp;= \\rho_m \\bf m \\\\\n\\end{align}$$\n理想流体的运动方程： $$\\rho_m\n\\frac{Dv}{Dt}=\\rho_m(\\frac{v}{t}-v\\cdot\\nabla v)=-\\nabla\\cdot\nP$$\n连续介质的导热\nFourier唯象导热定律： $$\\begin{align}\nq=-\\lambda\\nabla T\n\\end{align}$$\n非平衡热力学基础\n局域平衡近似\n非平衡态的体系有相新的平衡态趋近的趋势，这样的过程称为弛豫过程，弛豫时间记为τmac。\n局域平衡近似是将非平衡的体系分为很多的小部分，其中每一个小部分具备宏观小微观大的特点，宏观小足够反省非平衡态在宏观上的不均匀性，微观大包含足够多的粒子。其中每一个小块，可以认为是这一个小块是均匀的，可以用平衡态的状态参量描述。不同小区域与邻近区域之间的相互作用很弱，微区与微区之间不满足平衡条件，记微区的弛豫时间为τmic。\n局域平衡近似成立有两个条件： * τmic ≪ τmac\n* lmic ≪ lmac，其中lmac为局域平衡成立的空间微观程度，lmac为外力作用造成体系热力学量的波动宏观尺度。\n不可逆过程中的平衡方程\n使用连续介质力学的方案得到非平衡态热力学的平衡（即衡算）方程。在一定的尺度范围内，可以将任何不平衡体系看成连续介质。\n设有一个宏观体系，体积为V，边界为Σ，讨论体系宏观广延量F(t)随时间的演化：\nF(t) = ∫Vρm(r, t)f(r, t)dr\n其中ρm(r, t)为密度质量，f(r, t)为单位质量的广延量，因此ρmf为单位体积的广延量。\n\n\n9-1\n\n讨论的体系包含化学反应，因此体系中有源和汇，设σF(r)是体系的源密度（r处产生F的量/体积/时间），正表示源，负表示汇。有以下的平衡方程：\n$$\\begin{align}\n\\frac{dF(t)}{dt} &amp;= P[F] + \\phi[F] \\\\\nP[F] &amp;\\equiv \\int_V \\sigma_f dr \\\\\n\\phi &amp;\\equiv -\\oint_{\\Sigma}j_F \\cdot dS \\\\\n\\frac{dF(t)}{dt} &amp;= \\frac{d}{dt}\\int_V \\rho_m (r,t)f(r,t)dr =\n\\int_V\\frac{\\partial}{\\partial t}(\\rho_m f)dr \\\\\n&amp;= \\int_V \\sigma_F dr - \\oint_{\\Sigma}j_F\\cdot dS \\\\\n\\int_V\\frac{\\partial}{\\partial t}(\\rho_m f)dr &amp;= \\int_V \\sigma_F dr\n- \\int_{V}\\nabla \\cdot j_F dv \\\\\n\\sigma_F &amp;=  \\frac{\\partial}{\\partial t}(\\rho_m f)+\\nabla \\cdot\nj_F    \\\\\n\\end{align}$$\n称为广延量F的局域平衡方程。其中ρmf是单位体积的广延量F（即F量/体积），σF广延量F的源密度（F产生的量/面积/时间），jF是广延量F的流密度（F的通过量/面积/时间）也称为流或者通量。\n以下讨论几个重要的具体广延量的平衡：质量、动量、能量、角动量和熵。\n连续介质中的质量守恒\n从微体积净增的物质的量一定等于从它外部流入到该微体积的物质的量，称为质量平衡或者质量横算。因为无源σF = 0, f = 1, jF = ρmv。\n$$\\begin{align}\n0 &amp;=  \\frac{\\partial}{\\partial t}(\\rho_m)+\\nabla \\cdot (\\rho_m v)\n\\end{align}$$\n连续介质中的动量平衡\n质量流ρmv可以理解为该处的动量密度，因此ρmvv为该处流体内的动量流。虽然其与能量密度的量纲相同，但是动量流为张量，能量密度是标量。流体的动量为：\n$$\\begin{align}\nG=\\int_v \\rho_m vd^3 r\n\\end{align}$$\n受到外力后，该体积内流动的动量就增加。单位时间内动量的增值就是该体积V所受的外力，即： $$\\begin{align}\nF\\equiv \\frac{d G}{d t}=\\int_v \\frac{\\partial \\rho_m v}{\\partial t} d^3\nr\n\\end{align}$$\n接下来还有具体讨论，暂且跳过\n连续介质中的能量守恒\n核心为分析功率，总功率分为三个部分：应力、质量、传热\n局域熵、不可逆过程的熵产生率\n数学上，散度表示流出\n因为非平衡态的假设是将整个区域分割为小的平衡区域。针对每个小的平衡区域，认为熵的变化分为两部分，分别为平衡体系内熵的变化，以及不同体系内熵的流动。\n局域熵的产生率σs均可由局域热力力量Xi和由它造成的（称为：与之为共轭的）局域流Ji的标积，Xi称为广义力，Ji称为广义流。局域熵产生率σs可表示为：\n$$\\begin{align}\n\\sigma_s = \\sum_i X_i\\cdot X_i\n\\end{align}$$\nOnsager关系\n将局域流Ji按局域力{Xj}展开，取最低的线性近似得到：\n$$\\begin{align}\nJ_i = \\sum_j L_{ij} X_j\n\\end{align}$$ 其中Lij就是各种输运系数。\nOnsager关系为： $$\\begin{align}\nL_{ij} = L_{ji}, L^T = L\n\\end{align}$$ Lij为对称矩阵。\n熵产生极小定理\n熵产生极小定理：对处于稳态的非平衡体系，其熵产生率处于极小值。\n涨落理论\n广义涨落有两大类： *\n无论在平衡态还是非平衡态，体系宏观量瞬时值在其平均值上下快速变动。为狭义的涨落。\n* Brown运动。\n涨落基本概念\n设B为热力学平衡态体系的任意宏观物理量。设体系处于第j个量子态时，该物理量取值Bj，所以物理量B的宏观值就是对量子态的平均值：\n &lt; B &gt;  = ∑jPjBj\n其中Pj为该量子态出现的概率，为方便在不混淆的情况下，省略Bj的下标，记为B。于是体系处于某平衡态的偏差与相对偏差为：\n$$\\begin{align}\n\\Delta B &amp;\\equiv B - &lt;B&gt; \\\\\nr_B &amp;\\equiv \\frac{\\Delta B}{&lt;B&gt;}\n\\end{align}$$\n因为 &lt; ΔB &gt;  = 0恒成立，为了表征涨落的程度，需将偏差的平方对量子态求平均值，称为B在系综中的均方涨落，简称涨落：\n$$\\begin{align}\n&lt;(\\Delta B)^2&gt; &amp;\\equiv \\sum_j P_j - (\\Delta B)^2 =\\left &lt;\n(B-&lt;\\Delta B&gt;)^2\\right&gt; \\\\\n&amp;= \\sum_j P_j\\left(B_j-\\langle B\\rangle\\right)^2=\\sum_j P_j B_j^2-2\n\\sum_j P_j B_j\\langle B\\rangle+\\sum_j P_j\\langle B\\rangle^2 \\\\\n&amp;= \\langle B^2\\rangle -\\langle B\\rangle^2\n\\end{align}$$\n其中⟨B2⟩为物理量B2的均值，或B的均方值。同样，相对偏差平方的均值可表为：\n$$\\begin{equation}\n\\begin{aligned}\n\\left\\langle r_B^2\\right\\rangle\n&amp;\\equiv\\left\\langle\\left(\\frac{\\Delta B}{\\langle\nB\\rangle}\\right)^2\\right\\rangle=\\frac{\\left\\langle(\\Delta\nB)^2\\right\\rangle}{\\langle B\\rangle^2}=\\frac{\\left\\langle(B-\\langle\nB\\rangle)^2\\right\\rangle}{\\langle B\\rangle^2} \\\\\n&amp;= \\frac{\\langle B^2\\rangle}{\\langle B\\rangle^2}-1\n\\end{aligned}\n\\end{equation}$$\n称为热力学量B的相对涨落。\n在连续谱时候的情况\n涨落理论\n正则系综中的涨落\n正则系综存在与环境的热交换，因此(N, V, T)恒定，体系存在能量E的涨落，能量均值： $$\\begin{align}\n\\langle E\\rangle &amp;= \\sum_j E_j P_j=\\frac{1}{Z}\\sum_j E_j (\\Omega_j\ne^{\\frac{-E_j}{k_B T}}) \\\\\n\\langle E\\rangle Z &amp;= \\sum_j E_j (\\Omega_j e^{\\frac{-E_j}{k_B T}})\n\\\\\n\\end{align}$$ 两边被$\\left(\n\\frac{\\partial}{\\partial T}\\right)_{V,N}$作用得到： $$\\begin{equation}\nZ\\left(\\frac{\\partial\\langle E\\rangle}{\\partial T}\\right)_{V, N}+\\langle\nE\\rangle\\left(\\frac{\\partial Z}{\\partial T}\\right)_{V,\nN}=\\frac{1}{k_{\\mathrm{B}} T^2} \\sum_j E_j^2\\left(\\Omega_j\n\\mathrm{e}^{-E_j /\\left(k_{\\mathrm{B}}\nT\\right)}\\right)=\\frac{Z\\left\\langle E^2\\right\\rangle}{k_{\\mathrm{B}}\nT^2}\n\\end{equation}$$\n根据$\\langle E\\rangle=k_B T^2\\left(\n\\frac{\\partial \\ln Z}{\\partial T}\\right)_{V, N}$得到$\\left( \\frac{\\partial Z}{\\partial T}\\right)_{V,\nN}=\\frac{Z}{k_B T^2}\\langle E\\rangle$，因此： $$\\begin{align}\n\\left(\\frac{\\partial\\langle E\\rangle}{\\partial T}\\right)_{V, N} =\n\\frac{1}{k_B T^2}\\left[\\langle E^2\\rangle-\\langle E\\rangle^2\\right]\n\\end{align}$$\n根据定容热容$C_V =\n\\left(\\frac{\\partial\\langle E\\rangle}{\\partial T}\\right)_{V,\nN}$，可以得到正则系统的能量涨落和能量的相对涨落分别为： $$\\begin{equation}\n\\begin{gathered}\n\\left\\langle(\\Delta E)^2\\right\\rangle=\\left\\langle\nE^2\\right\\rangle-\\langle E\\rangle^2=k_{\\mathrm{B}}\nT^2\\left(\\frac{\\partial\\langle E\\rangle}{\\partial T}\\right)_{V,\nN}=k_{\\mathrm{B}} T^2 C_V \\\\\n\\left\\langle r_E^2\\right\\rangle=\\frac{\\left\\langle(\\Delta\nE)^2\\right\\rangle}{\\langle E\\rangle^2}=\\frac{1}{\\langle E\\rangle^2}\nk_{\\mathrm{B}} T^2\\left(\\frac{\\partial\\langle E\\rangle}{\\partial\nT}\\right)_{V, N}=k_{\\mathrm{B}} T^2 \\frac{C_V}{\\langle E\\rangle^2}\n\\propto \\frac{1}{N}\n\\end{gathered}\n\\end{equation}$$\n巨正则系综中粒子数能能量的涨落\n平衡态开放体系中的自发涨落、Onsager的涨落回归假设\n讨论平衡态开放体系的中的任意动力学量出现的自发涨落是自然的，但是更重要的一层意义是它的讨论有助于理解非平衡态。\nOnsager注意到有两种弛豫过程： *\n平衡态在没有外场干预的条件下，内部分子的热运动引起动力学量的自发涨落：不断偏离均值再回归均值。（微观弛豫）\n*\n当体系受到某种外场作用，使之成为一个宏观的非平衡状态，若突然终止该外场，则体系将通过弛豫过程趋于平衡态。（宏观弛豫）\nOnsager假设这两种弛豫过程服从相同的规律，称为涨落回归假设。后来人们意识到，Onsager的假设在力学上有深刻的原因，即1951年Callen和Welton证明涨落耗散定理。\n以下先用经典理论讨论平衡体系中的自发涨落问题。\n非平衡态的系综平均\n上述Onsager假设联系两种驰豫，前者是平衡态的自发涨落弛豫，其系综平均记为⟨⋅⟩；后者是非平衡态的宏观弛豫，其系综平均记为$\\overline{\\left(\\cdot\\right)}$，在时刻t的瞬时系综平均值记为$\\overline{A}(t)$。\n考虑一个纯态，初始时刻是一个相点，将t时刻体系的任意动力学量A记为： A(t) = A[rN(t), pN(t)] ≡ A(t; rN(0), pN(0)) ≜ A(t; rN, pN)\n其中rN, pN特指初始条件rN(0), rN(0)。\n更普世的情况，考虑一个混合态，初始时刻是一个分布，故任意时刻A(t)的均值要用系综平均求。设ϕ(rN, pN)为非平衡态体系在相空间的分布函数，因此A(t)的系综平均值为： $$\\begin{equation}\n\\begin{aligned}\n\\bar{A}(t)&amp;=\\int \\mathrm{d} \\boldsymbol{r}^N \\mathrm{~d}\n\\boldsymbol{p}^N \\phi\\left(\\boldsymbol{r}^N, \\boldsymbol{p}^N\\right)\nA\\left(t ; \\boldsymbol{r}^N, \\boldsymbol{p}^N\\right) \\\\\n1 &amp;= \\int \\mathrm{d} \\boldsymbol{r}^N \\mathrm{~d} \\boldsymbol{p}^N\n\\phi\\left(\\boldsymbol{r}^N, \\boldsymbol{p}^N\\right)\n\\end{aligned}\n\\end{equation}$$\n这里采用Heisenber绘景思想，将时间的俄影响归于力学量，而非分布函数。\n任意动力学量A的瞬时微观值A(t)偏离平衡的量可定义为：δA(t) ≡ A(t) − ⟨A⟩$\nA(t)的非平衡均值Ā(t)偏离平衡的量为： $$\\begin{equation}\n\\Delta \\bar{A}(t)=\\int \\mathrm{d} \\boldsymbol{r}^N \\mathrm{~d}\n\\boldsymbol{p}^N \\phi\\left(\\boldsymbol{r}^N,\n\\boldsymbol{p}^N\\right)\\left[A\\left(t ; \\boldsymbol{r}^N,\n\\boldsymbol{p}^N\\right)-\\langle A\\rangle\\right]=\\overline{\\delta A(t)}\n\\end{equation}$$\n平衡态的自发涨落\n在平衡态下，δA(t)的平均值有：\n⟨δA(t)⟩ = 0\n但是有意义的是平衡时不同不同偏离量之间的相关，例如δA(t)与δA(0)之间的相关可表示为涨落的时间自相关函数：\nC(t) ≡ ⟨δA(t)δA(0)⟩\n对于经典体系： C(t) = ∫drN dpNf(rN, pN)δA(0; rN, pN)δA(t; rN, pN)\n其中f(rN, pN)是相空间中平衡时的分布函数。\nC(t)的性质如下： 1.\nC(t) ≡ ⟨δA(t)δA(0)⟩ = ⟨A(t)A(0)⟩ − ⟨A⟩2\n2. 平衡体系的时间相关函数具有时间平移不变性，即与时间原点的选取无关。 3.\n若A(−t)与A(0)两个量可以对易，则交换两者的次序得到：\nC(t) = ⟨δA(−t)δA(0)⟩ = ⟨δA(0)δA(−t)⟩ = C(−t)\n对于经典体系这样的对易衡成立，对于量子体系则不一定。 4. C(0) = ⟨δA(0)δA(0)⟩ = ⟨(δA(0))2⟩\n当两个时间间隔极大时，δA(t)与δA(0)之间的相关会趋于零。可见任意力学量A在平衡态涨落的时间自相关函数总是呈现衰减到零的趋势，Onsager称之为涨落的“回归”。\nOnsager涨落回归假设的数学描述\n基于上述对于平衡涨落的时间自相关函数，现在考虑非平衡体系开始相平衡的弛豫。设t = 0时撤区外场让制备得到的非平衡体系开始相平衡态作自由弛豫。Onsager涨落回归假设是指在线性范围内，可以假设弛豫服从如下方程：\n$$\\begin{align}\n\\frac{\\Delta \\bar A(t)}{\\Delta\\bar A(0)}=\\frac{C(t)}{C(0)}\n\\end{align}$$\n左边表示非平衡体系向平衡态作宏观弛豫的衰减程度，右边表示平衡涨落的自相关行为或微观弛豫。假设这两种弛豫规律相等，这就是Onsager的涨落回归假设。换言之，对于一个近平衡体系，无法区分是自发涨落还是偏离平衡后的弛豫，那么自发涨落自相关的行为实际上应该与t瞬间非平衡均值偏离平衡的量衰减到平衡的行为是相同的。\n非平衡分布函数ϕ(rN, pN)\n平衡态分布f与非平衡态分布ϕ在近平衡的范围内应当有：\n$$\\begin{equation}\n\\frac{\\phi\\left(\\boldsymbol{r}^N,\n\\boldsymbol{p}^N\\right)}{f\\left(\\boldsymbol{r}^N,\n\\boldsymbol{p}^N\\right)}=\\frac{A\\left(t=0 ; \\boldsymbol{r}^N,\n\\boldsymbol{p}^N\\right)}{\\langle A\\rangle}\n\\end{equation}$$ 即： $$\\begin{align}\n\\phi\\left(\\boldsymbol{r}^N, \\boldsymbol{p}^N\\right)=\\frac{A\\left(t=0 ;\n\\boldsymbol{r}^N, \\boldsymbol{p}^N\\right)}{\\langle\nA\\rangle}f\\left(\\boldsymbol{r}^N, \\boldsymbol{p}^N\\right)\n\\end{align}$$ 得到： $$\\begin{equation}\n\\begin{aligned}\n\\bar{A}(t) &amp; =\\int \\mathrm{d} \\boldsymbol{r}^N \\mathrm{~d}\n\\boldsymbol{p}^N \\phi\\left(\\boldsymbol{r}^N, \\boldsymbol{p}^N\\right)\nA\\left(t ; \\boldsymbol{r}^N, \\boldsymbol{p}^N\\right) \\\\\n&amp; =\\langle A\\rangle^{-1} \\int \\mathrm{d} \\boldsymbol{r}^N\n\\mathrm{~d} \\boldsymbol{p}^N f\\left(\\boldsymbol{r}^N,\n\\boldsymbol{p}^N\\right) A\\left(0 ; \\boldsymbol{r}^N,\n\\boldsymbol{p}^N\\right) A\\left(t ; \\boldsymbol{r}^N,\n\\boldsymbol{p}^N\\right)\n\\end{aligned}\n\\end{equation}$$ 即： $$\\begin{aligned}\n\\bar{A}(t) =\\langle A\\rangle^{-1}\\langle A(0)A(t)\\rangle\n\\end{aligned}$$\n得到瞬时非平衡均值偏离平衡的量： $$\\begin{equation}\n\\begin{aligned}\n\\Delta \\bar{A}(t) &amp;\\equiv \\bar{A}(t)-\\langle A\\rangle=\\langle\nA\\rangle^{-1}\\langle A(0) A(t)\\rangle-\\langle A\\rangle \\\\\n&amp;=\\langle A\\rangle^{-1}\\left\\{\\langle A(0) A(t)\\rangle-\\langle\nA\\rangle^2\\right\\} \\\\\n&amp;=\\langle A\\rangle^{-1}\\langle \\delta A(0) \\delta A(t)\\rangle \\\\\n&amp;= \\langle A\\rangle^{-1}C(t) \\\\\nC(t) &amp;= \\Delta \\bar{A}(t)\\langle A\\rangle\n\\end{aligned}\n\\end{equation}$$\n左边是平衡态力学量A的自发涨落，右边是非平衡不可逆过程的弛豫。\n涨落的准热力学理论\n涨落的准热力学理论（quasi-thermodynamic\ntheory）是计算宏观热力学量涨落的普遍理论。其思路是先求出各种略微偏移平衡态的宏观态出现的概率，然后通过统计平均求出各种热力学量的均方偏差、相对涨落。\n设体系的能量、体积和粒子数分别为E, V, N，体系的熵为S = kBln Ω，Ω为微观状态数，无论系统处于平衡还是偏离平衡均适用。若该体系孤立，则当体系处于平衡时体系熵和微观状态数均达到最大。\nS̄ = kBln Ωmax\n出现熵极大的概率为Wmax，其应该与Ωmax成正比： Wmax ∝ Ωmax = eS̄/kB\n由于涨落，熵可以偏离其极大值，体系熵为S的概率为W依然与为微观状态数成正比： W ∝ Ω = eS/kB\n熵的偏离值ΔS ≡ S − S̄，得到：\n$$\\begin{align}\nW = W_{\\max}\\mathrm{e}^{\\Delta S / k_{\\mathrm{B}}}\n\\end{align}$$ 称为Smoluchowski-Einstain公式。\n将该孤立系统的分析拓展到与环境有接触的非孤立系统。把系统与环境看成是一个拓展体系，将拓展体系视为一个孤立的个体：\nEex = E + Eb, Vex = V + Vb\n其中下标”ex”指拓展体系，“b”指环境，无下标指体系。显然存在以下关系：\nΔE = −ΔEb, ΔV = −ΔVb, ΔN = −ΔNb\n由于拓展体系是孤立体系，因此熵偏差值为： ΔSex = ΔS + ΔSb\n有： W(ΔSex) = Wmaxe(ΔS + ΔSb)/kB\n假设环境足够大，有确定的温度T和压强p，则有： $$\\begin{align}\n\\Delta S_{\\mathrm{b}}&amp;=\\frac{1}{T}\\left(\\Delta E_{\\mathrm{b}}+p\n\\Delta V_{\\mathrm{b}}\\right)=-\\frac{1}{T}(\\Delta E+p \\Delta V) \\\\\nW\\left(\\Delta S_{\\mathrm{ex}}\\right) &amp;\\equiv W(\\Delta S, \\Delta E,\n\\Delta V)=W_{\\max } \\mathrm{e}^{\\left(\\Delta S+\\Delta S_b\\right) /\nk_{\\mathrm{B}}}=W_{\\max } \\mathrm{e}^{(T \\Delta S-\\Delta E-p \\Delta V)\n/\\left(k_{\\mathrm{B}} T\\right)}\\\\\nW &amp;= W_{\\max } \\mathrm{e}^{-(\\Delta F+p \\Delta V)\n/\\left(k_{\\mathrm{B}} T\\right)}\n\\end{align}$$ 这是封闭体系的Smoluchowski公式。\n单组分封闭体系的涨落、开放体系涨落\nSmoluchowski-Einstein理论从另一个角度把计算涨落问题与热力学量在理论上结合起来。该理论一方面，不是从体系的微观状态的概率分布为基础，因此属于唯象理论；另一方面，它能导出涨落，而涨落是纯热力学无法涉及的。因此它被称为准热力学理论\n下面将介绍，如何利用该公式导出体系各宏观物理量的涨落以及涨落之间的关系\n待补全\n封闭体系热力学量的涨落\n开放体系热力学量的涨落\n临界点附近的涨落\n多变量涨落的准热力学理论\n动理学描述与Boltzmann方程\n近平衡态体系发生的典型过程有热传导、扩散、黏滞现象、电导等，总称为输运过程。当体系处于非平衡态时，其体系性质随时间变化而变化。本篇介绍非平衡态处于近平衡态的体系，解释这些不可逆过程的方向，求出不可逆过程中的输运系数。与平衡态类似，非平衡态问题的关键仍然是求得体系的分布函数，但是由于非平衡态的原因，分布函数是时间的函数。因此，关键问题是求得分布函数随时间变化所需满足的方程，Boltzmann方程，是求算许多输运系数的依据，奠定了非平衡统计力学的基础。\nBoltzmann方程\n混合稀薄气体\n假定在混合稀薄气体中间，气体分子之间的相互作用只是二体碰撞，不存在三体碰撞，将第j种的物种的单粒子分布记为fj(1)(q1, p1, t)，混合稀薄气体体系的宏观性质只取决于{fj(1)(r, v1, t)}（动量改用速度），于是fj(1)(r, v1, t)dvj代表t时刻在r处单位体积内第j种物种粒子速度处于vj → vj + dvj的粒子数；或者fj(1)(r, v1, t)dvjdr代表t时刻在r处单位体积内第j种物种粒子速度处于vj → vj + dvj、位置处于r → r + dr的粒子数，其中vj → vj + dvj的粒子数，其中fj(1)(r, v1, t)为第j种物种粒子μ空间的数密度。对v积分得到粒子数密度： ρj(r, t) = ∫fj(1)(r, vj, t)dvj\n再对位置空间积分，得到第j种物种的粒子数为： ∬fj(1)(r, vj, t)drdvj = ∫ρj(r, t)dr = Nj\n几种平均速度的定义\n\n在t时刻r处第j种物种粒子的平均速度为： $$\\begin{equation}\n\\left\\langle\\boldsymbol{v}_j(\\boldsymbol{r},\nt)\\right\\rangle=\\frac{1}{\\rho_j(\\boldsymbol{r}, t)} \\int\n\\boldsymbol{v}_j f_j^{(1)}\\left(\\boldsymbol{r}, \\boldsymbol{v}_j,\nt\\right) \\mathrm{d} \\boldsymbol{v}_j\n\\end{equation}$$ 其中对所有不同速度的第j种物种粒子求平均，它代表第j种物种粒子的宏观流向。设mj为第j种物种粒子的质量，于是j的质量密度为： (ρm)j ≡ mjρj\n该混合稀薄气体体系的总质量密度为： ρm = ∑j(ρm)j = ∑jmjρj\n在t时刻r处所有物种粒子总质量平均速度为：\n$$\\begin{equation}\n\\boldsymbol{v}_0(\\boldsymbol{r}, t) \\equiv\n\\frac{\\sum_j\\left\\langle\\boldsymbol{v}_j\\right\\rangle\\left(\\rho_m\\right)_j}{\\sum_j\\left(\\rho_m\\right)_j}=\\frac{\\sum_j\\left\\langle\\boldsymbol{v}_j\\right\\rangle\nm_j \\rho_j}{\\sum_j m_j \\rho_j}=\\frac{1}{\\rho_m}\n\\sum_j\\left\\langle\\boldsymbol{v}_j\\right\\rangle\\left(\\rho_m\\right)_j\n\\end{equation}$$\n第j种物种中的某一粒子相对于整个流体质心的相对速度为：\nVj ≡ vj − v0\n用相对速度的局域瞬时的系综平均称为第j种物种的扩散速度： $$\\begin{equation}\n\\left\\langle\\boldsymbol{V}_j\\right\\rangle \\equiv\n\\frac{1}{\\rho_j(\\boldsymbol{r}, t)}\n\\int\\left(\\boldsymbol{v}_j-\\boldsymbol{v}_0\\right)\nf_j^{(1)}\\left(\\boldsymbol{r}, \\boldsymbol{v}_j, t\\right) \\mathrm{d}\n\\boldsymbol{v}_j\n\\end{equation}$$ 乘以其质量密度后，再对所有物种加和，则： ∑j⟨Vj⟩(ρm)j = 0\n\n流向量\n设ψ为第j种物种分子的某一性质（物理量），ψj的流是指单位时间内通过单位截面的ψj的量，即ψj的通量。\n\n\n11-1\n\n单位时间，以相对速度并且有密度分布，穿过单位面积的粒子数为: (ds ⋅ Vj dt)(fj dvj) = ds(n ⋅ Vjfj dvj)dt\n因此流等于： ∫ψj(n ⋅ Vjfj dvj) = n ⋅ ∫ψjVjfj dvj\n因此定义流向量： Ψj = ∫ψjVjfj dvj\n质量流向量、动量流向量、能量流向量（热流向量）\nBoltzmann方程\n讨论单粒子分布函数需要遵守的方程，即Boltzmann方程，这是稀薄气体严格的动理论的基本方程。由该方程出发，从分子质量、分子间相互作用，可得到指定温度下的扩散系数、导热系数、黏滞系数等输运性质。\n继续讨论多组分混合稀薄气体。仅考虑两体的弹性碰撞。将单粒子分布函数fj(1)省略上标，简记为fj。\n\n二体弹性碰撞\n碰撞分析 任意时刻、任意位置碰撞前后第j种组分粒子数一定守恒，故有： $$\\begin{equation}\n\\begin{aligned}\n&amp; f_j\\left(\\boldsymbol{r}+\\boldsymbol{v}_j \\mathrm{~d} t,\n\\boldsymbol{v}_j+\\frac{\\boldsymbol{X}_j}{m_j} \\mathrm{~d} t,\nt+\\mathrm{d} t\\right) \\mathrm{d} \\boldsymbol{r} \\mathrm{d}\n\\boldsymbol{v}_j \\\\\n= &amp; f_j\\left(\\boldsymbol{r}, \\boldsymbol{v}_j, t\\right) \\mathrm{d}\n\\boldsymbol{r} \\mathrm{d} \\boldsymbol{v}_j+\\sum_i\\left(\\Gamma_{j\ni}^{(+)}-\\Gamma_{j i}^{(-)}\\right) \\mathrm{d} \\boldsymbol{r} \\mathrm{d}\n\\boldsymbol{v}_j \\mathrm{~d} t \\\\\n\\end{aligned}\n\\end{equation}$$ 其中Γji(+)drdvj dt, Γji(−)drdvj dt分别代表流入的与流出相空间的粒子数。\n$$\\begin{equation}\n\\begin{aligned}\nf_j\\left(\\boldsymbol{r}+\\boldsymbol{v}_j \\mathrm{~d} t,\n\\boldsymbol{v}_j+\\frac{\\boldsymbol{X}_j}{m_j} \\mathrm{~d} t,\nt+\\mathrm{d} t\\right)=&amp;f_j\\left(\\boldsymbol{r}, \\boldsymbol{v}_j,\nt\\right)+\\frac{\\partial f_j}{\\partial t} \\mathrm{~d}\nt+\\nabla_{\\boldsymbol{r}} f_j \\cdot \\boldsymbol{v}_j \\mathrm{~d}\nt+\\nabla_{\\boldsymbol{v}_j} f_j \\cdot \\frac{\\boldsymbol{X}_j}{m_j}\n\\mathrm{~d} t \\\\\n\\frac{\\partial f_j}{\\partial t}+\\boldsymbol{v}_j \\cdot\n\\nabla_{\\boldsymbol{r}} f_j+\\frac{\\boldsymbol{X}_j}{m_j} \\cdot\n\\nabla_{\\boldsymbol{v}_j} f_j=&amp;\\sum_i\\left(\\Gamma_{j\ni}^{(+)}-\\Gamma_{j i}^{(-)}\\right), \\quad \\forall j\n\\end{aligned}\n\\end{equation}$$ 上面便是Boltzmann方程，代表第j种组分粒子μ空间的数密度时间演化规律。左边是非碰撞流动对数密度的贡献，称为漂移项；右边代表碰撞对数密度变化的贡献，称为碰撞项。\n当体系处于定态的时候$\\frac{\\partial\nf_j}{\\partial t}=0$，故Boltzmann方程为： $$\\begin{equation}\n\\boldsymbol{v}_j \\cdot \\nabla_{\\boldsymbol{r}}\nf_j+\\frac{\\boldsymbol{X}_j}{m_j} \\cdot \\nabla_{\\boldsymbol{v}_j}\nf_j=\\sum\\left(\\Gamma_{j i}^{(+)}-\\Gamma_{j i}^{(-)}\\right), \\quad\n\\forall j .\n\\end{equation}$$\n碰撞项分析 具体分析Γji(+), Γji(−)的计算方法，针对组分j计算其碰撞i组分之后脱离j组分，记为Γji(−):\nΓji(−) = 2π∬fj(r, vj, t)fi(r, vi, t)|vi − vj|b db dvi\n这个表达式假定了粒子速度与位置无关，称为分子混沌假设。这是证明过程中薄弱的地方。\n同理，考虑由i组分碰撞成j组分的贡献。最后得到： $$\\begin{equation}\n\\frac{\\partial f_j}{\\partial t}+\\boldsymbol{v}_j \\cdot\n\\nabla_{\\boldsymbol{r}} f_j+\\frac{\\boldsymbol{X}_j}{m_j} \\cdot\n\\nabla_{\\boldsymbol{v}_j} f_j=2 \\pi \\sum_i \\int_b\n\\int_{\\boldsymbol{v}_i} b \\mathrm{~d} b \\mathrm{~d}\n\\boldsymbol{v}_i\\left|\\boldsymbol{v}_i-\\boldsymbol{v}_j\\right|\\left\\{f_j^{\\prime}\nf_i^{\\prime}-f_j f_i\\right\\}, \\quad \\forall j\n\\end{equation}$$ 其中： $$\\begin{equation}\n\\left\\{\\begin{aligned}\nf_i^{\\prime} &amp; \\equiv f_i\\left(\\boldsymbol{r},\n\\boldsymbol{v}_i^{\\prime}\\left(\\boldsymbol{v}_i,\n\\boldsymbol{v}_j\\right), t\\right) \\\\\nf_j^{\\prime} &amp; \\equiv f_j\\left(\\boldsymbol{r},\n\\boldsymbol{v}_j^{\\prime}\\left(\\boldsymbol{v}_i,\n\\boldsymbol{v}_j\\right), t\\right) \\\\\nf_i &amp; \\equiv f_i\\left(\\boldsymbol{r}, \\boldsymbol{v}_i, t\\right) \\\\\nf_j &amp; \\equiv f_j\\left(\\boldsymbol{r}, \\boldsymbol{v}_j, t\\right)\n\\end{aligned}\\right.\n\\end{equation}$$\n\nEnskog方程\n接下来从Boltamann输运方程出发，求混合稀薄气体中的各种输运过程中粒子ψ的时间演化，这便是Enskog方程。\n性质的时间演化\n考虑j组分粒子的性质ψ，将Boltzmann方程两边作用∫dvjψj(⋅)得到：\n$$\\begin{equation}\n\\begin{aligned}\n&amp; \\int \\mathrm{d} \\boldsymbol{v}_j \\psi_j\\left[\\frac{\\partial\nf_j}{\\partial t}+\\boldsymbol{v}_j \\cdot \\nabla_r\nf_j+\\frac{\\boldsymbol{X}_j}{m_j} \\cdot \\nabla_{\\boldsymbol{v}_j}\nf_j\\right] \\\\\n= &amp; 2 \\pi \\sum_i \\iiint \\psi_j\\left(f_j^{\\prime} f_i^{\\prime}-f_j\nf_i\\right)\\left|\\boldsymbol{v}_i-\\boldsymbol{v}_j\\right| b \\mathrm{~d} b\n\\mathrm{~d} \\boldsymbol{v}_i \\mathrm{~d} \\boldsymbol{v}_j, \\quad \\forall\nj\n\\end{aligned}\n\\end{equation}$$ 左边第一项写为： $$\\begin{equation}\n\\frac{\\partial}{\\partial t} \\int \\mathrm{d} \\boldsymbol{v}_j \\psi_j\nf_j-\\int \\mathrm{d} \\boldsymbol{v}_j\\left(\\frac{\\partial\n\\psi_j}{\\partial t}\\right) f_j=\\frac{\\partial}{\\partial\nt}\\left(\\rho_j\\left\\langle\\psi_j\\right\\rangle\\right)-\\rho_j\\left\\langle\\frac{\\partial\n\\psi_j}{\\partial t}\\right\\rangle\n\\end{equation}$$ 左边第二项写为： $$\\begin{equation}\n\\begin{aligned}\n\\int \\mathrm{d} \\boldsymbol{v}_j \\psi_j \\boldsymbol{v}_j \\cdot\n\\nabla_{\\boldsymbol{r}} f_j &amp; =\\nabla_{\\boldsymbol{r}} \\cdot \\int\n\\mathrm{d} \\boldsymbol{v}_j \\psi_j \\boldsymbol{v}_j f_j-\\int \\mathrm{d}\n\\boldsymbol{v}_j\\left(\\nabla_{\\boldsymbol{r}} \\psi_j\\right) \\cdot\n\\boldsymbol{v}_j f_j-\\int \\mathrm{d} \\boldsymbol{v}_j\n\\psi_j\\left(\\nabla_{\\boldsymbol{r}} \\cdot \\boldsymbol{v}_j\\right) f_j \\\\\n&amp; =\\nabla_{\\boldsymbol{r}} \\cdot\\left(\\rho_j\\left\\langle\\psi_j\n\\boldsymbol{v}_j\\right\\rangle\\right)-\\rho_j\\left\\langle\\boldsymbol{v}_j\n\\cdot \\nabla_{\\boldsymbol{r}} \\psi_j\\right\\rangle\n\\end{aligned}\n\\end{equation}$$ 左边第三项： $$\\begin{equation}\n\\begin{aligned}\n\\int \\mathrm{d} \\boldsymbol{v}_j \\psi_j \\frac{\\boldsymbol{X}_j}{m_j}\n\\cdot \\nabla_{\\boldsymbol{v}_j} f_j &amp; =\\frac{1}{m_j}\n\\boldsymbol{X}_j \\cdot \\int \\mathrm{d} \\boldsymbol{v}_j \\psi_j\n\\nabla_{\\boldsymbol{v}_j} f_j \\\\\n&amp; =\\frac{1}{m_j} \\boldsymbol{X}_j \\cdot\\left[\\int \\mathrm{d}\n\\boldsymbol{v}_j \\nabla_{\\boldsymbol{v}_j}\\left(\\psi_j f_j\\right)-\\int\n\\mathrm{d} \\boldsymbol{v}_j\\left(\\nabla_{\\boldsymbol{v}_j} \\psi_j\\right)\nf_j\\right]\n\\end{aligned}\n\\end{equation}$$ 结合Gauss定律： $$\\begin{equation}\n\\iiint_V \\mathrm{~d} \\boldsymbol{v} \\nabla\\left(\\begin{array}{c}\nf \\\\\n\\cdot \\boldsymbol{A} \\\\\n\\times \\boldsymbol{A}\n\\end{array}\\right)=\\oint_S \\mathrm{~d}\n\\boldsymbol{s}\\left(\\begin{array}{c}\nf \\\\\n\\cdot \\boldsymbol{A} \\\\\n\\times \\boldsymbol{A}\n\\end{array}\\right)\n\\end{equation}$$ 得到： ∫dvj∇vj(ψjfj) = ∮edgeds(ψjfj) = 0.\n\n结合以上三项得到关于j组分的Enskog方程： $$\\begin{equation}\n\\begin{aligned}\n&amp; \\frac{\\partial}{\\partial\nt}\\left(\\rho_j\\left\\langle\\psi_j\\right\\rangle\\right)+\\nabla_{\\boldsymbol{r}}\n\\cdot\\left(\\rho_j\\left\\langle\\psi_j\n\\boldsymbol{v}_j\\right\\rangle\\right)-\\rho_j\\left[\\left\\langle\\frac{\\partial\n\\psi_j}{\\partial t}\\right\\rangle+\\left\\langle\\boldsymbol{v}_j \\cdot\n\\nabla_{\\boldsymbol{r}} \\psi_j\\right\\rangle+\\frac{\\boldsymbol{X}_j}{m_j}\n\\cdot\\left\\langle\\nabla_{\\boldsymbol{v}_j} \\psi_j\\right\\rangle\\right] \\\\\n= &amp; 2 \\pi \\sum_i \\iiint \\psi_j\\left(f_j^{\\prime} f_i^{\\prime}-f_j\nf_i\\right)\\left|\\boldsymbol{v}_{\\boldsymbol{i}}-\\boldsymbol{v}_j\\right|\nb \\mathrm{~d} b \\mathrm{~d} \\boldsymbol{v}_i \\mathrm{~d}\n\\boldsymbol{v}_j, \\quad \\forall j\n\\end{aligned}\n\\end{equation}$$\n不变量性质ψ的Enskog方程\n部分性质在碰撞前后不变，即满足： ψi(vi) + ψj(vj) = ψi′(vi′) + ψj′(vj′),  ∀i, j\n可以得到不变量的定理： ∑i, i∭ψj(fi′fj′ − fifj)|vi − vj|b db dvi dvj = 0\n可以得到不变量ψ的方程： $$\\begin{equation}\n\\frac{\\partial}{\\partial t} \\sum_j\n\\rho_j\\left\\langle\\psi_j\\right\\rangle+\\nabla_{\\boldsymbol{r}} \\cdot\n\\sum_j \\rho_j\\left\\langle\\psi_j \\boldsymbol{v}_j\\right\\rangle-\\sum_j\n\\rho_j\\left[\\left\\langle\\frac{\\partial \\psi_j}{\\partial\nt}\\right\\rangle+\\left\\langle\\boldsymbol{v}_j \\cdot\n\\nabla_{\\boldsymbol{r}} \\psi_j\\right\\rangle+\\frac{\\boldsymbol{X}_j}{m_j}\n\\cdot\\left\\langle\\nabla_{\\boldsymbol{v}_j} \\psi_j\\right\\rangle\\right]=0\n\\end{equation}$$\nBoltzmann的H定理\n以下是基于LLM的回答：1. 什么是H定理？H定理是描述一个系统随时间演变向着熵增的方向发展的统计物理原理，由玻尔兹曼在1872年提出。H定理的核心内容在于它提供了一个概率性的框架来理解热力学第二定律，即在一个孤立系统中，总熵不会减少。玻尔兹曼通过引入一个特殊的物理量“H”，证明了在理想气体系统中，这个量随时间单调递减，表明系统趋向于最大熵状态，也就是热力学平衡状态。具体来说，H定理指出，系统的状态函数H(t)，定义为粒子分布函数f的对数乘以f在整个相空间的积分，会随时间单调递减，即dH/dt ≤ 0。等号成立的情况对应于系统达到了平衡态分布（例如麦克斯韦-玻尔兹曼分布）。此外，H定理对于理解热力学和统计力学之间的桥梁具有重要意义。它不仅揭示了单个分子动力学行为与宏观热力学变量之间的关系，也为后续关于系统远离平衡态的研究奠定了基础。2. H定理对于理解热力学和统计力学之间的桥梁有何重要意义？H定理在连接热力学和统计力学之间扮演了桥梁的角色，其重要意义体现在以下几个方面：从微观到宏观：H定理通过玻尔兹曼方程展示了如何从微观的粒子动力学行为出发，推导出宏观的热力学第二定律。这一过程体现了统计力学的一个核心思想，即宏观的不可逆现象（如熵增）可以由微观的可逆机制得出。定义热力学熵：H定理提供了一个可能的途径来定义热力学熵。它探讨了在何种条件下物理量H可以等同于热力学熵，并尝试将两者关联起来。探讨非平衡态：H定理与非平衡态统计物理有着密切的联系。在现代物理学中，对于非平衡系统的理解和描述仍然是一个重要的研究领域，H定理及其相关讨论为这一领域的研究提供了理论基础。引发深入讨论：H定理衍伸出许多关于其真实含意的讨论，这些讨论有助于深化我们对热力学和统计力学概念的理解，例如熵的本质以及它在物理学中的多种表述。总的来说，H定理不仅是理解热力学和统计力学关系的关键，也是推动物理学深入发展的一个动力源泉。\n考虑单组分体系。Boltxmann定义H函数为： H(t) ≡ ∬drdvf(r, v, t)ln f(r, v, t)\nH函数本质上就是“负熵”，以下从本章第一节的Boltamann积分微分方程出发，分析H定理的物理含义。\nH函数对时间求导： $$\\begin{equation}\n\\begin{aligned}\n\\frac{\\mathrm{d} H}{\\mathrm{~d} t}=&amp;\\iint \\mathrm{d} r \\mathrm{~d}\n\\boldsymbol{v}\\left(\\frac{\\partial f}{\\partial t}\\right)(1+\\ln f) \\\\\n=&amp; -\\iint \\mathrm{d} \\boldsymbol{r} \\mathrm{d} \\boldsymbol{v}(1+\\ln\nf) \\boldsymbol{v} \\cdot \\nabla_{\\boldsymbol{r}} f-\\iint \\mathrm{d}\n\\boldsymbol{r} \\mathrm{d} \\boldsymbol{v}(1+\\ln f)\n\\frac{\\boldsymbol{X}}{m} \\cdot \\nabla_{\\boldsymbol{v}} f \\\\\n&amp; +2 \\pi \\iiint \\int \\mathrm{d} b \\mathrm{~d} \\boldsymbol{v}_1\n\\mathrm{~d} \\boldsymbol{r} \\mathrm{d} \\boldsymbol{v} b(1+\\ln\nf)\\left|\\boldsymbol{v}_1-\\boldsymbol{v}\\right|\\left(f^{\\prime}\nf_1^{\\prime}-f f_1\\right) \\\\\n=&amp; 2 \\pi \\iiint \\int \\mathrm{d} b \\mathrm{~d} \\boldsymbol{v}_1\n\\mathrm{~d} \\boldsymbol{r} \\mathrm{d} \\boldsymbol{v} b(1+\\ln\nf)\\left|\\boldsymbol{v}_1-\\boldsymbol{v}\\right|\\left(f^{\\prime}\nf_1^{\\prime}-f f_1\\right) \\\\\n=&amp; 2 \\pi \\iiint \\int \\mathrm{d} b \\mathrm{~d} \\boldsymbol{v}_1\n\\mathrm{~d} \\boldsymbol{r} \\mathrm{d} \\boldsymbol{v} b(1+\\ln\nf)\\left|\\boldsymbol{v}-\\boldsymbol{v}_1\\right|\\left(f_1^{\\prime}\nf^{\\prime}-f_1 f\\right) \\\\\n=&amp;\\frac{1}{2}[(\\cdot)+(\\cdot \\cdot)] \\\\\n=&amp;2 \\pi \\iiint b \\mathrm{~d} b \\mathrm{~d} \\boldsymbol{v}_1\n\\mathrm{~d} \\boldsymbol{r} \\mathrm{d}\n\\boldsymbol{v}\\left|\\boldsymbol{v}_1-\\boldsymbol{v}\\right|\n\\frac{1}{2}\\left(\\left(f^{\\prime} f_1^{\\prime}-f f_1\\right)(1+\\ln\nf)+\\left(f_1^{\\prime} f^{\\prime}-f_1 f\\right)\\left(1+\\ln\nf_1\\right)\\right) \\\\\n=&amp;\\pi \\iiint b \\mathrm{d} b \\mathrm{~d} \\boldsymbol{v}_1 \\mathrm{~d}\n\\boldsymbol{r} \\mathrm{d}\n\\boldsymbol{v}\\left|\\boldsymbol{v}_1-\\boldsymbol{v}\\right|\\left(f^{\\prime}\nf_1^{\\prime}-f f_1\\right)\\left(2+\\ln \\left(f f_1\\right)\\right) \\\\\n=&amp;\\pi \\iiint \\int b \\mathrm{~d} b \\mathrm{~d} v_1 \\mathrm{~d} r\n\\mathrm{~d}\nv\\left|\\boldsymbol{v}_1-\\boldsymbol{v}\\right|\\left(f\\left(\\boldsymbol{v}^{\\prime}\\right)\nf\\left(\\boldsymbol{v}_1^{\\prime}\\right)-f(\\boldsymbol{v})\nf\\left(\\boldsymbol{v}_1\\right)\\right)\\left[2+\\ln \\left(f(\\boldsymbol{v})\nf\\left(\\boldsymbol{v}_1\\right)\\right)\\right] \\\\\n=&amp;\\pi \\iiint \\int b^{\\prime} \\mathrm{d} b^{\\prime} \\mathrm{d}\n\\boldsymbol{v}_1^{\\prime} \\mathrm{d} \\boldsymbol{r} \\mathrm{d}\n\\boldsymbol{v}^{\\prime}\\left|\\boldsymbol{v}_1^{\\prime}-\\boldsymbol{v}\\right|\\left(f(\\boldsymbol{v})\nf\\left(\\boldsymbol{v}_1\\right)-f\\left(\\boldsymbol{v}^{\\prime}\\right)\nf\\left(\\boldsymbol{v}_1^{\\prime}\\right)\\right)\\left[2+\\ln\n\\left(f\\left(\\boldsymbol{v}^{\\prime}\\right)\nf\\left(\\boldsymbol{v}_1^{\\prime}\\right)\\right)\\right] \\\\\n=&amp; \\pi \\iiint \\int b \\mathrm{~d} b \\mathrm{~d} \\boldsymbol{v}_1\n\\mathrm{~d} \\boldsymbol{r} \\mathrm{d}\n\\boldsymbol{v}\\left|\\boldsymbol{v}_1-\\boldsymbol{v}\\right|\\left(f\nf_1-f^{\\prime} f_1^{\\prime}\\right)\\left(2+\\ln \\left(f^{\\prime}\nf_1^{\\prime}\\right)\\right) \\\\\n=&amp; \\pi \\iiint \\int b \\mathrm{~d} b \\mathrm{~d} \\boldsymbol{v}_1\n\\mathrm{~d} r \\mathrm{~d} v\\left|\\boldsymbol{v}_1-\\boldsymbol{v}\\right|\n\\frac{1}{2}\\left(f^{\\prime} f_1^{\\prime}-f f_1\\right)\\left[\\ln \\left(f\nf_1\\right)-\\ln \\left(f^{\\prime} f_1^{\\prime}\\right)\\right] \\\\\n=&amp; \\frac{\\pi}{2} \\iiint \\int b \\mathrm{~d} b \\mathrm{~d}\n\\boldsymbol{v}_1 \\mathrm{~d} \\boldsymbol{r} \\mathrm{d}\n\\boldsymbol{v}\\left|\\boldsymbol{v}_1-\\boldsymbol{v}\\right|(x-y) \\ln\n\\left(\\frac{y}{x}\\right)\n\\end{aligned}\n\\end{equation}$$\n通过分析x, y的大小，可知$\\frac{\\mathrm{~d} H}{\\mathrm{~d} t}\\leq\n0$，称之为H定理。\nH定理受到“可逆性佯谬”与“重现性佯谬”的诘难，为了解释这个问题，需要先讨论“微观上可逆性”与“宏观上不可逆性”的概念。\n微观变化的可逆性与宏观变化的不可逆性\nLagrange方程的时间反演可逆性\nSchrodinger方程的时间反演可逆性\nLoschmidt佯谬\n”Loschmidt佯谬“即“可逆性佯谬”，认为如果在某一时刻，令体系所有分子速度方向反转，v → −v，按照微观运动的可逆性，每个分子将沿原来的轨迹回溯，整体表现出的宏观过程也就逆转了。这与H定理所表现出的宏观不可逆性是矛盾的。\n这里对H定理进行修改，指出并不是严格的下降，在平衡态度也存在涨落，只是涨落很小，涨落很大的概率很小。\n以下使用分子动力学模拟方法，对100个小球进行研究。其中分别在碰撞50次与100次的时候，将速度进行翻转，较大的点表示为速度没有翻转情况，较小的点表示对速度进行翻转。可以看出，在速度未翻转的情况下，H是逐渐下降的，符合H定理的预言。abc三幅图分别表示在不同随机性下的模型，可以发现在随机性较小的情况下，确实H增大到初始状态，但是随着随机涨落变大，可逆性性基本消失。\n\n\nLoschmidt佯谬\n\nZermelo佯谬\n根据动力学理论，孤立有限大保守的动力学体系，在其演化的过程中，经过有限长的时间，总是能回复到任意接近它原来起始的状态。“Zermelo佯谬”也称“重现性佯谬”认为，既然能够接近原来的状态，那么如何认为H定理总是下降？\n调和方案依旧是利用涨落概念，重现初始状态是利用涨落，重现时间相当长。\n这本书并没有更细致的讲解。\n概率论方法\n随机过程\nMarkov过程的时间演化方程称为Fokker-Planck方程。\n联合概率、条件概率、联合条件概率\nMarkov过程、Chapman-Kolmogorov方程\nMarkov过程详细介绍。\nChapman-Kolmogorov方程（简称C-K方程），或称为 Smoluchowski\n方程，描述马尔可夫过程中转移概率之间的联系： P1 ∣ 1(y3, t3 ∣ y1, t1) = ∫dy2P1 ∣ 1(y3, t3 ∣ y2, t2)P1 ∣ 1(y2, t2 ∣ y1, t1)\n主方程\n单位时间内体系y1转移到y2的条件概率密度，概率密度跃迁速度Wt(y1, y2)：\n$$\\begin{equation}\nW_t\\left(y_1, y_2\\right) \\equiv \\lim _{\\tau \\rightarrow\n0}\\left\\{\\frac{P_{1 \\mid 1}\\left(y_2, t_1+\\tau \\mid y_1,\nt_1\\right)}{\\tau}\\right\\}_{y_1 \\neq y_2}\n\\end{equation}$$\nPauli主方程（Master equation）： $$\\begin{equation}\n\\frac{\\partial P_1\\left(y_2, t\\right)}{\\partial t}=\\int_{\\text {all }\ny_1} \\mathrm{~d} y_1\\left\\{W_t\\left(y_1, y_2\\right) P_1\\left(y_1,\nt\\right)-W_t\\left(y_2, y_1\\right) P_1\\left(y_2, t\\right)\\right\\}\n\\end{equation}$$ 右边第一项表示从其它态到y2，第二项表示从y2变化到其它态的项。主方程就是Markov过程概率分布的时间演化。\nFokker-Planck方程\n略去跃迁速度的下标，认为跃迁速度取决于初态及其跃迁幅度ξ ≡ y − y′。\nW(y′, y) ≡ W(y′; y − y′) = W(y′; ξ)\n利用变化与Taylor展开，可将主方程改写为： $$\\begin{equation}\n\\begin{aligned}\n\\frac{\\partial P_1(y, t)}{\\partial t}= &amp; \\int \\mathrm{d} \\xi P_1(y,\nt) W(y ; \\xi)+\\sum_{n=1}^{\\infty} \\frac{(-1)^n}{n !}\n\\frac{\\partial^n}{\\partial y^n}\\left[P_1(y, t) \\int \\mathrm{d} \\xi \\xi^n\nW(y ; \\xi)\\right] \\\\\n&amp; -P_1(y, t) \\int \\mathrm{d} \\xi W(y ;-\\xi)\n\\end{aligned}\n\\end{equation}$$\n可以假定，当|ξ|变大时，跃迁速度W会很快变小。 \nP1(y + Δy, t) ≃ P1(y, t),  ∀|Δy| &lt; δ,\n得到W(y; ξ) = W(y; −ξ)，同时令\nαn(y) ≡ ∫dξξnW(y; ξ)\n得到： $$\\begin{equation}\n\\frac{\\partial P_1(y, t)}{\\partial t}=\\sum_{n=1}^{\\infty}\n\\frac{(-1)^n}{n !} \\frac{\\partial^n}{\\partial y^n}\\left[\\alpha_n(y)\nP_1(y, t)\\right]\n\\end{equation}$$\n如果只取到二次统计矩，忽略高阶统计矩，得到但变的Fokker-Planck方程：\n$$\\begin{equation}\n\\frac{\\partial P_1(y, t)}{\\partial t} \\simeq-\\frac{\\partial}{\\partial\ny}\\left[\\alpha_1(y) P_1(y, t)\\right]+\\frac{1}{2}\n\\frac{\\partial^2}{\\partial y^2}\\left[\\alpha_2(y) P_1(y, t)\\right]\n\\end{equation}$$\n当有两个变量时，对应Chapman-Kolmogorov方程： P1 ∣ 1(x3, y3, t3 ∣ x1, y1, t1) = ∫dx2 dy2P1 ∣ 1(x3, y3, t3 ∣ x2, y2, t2)P1 ∣ 1(x2, y2, t2 ∣ x1, y1, t1)\n同理, 可以得到对应的 Fokker-Planck 方程 $$\n\\begin{aligned}\n\\frac{\\partial P_1(x, y, t)}{\\partial t}= &amp;\n-\\frac{\\partial}{\\partial x}\\left[\\alpha_1 P_1(x, y,\nt)\\right]-\\frac{\\partial}{\\partial y}\\left[\\beta_1 P_1(x, y, t)\\right]\n\\\\\n&amp; +\\frac{1}{2} \\frac{\\partial^2}{\\partial x^2}\\left[\\alpha_2 P_1(x,\ny, t)\\right]+\\frac{1}{2} \\frac{\\partial^2}{\\partial y^2}\\left[\\beta_2\nP_1(x, y, t)\\right]+\\frac{\\partial^2}{\\partial x \\partial y}\\left[\\gamma\nP_1(x, y, t)\\right]\n\\end{aligned}\n$$\n其中 $$\n\\begin{aligned}\n\\alpha_n(x, y) &amp; \\equiv \\iint \\mathrm{d} \\xi \\mathrm{d} \\zeta \\xi^n\nW(x, y ; \\xi, \\zeta) \\\\\n\\beta_n(x, y) &amp; \\equiv \\iint \\mathrm{d} \\xi \\mathrm{d} \\zeta \\zeta^n\nW(x, y ; \\xi, \\zeta) \\\\\n\\gamma(x, y) &amp; \\equiv \\iint \\mathrm{d} \\xi \\mathrm{d} \\zeta \\xi\n\\zeta W(x, y ; \\xi, \\zeta)\n\\end{aligned}\n$$\n从Fokker-Planck方程到Fick定律\nBrown运动、Langevin方程及Fokker-Planck方程\nBrown 运动和Langevin方程\nBrown运动理论的基本方程称为Langevin方程，含有随机力与摩擦力。涨落耗散定理把这些力联系起来。这样一类引入随机过程用来处理复杂体系，或对同一体系相宏观方向提高描述的层次，从而达到粗粒化目的的方法，就是推广意义上的Brown运动。\n无外场Langevin方程\n$$\\begin{equation}\n\\begin{aligned}\n&amp;m \\dot{\\boldsymbol{v}}=-m \\zeta \\boldsymbol{v}+\\boldsymbol{f}(t)\\\\\n&amp;\\dot{\\boldsymbol{v}}=-\\zeta\n\\boldsymbol{v}+\\frac{\\boldsymbol{f}(t)}{m}\n\\end{aligned}\n\\end{equation}$$ 其中f(t)是随机力，−mζv是粘滞力（摩擦力），该方程称为无外场Langevin方程。\n利用Laplace变换： $$\n\\begin{gathered}\ns \\tilde{\\boldsymbol{v}}(s)-\\boldsymbol{v}(0)=-\\zeta\n\\tilde{\\boldsymbol{v}}(s)+\\mathcal{L}\\left(\\frac{\\boldsymbol{f}(t)}{m}\\right)\n\\\\\n\\tilde{\\boldsymbol{v}}(s)=(s+\\zeta)^{-1}\n\\tilde{\\boldsymbol{v}}(0)+(s+\\zeta)^{-1}\n\\mathcal{L}\\left(\\frac{\\boldsymbol{f}(t)}{m}\\right)\n\\end{gathered}\n$$\n再利用反变换得到： $$\n\\boldsymbol{v}(t)=\\mathrm{e}^{-\\zeta t}\n\\boldsymbol{v}(0)+\\mathrm{e}^{-\\zeta t} *\n\\mathcal{L}\\left(\\frac{\\boldsymbol{f}(t)}{m}\\right)\n$$ $$\n\\boldsymbol{v}(t)=\\mathrm{e}^{-\\zeta t} \\boldsymbol{v}(0)+\\int_0^t\n\\mathrm{~d} \\tau \\mathrm{e}^{-\\zeta(t-\\tau)}\n\\frac{\\boldsymbol{f}(\\tau)}{m}\n$$\n右边第一项给出了初始速度的衰减，第二项给出了随机力造成的速度。\n假设随机力的平均值和它的自时间相关函数服从以下关系： ⟨f(t)⟩ = 0 and\n⟨f(t) ⋅ f(t′)⟩ = ϕ(t − t′),\n速度的自时间相关函数\n接下来考虑Brown运动体系处于稳态时长时间的速度的自时间相关函数。\n当t → ∞时，第二项进行变量替换u ≡ t − τ： $$\\begin{equation}\n\\begin{aligned}\n\\lim _{t \\rightarrow \\infty} \\boldsymbol{v}(t) &amp;\\simeq \\lim _{t\n\\rightarrow \\infty} \\int_t^0(-\\mathrm{d} u) \\mathrm{e}^{-\\zeta u}\n\\frac{\\boldsymbol{f}(t-u)}{m}\\\\\n&amp;=\\frac{1}{m} \\int_0^{\\infty} \\mathrm{d} u \\mathrm{e}^{-\\zeta u}\nf(t-u)\n\\end{aligned}\n\\end{equation}$$ 速度的自时间相关函数，用时间平均可表示为： $$\\begin{equation}\n\\begin{aligned}\n\\left\\langle\\boldsymbol{v}(t) \\cdot\n\\boldsymbol{v}\\left(t^{\\prime}\\right)\\right\\rangle &amp;= \\lim _{\\tau\n\\rightarrow \\infty} \\frac{1}{\\tau} \\int_0^\\tau \\mathrm{d} s\n\\boldsymbol{v}(t+s) \\cdot \\boldsymbol{v}\\left(t^{\\prime}+s\\right) \\\\\n&amp;=\\lim _{\\tau \\rightarrow \\infty} \\int_0^{\\infty} \\mathrm{d} u_1\n\\int_0^{\\infty} \\mathrm{d} u_2 \\mathrm{e}^{-\\zeta\\left(u_1+u_2\\right)}\n\\frac{1}{\\tau} \\int_0^\\tau \\mathrm{d} s \\frac{1}{m^2}\n\\boldsymbol{f}\\left(t+s-u_1\\right) \\cdot\n\\boldsymbol{f}\\left(t^{\\prime}+s-u_2\\right)\n\\end{aligned}\n\\end{equation}$$ 考虑随机力的性质： ⟨f(t) ⋅ f(t′)⟩ = ϕ(t − t′) ≃ λδ(t − t′)\n进一步得到 $$\n\\left\\langle\\boldsymbol{v}(t) \\cdot\n\\boldsymbol{v}\\left(t^{\\prime}\\right)\\right\\rangle=\\int_0^{\\infty}\n\\mathrm{d} u_1 \\int_0^{\\infty} \\mathrm{d} u_2\n\\mathrm{e}^{-\\zeta\\left(u_1+u_2\\right)} \\lim _{\\tau \\rightarrow \\infty}\n\\frac{1}{\\tau} \\int_0^\\tau \\mathrm{d} s \\frac{1}{m^2} \\lambda\n\\delta\\left[\\left(t-u_1\\right)-\\left(t^{\\prime}-u_2\\right)\\right],\n$$\n其中对 s 的积分为 $$\n\\begin{aligned}\n\\lim _{\\tau \\rightarrow \\infty} \\frac{1}{\\tau} \\int_0^\\tau \\mathrm{d} s\n\\frac{1}{m^2} \\lambda\n\\delta\\left[\\left(t-u_1\\right)-\\left(t^{\\prime}-u_2\\right)\\right] &amp;\n=\\frac{\\lambda}{m^2}\n\\delta\\left[\\left(t-t^{\\prime}\\right)-\\left(u_1-u_2\\right)\\right] \\lim\n_{\\tau \\rightarrow \\infty} \\frac{1}{\\tau} \\int_0^\\tau \\mathrm{d} s \\\\\n&amp; =\\frac{\\lambda}{m^2}\n\\delta\\left[u_2-\\left(u_1-t+t^{\\prime}\\right)\\right],\n\\end{aligned}\n$$\n进而 $$\n\\begin{aligned}\n\\left\\langle\\boldsymbol{v}(t) \\cdot\n\\boldsymbol{v}\\left(t^{\\prime}\\right)\\right\\rangle &amp;\n=\\int_0^{\\infty} \\mathrm{d} u_1 \\int_0^{\\infty} \\mathrm{d} u_2\n\\mathrm{e}^{-\\zeta\\left(u_1+u_2\\right)} \\frac{\\lambda}{m^2}\n\\delta\\left[u_2-\\left(u_1-t+t^{\\prime}\\right)\\right] \\\\\n&amp; =\\frac{\\lambda}{m^2} \\mathrm{e}^{-\\zeta\\left(t^{\\prime}-t\\right)}\n\\int_0^{\\infty} \\mathrm{d} u_1 \\mathrm{e}^{-2 \\zeta u_1} .\n\\end{aligned}\n$$\n最右边的积分等于 1/(2ζ),\n于是得到 $$\n\\left\\langle\\boldsymbol{v}(t) \\cdot\n\\boldsymbol{v}\\left(t^{\\prime}\\right)\\right\\rangle=\\frac{\\lambda}{2\n\\zeta m^2} \\mathrm{e}^{-\\zeta\\left(t^{\\prime}-t\\right)} .\n$$\n又因为必有 ⟨v(t) ⋅ v(t′)⟩ = ⟨v(t′) ⋅ v(t)⟩,\n故得到 $$\n\\left\\langle\\boldsymbol{v}(t) \\cdot\n\\boldsymbol{v}\\left(t^{\\prime}\\right)\\right\\rangle=\\frac{\\lambda}{2\n\\zeta m^2} \\mathrm{e}^{-\\zeta\\left|t^{\\prime}-t\\right|},\n$$\n即时间相关函数取决于时间间隔的绝对值 |t − t′|. 现在,\n再根据 Brown 运动中的涨落耗散定理, 可以得到稳态时 Brown\n粒子速度的自时间相关函数为 $$\n\\left\\langle\\boldsymbol{v}(t) \\cdot\n\\boldsymbol{v}\\left(t^{\\prime}\\right)\\right\\rangle=\\frac{3\nk_{\\mathrm{B}} T}{m} \\mathrm{e}^{-\\zeta\\left|t^{\\prime}-t\\right|} .\n$$\n根据Doob定理，若Gauss过程的自相关函数是指数形的。则该过程一定是一个Markov过程。\nBrown粒子的均方位移\n得到了稳态时 Brown 粒子速度的自时间相关函数之后, 就可以求解 Brown\n运动中粒子位移平方的系综平均值, 简称均方位移(MSD).\n因为速度是位置的一阶导数, 即 $$\n\\left\\langle\\dot{\\boldsymbol{r}}(t) \\cdot\n\\dot{\\boldsymbol{r}}\\left(t^{\\prime}\\right)\\right\\rangle=\\left\\langle\\boldsymbol{v}(t)\n\\cdot \\boldsymbol{v}\\left(t^{\\prime}\\right)\\right\\rangle \\quad \\text {\n和 } \\quad \\boldsymbol{r}(t)=\\int_0^t \\mathrm{~d} \\tau\n\\boldsymbol{v}(\\tau),\n$$\n于是求解稳态 (即 t ≫ ζ−1 ) 时\nBrown 粒子的均方位移 ⟨r(t)2⟩,\n只需对速度自相关积分两次, 即 $$\n\\begin{aligned}\n\\left\\langle r(t)^2\\right\\rangle=\\lim _{t \\rightarrow\nt^{\\prime}}\\left\\langle\\boldsymbol{r}(t) \\cdot\n\\boldsymbol{r}\\left(t^{\\prime}\\right)\\right\\rangle &amp; =\\lim _{t\n\\rightarrow t^{\\prime}} \\int_0^{t^{\\prime}} \\mathrm{d} \\tau^{\\prime}\n\\int_0^t \\mathrm{~d} \\tau\\left\\langle\\boldsymbol{v}(\\tau) \\cdot\n\\boldsymbol{v}\\left(\\tau^{\\prime}\\right)\\right\\rangle \\\\\n&amp; =\\lim _{t \\rightarrow t^{\\prime}} \\int_0^{t^{\\prime}} \\mathrm{d}\n\\tau^{\\prime} \\int_0^t \\mathrm{~d} \\tau \\frac{\\lambda}{2 \\zeta m^2}\n\\mathrm{e}^{-\\zeta\\left|\\tau-\\tau^{\\prime}\\right|},\n\\end{aligned}\n$$\n即 $$\n\\left\\langle r(t)^2\\right\\rangle=\\int_0^t \\mathrm{~d} \\tau^{\\prime}\n\\int_0^t \\mathrm{~d} \\tau \\frac{\\lambda}{2 \\zeta m^2} \\mathrm{e}^{-\\zeta\n\\mid \\tau-\\tau^{\\prime}} .\n$$\n式 (13.1.3-1) 中的积分属于 I = ∫0t dτ∫0t dτ′f(τ − τ′)\n类型, 可以证明, 此类积分有如下性质: ∫0t dτ∫0t dτ′f(τ − τ′) = ∫0t du(t − u)[f(u) + f(−u)]\n得到： $$\n\\begin{aligned}\n\\left\\langle r(t)^2\\right\\rangle &amp; =\\int_0^t \\mathrm{~d}\n\\tau^{\\prime} \\int_0^t \\mathrm{~d} \\tau \\frac{\\lambda}{2 \\zeta m^2}\n\\mathrm{e}^{-\\zeta\\left|\\tau-\\tau^{\\prime}\\right|}=\\int_0^t \\mathrm{~d}\nu(t-u)\\left[\\frac{\\lambda}{2 \\zeta m^2}\n\\mathrm{e}^{-\\zeta|u|}+\\frac{\\lambda}{2 \\zeta m^2}\n\\mathrm{e}^{-\\zeta|-u|}\\right] \\\\\n&amp; =\\frac{\\lambda}{\\zeta m^2} \\int_0^t \\mathrm{~d} u(t-u)\n\\mathrm{e}^{-\\zeta|u|}=\\frac{\\lambda}{\\zeta m^2} \\int_0^t \\mathrm{~d}\nu(t-u) \\mathrm{e}^{-\\zeta u} .\n\\end{aligned}\n$$\n可以直接积分得到其中的 $$\n\\int_0^t \\mathrm{~d} u(t-u) \\mathrm{e}^{-\\zeta\nu}=\\frac{t}{\\zeta}+\\frac{1}{\\zeta^2}\\left(\\mathrm{e}^{-\\zeta t}-1\\right)\n.\n$$\n于是 $$\n\\left\\langle r(t)^2\\right\\rangle=\\frac{\\lambda}{\\zeta\nm^2}\\left[\\frac{t}{\\zeta}+\\frac{1}{\\zeta^2}\\left(\\mathrm{e}^{-\\zeta\nt}-1\\right)\\right] .\n$$\n在时间较长的情况下有 $$\n\\lim _{t \\rightarrow \\infty}\\left\\langle r^2(t)\\right\\rangle \\simeq\n\\frac{\\lambda}{\\zeta^2 m^2} t .\n$$\n至此, 理论把 Langevin 方程中的摩擦系数 ζm, 随机力强度 λ 与均方位移联系起来了,\n还没有联系到扩散系数 D.\n唯象规律中的扩散系数\n扩散系数D的概念是从实验中引入。 ρv = −D∇ρ\n其中ρ(r, t)表示t时刻r处单位溶液体积内溶质的粒子数，即数密度；v为溶质粒子的速度；D为扩散系数，准确点为平动扩散系数。上式称为Fick第一定律。\n另一方面，从粒子数守恒方程出发： $$\\begin{align}\n0=&amp;\\frac{\\partial \\rho}{\\partial t}+ \\nabla\\cdot(\\rho\n\\boldsymbol{v}) \\\\\n=&amp;  \\frac{\\partial \\rho}{\\partial t}+ \\nabla\\cdot(-D\\nabla\\rho) \\\\\n=&amp; \\frac{\\partial \\rho}{\\partial t}-D \\nabla\\cdot\\nabla\\rho \\\\\n\\frac{\\partial \\rho}{\\partial t}=&amp;D \\nabla^2\\rho\n\\end{align}$$\n称为Fick第二定律，表示溶液中任意一处溶质数密度随时间的增速正比于∇2ρ，比例系数为平动扩散系数。\n以下假设初始情况（t = 0）N个粒子再r0处： ρ(r, 0) = Nδ(r − r0)\n再设G(r, t)dr为t时刻在微体积dr中出现溶质粒子的概率，于是：\n$$\\begin{equation}\nG(r, t) = \\frac{\\rho(r, t)}{N}\n\\end{equation}$$ 因此： $$\\begin{align}\n\\frac{\\partial G(r, t)}{\\partial t}=&amp;D \\nabla^2G(r, t) \\\\\nG(r, 0) =&amp; \\delta(r-r_0)\n\\end{align}$$ 利用傅里叶变换解得： $$\\begin{equation}\nG(r, t)=\\left(\\frac{1}{2 \\pi}\\right)^3\\left(\\frac{\\pi}{D t}\\right)^{3 /\n2} \\mathrm{e}^{-\\frac{\\left|r-r_0\\right|^2}{4 D t}}\n\\end{equation}$$\n任意物理量A(r)的系综平均为： $$\\begin{align}\n\\langle A\\rangle = \\int_\\Omega dr A(r)G(r, t)\n\\end{align}$$\n从Langevin方程到Fokker-Planck方程\n无外场Langevin方程的Fokker-Planck方程\n设Brown粒子的速度平均为ξ，在t时刻粒子速度处于|ξ, ξ + dξ|的概率为P(ξ, t)，概率密度的定义为：\n$$\\begin{align}\nP(\\xi, t)\\equiv \\langle\\delta(\\xi-v(t))\\rangle\n\\end{align}$$ 密度与概率密度之间的对应关系为： $$\\begin{equation}\n\\begin{array}{ccccc}\n\\hline \\rho(\\boldsymbol{r})=\\sum_{i=1}^N\n\\delta\\left(\\boldsymbol{r}-\\boldsymbol{r}_{\\boldsymbol{i}}\\right) &amp;\n\\rho(\\boldsymbol{r}) &amp; \\boldsymbol{r} &amp; \\boldsymbol{r}_i &amp;\n\\sum_{i=1}^N(\\cdot) \\\\\n\\hline P(\\boldsymbol{\\xi}, t)\n\\equiv\\langle\\delta(\\boldsymbol{\\xi}-\\boldsymbol{v}(t))\\rangle &amp;\nP(\\boldsymbol{\\xi}, t) &amp; \\boldsymbol{\\xi} &amp; \\boldsymbol{v}(t)\n&amp; \\langle\\cdot\\rangle \\\\\n\\hline\n\\end{array}\n\\end{equation}$$ 求某物理量的运动方程就是求P的时间偏导数。\n$$\\begin{equation}\n\\begin{aligned}\n\\frac{\\partial}{\\partial t} P(\\boldsymbol{\\xi},\nt)&amp;=-\\frac{\\partial}{\\partial\n\\boldsymbol{\\xi}}\\langle\\delta(\\boldsymbol{\\xi}-\\boldsymbol{v}(t))\n\\dot{\\boldsymbol{v}}(t)\\rangle \\\\\n&amp;\n=\\frac{\\partial\\langle\\delta(\\boldsymbol{\\xi}-\\boldsymbol{v}(t))\\rangle}{\\partial(\\boldsymbol{\\xi}-\\boldsymbol{v}(t))}\n\\frac{\\partial(\\boldsymbol{\\xi}-\\boldsymbol{v}(t))}{\\partial\nt}=\\frac{\\partial\\langle\\delta(\\boldsymbol{\\xi}-\\boldsymbol{v}(t))\\rangle}{\\partial\n\\boldsymbol{\\xi}}[-\\dot{\\boldsymbol{v}}(t)] \\\\\n&amp; =-\\frac{\\partial}{\\partial\n\\boldsymbol{\\xi}}\\langle\\delta(\\boldsymbol{\\xi}-\\boldsymbol{v}(t))\n\\dot{\\boldsymbol{v}}(t)\\rangle \\\\\n&amp; =-\\frac{\\partial}{\\partial\n\\boldsymbol{\\xi}}\\left\\langle\\delta(\\boldsymbol{\\xi}-\\boldsymbol{v}(t))\\left(-\\zeta\n\\boldsymbol{\\xi}+\\frac{\\boldsymbol{f}(t)}{m}\\right)\\right\\rangle \\\\\n&amp; =\\frac{\\partial}{\\partial \\boldsymbol{\\xi}}\\{\\zeta\n\\boldsymbol{\\xi}\\langle\\delta(\\boldsymbol{\\xi}-\\boldsymbol{v}(t))\\rangle\\}-\\frac{1}{m}\n\\frac{\\partial}{\\partial\n\\boldsymbol{\\xi}}\\langle\\delta(\\boldsymbol{\\xi}-\\boldsymbol{v}(t))\n\\boldsymbol{f}(t)\\rangle \\\\\n&amp; =\\frac{\\partial}{\\partial \\boldsymbol{\\xi}}[\\zeta\nP(\\boldsymbol{\\xi}, t) \\boldsymbol{\\xi}]-\\frac{1}{m}\n\\frac{\\partial}{\\partial\n\\boldsymbol{\\xi}}\\langle\\delta(\\boldsymbol{\\xi}-\\boldsymbol{v}(t))\n\\boldsymbol{f}(t)\\rangle\n\\end{aligned}\n\\end{equation}$$\n假设随机力的概率密度为Gauss分布： $$\\begin{equation}\nP[\\boldsymbol{f}(t)]=\\exp \\left\\{-\\int_{t_0}^{t_f} \\mathrm{~d} t\n\\frac{f^2(t)}{4 \\zeta m k_{\\mathrm{B}} T}\\right\\}\n\\end{equation}$$ 其中 t0, tf\n分别为 f(t)\n的初始时间和结束时间. 为了理解泛函型的概率密度, 要对 Gauss\n分布多作些解释: 因为这里整个范围内的随机力函数 f(t) 都与一个标量\nP 对应,\n所以这样的概率密度是一个泛函 P[f(t)],\n而不是复合函数 P(f(t)) 。 相应地,\n概率密度的归一化是泛函积分。\n\n对于一个随机变量归一化的 Gauss 分布 N(μ, σ2),\n其概率密度 (函数) 为 $$\nf(x)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\mathrm{e}^{-\\frac{(z-\\mu)^2}{2\n\\sigma^2}}\n$$ 它满足 ∫−∞∞dxf(x) = 1。\n推广到 n 个随机变量\nx1, x2, ⋯, xn\n(令列阵 x ≡ [x1, x2, ⋯, xn]T\n) 归一化的 Gauss 分布 N(μ, S),\n其概率密度 (函数) 为 $$\nf(\\boldsymbol{x})=\\frac{1}{(2 \\pi|\\boldsymbol{S}|)^{n / 2}}\n\\mathrm{e}^{-\\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^{\\mathrm{T}}\nS^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu})}\n$$\n其中 μ ≡ [μ1, μ2, ⋯, μn]T\n为所有平均值排成的列阵, 协方差阵 $\\boldsymbol{S} \\equiv\n\\frac{1}{n-1}(\\boldsymbol{x}-$ μ)(x − μ)T。\n在现在的情况 (见式 (13.2.1-4)) 下, 随机变量不是离散型的,\n而是一个连续型的函数 f(t),\n相当于无穷多个互为独立的随机自变量. 与此对应, 对于 n 个独立的随机自变量, 并且均值 μ = 0 和\nS = 2ΓkBT1\n的情况, 式 (13.2.1-6) 应该推广、改写为 $$\nf(\\boldsymbol{x})=\\frac{1}{\\left(4 \\pi \\Gamma k_{\\mathrm{B}} T\\right)^{n\n/ 2}} \\mathrm{e}^{-\\frac{1}{4 \\Gamma k_{\\mathrm{B}} T} \\sum_{i=1}^n\nx_i^2} .\n$$\n再从离散型推广到连续型随机变量 x(t)\n就得到泛函型的概率密度为 $$\nf[x(t)]=C \\exp \\left\\{-\\int_{t_0}^{t_f} \\mathrm{~d} t \\frac{x^2(t)}{4\n\\Gamma k_{\\mathrm{B}} T}\\right\\},\n$$\n其中 C 为归一化常数, t0, tf\n分别为 x(t)\n的初始时间和结束时间。\n\n此处省略很多化简步骤\n最终得到： $$\\begin{equation}\n\\frac{\\partial}{\\partial t} P(\\boldsymbol{v}, t)=\\zeta\n\\frac{\\partial}{\\partial \\boldsymbol{v}}[P(\\boldsymbol{v}, t)\n\\boldsymbol{v}]+\\zeta \\frac{k_{\\mathrm{B}} T}{m}\n\\frac{\\partial^2}{\\partial v^2} P(\\boldsymbol{v}, t)\n\\end{equation}$$ 称为Fokker-Planck方程。\n过阻尼Langevin方程的Smoluchowski方程\n有外场Langevin方程的Fokker-Plank方程\n自由Brown运动的Fokker-Planck方程的严格解\n线性响应理论\n静态响应：外场不随时间变化，则体系会在该恒定外场之下达到新的平衡态，求这样响应的平衡统计力学问题。\n动态响应：求体系对外场的瞬时响应，或者周期性外场。\n以下先讨论体系对静态外场的响应，然后讨论对含时外场响应的Green-Kubo线性响应理论。\n静态线性响应\n讨论如何求平衡的线性响应。\n设体系在未受扰动时的 Hamilton 量为 H0(x),其中 x ≡ {q, p}, q ≡ {q1, q2, ⋯, q3N}, p ≡ {p2, p2, ⋯, p3N},\n记恒定外场为 E.\n体系受扰动后的能量增量, 即体系与外场耦合的能量, 设为 H′ = −A(x)E,\n其中 A(x)为体系状态的某个与\nE 共轭的已知函数. “共轭”\n是指若 E 是外电场的电场强度\nE, 则 A 就是体系总的电偶极矩 μ. 与外磁场强度 H 共轭的是体系的总磁矩 M.对应的扰动能量为 H′ = −μ ⋅ E\n和 H′ = −M ⋅ H.\n实际上, 在以下讨论中, E 和\nA的具体形式并不重要.\n扰动时体系的 Hamilton 量为 H(x, E) = H0 + H′ = H0(x) − A(x)E\n经典力学中的静态线性响应\n设未扰动的分布函数f(x)为： $$\\begin{align}\nf(x) = \\frac{1}{Q}\\mathbb{e}^{-\\beta H_0(x)}\n\\end{align}$$ 其中Q = ∫dxe−βH0(x)为未扰动时体系的配分函数，x ≡ (q, p)表示Γ相空间变量。未扰动时，若体系在该外场之下达到平衡，则扰动时的分布函数为：\n$$\\begin{align}\nf(x, E)=&amp;\\frac{1}{Q(E)} \\mathrm{e}^{-\\beta H(x, E)}=\\frac{1}{Q(E)}\n\\mathrm{e}^{-\\beta\\left[H_0(x)-A(x) E\\right]} \\\\\nQ(E)=&amp;\\int \\mathrm{d} x \\mathrm{e}^{-\\beta\\left[H_0(x)-A(x)\nE\\right]}\n\\end{align}$$\n通常做法，把扰动体系的物理量在未扰动体系处展开。将未受扰动的平衡态的系综均值⟨⋅⟩eq。若外场是弱场，则可作近似展开：\n$$\\begin{align}\n\\mathrm{e}^{-\\beta\\left[H_0(x)-A(x) E\\right]}=[1+\\beta\nAE+O(E^2)]\\mathbb{e}^{-\\beta H_0}\n\\end{align}$$ 于是体系配分函数展开为： $$\\begin{align}\nQ(E)=&amp;\\int \\mathrm{d} x \\mathrm{e}^{-\\beta\\left[H_0(x)-A(x)\nE\\right]} \\\\\n=&amp; \\int \\mathrm{d} x [1+\\beta AE+O(E^2)]\\mathbb{e}^{-\\beta H_0} \\\\\n=&amp; Q[1+\\beta\\langle A\\rangle_{eq}E+O(E^2)]\n\\end{align}$$\n可以得到扰动时分布函数的展开为： $$\\begin{equation}\nf(x, E)=\\frac{\\left[1+\\beta A E+O\\left(E^2\\right)\\right]\n\\mathrm{e}^{-\\beta H_0}}{\\left[1+\\beta\\langle A\\rangle_{\\mathrm{eq}}\nE+O\\left(E^2\\right)\\right] Q}=\\frac{1+\\beta A\nE+O\\left(E^2\\right)}{1+\\beta\\langle A\\rangle_{\\mathrm{eq}}\nE+O\\left(E^2\\right)} f(x)\n\\end{equation}$$ 根据|x| &lt; 1时$\\frac{1}{1+x}$的级数展开： $$\\begin{align}\n\\frac{1+\\beta A E+O\\left(E^2\\right)}{1+\\beta \\langle\nA\\rangle_{\\mathrm{eq}} E+O\\left(E^2\\right)}= 1+\\beta[A-\\langle\nA\\rangle_{eq}]E+O(E^2)\n\\end{align}$$ 得到： $$\\begin{align}\nf(x, E)=\\left \\{ 1+\\beta[A-\\langle A\\rangle_{eq}]E\\right\\}f(x)+O(E^2)\n\\end{align}$$ 其中⟨A⟩eq为未扰动时平衡态A的均值，不失普遍性的可令⟨A⟩eq = 0，因为A是扰动项的共轭物理量，在平衡没有扰动的情况下，可以认为该物理量是不存在的。\n设B(x)为体系的任意力学量，扰动时其均值为：\n$$\\begin{align}\n\\langle B(E) \\rangle =&amp; \\int dx f(x, E)B(x) \\\\\n=&amp;\\int dx f(x)\\left [ 1+\\beta A(x) E\\right]B(x)+O(E^2) \\\\\n=&amp; \\langle B\\rangle_{eq} +\\beta\\langle AB\\rangle_{eq}E+O(E^2) \\\\\n\\langle \\Delta B(E) \\rangle \\equiv&amp; \\langle B(E) \\rangle -\\langle B\n\\rangle_{eq} \\\\\n=&amp; \\chi_{BA}E+O(E^2) \\\\\n\\chi_{BA}=&amp; \\beta\\langle AB\\rangle_{eq}\n\\end{align}$$ 其中χBA称为广义极化率，第二个下标A为外场E共轭的那个体系的力学量，即外因E是通过内因A对体系的任意力学量B起作用的，那个作用就是响应，也就是第一个下标B。若取力学量B为体系总的电偶极矩M，则χBA就是电极化率。当高次项可以忽略的时候，可以得到线性响应为：\n⟨ΔB(E)⟩ = χBAE\n上式表示在施加弱外场E时，外场E通过与体系种共轭力学量A的相互作用，造成任意力学量B产生响应的增量。广义极化率χBA表示单位外场E通过A造成力学量B的响应增量。\n量子力学中的静态线性响应\n动态线性响应\n经典力学中的动态线性响应\nKubo变换\n复数方法、响应的频率关系\n响应函数的客观属性\nKramers-Kronig关系式\n线性响应理论的应用\nZwanzig-Mori投影算符理论\n近平衡体系时有两种方法： 1. 概率论方法\n在适当假设的基础上求出概率密度服从的方程，如Fokker-Planck方程、主方程 2.\n基于Langevin方程或广义Langevin方程\n直接求目标随机变量的均值，如求Brown运动粒子其速度服从的方程。\n以上两种方法在一定程度上需要借助唯象规律，即根据经验规律将随机变量假定成某种特定的形式。\n许多人设法给Fokker-Planck方程、Langevin方程一个微观基础，重要进展是R.Zwanzig的投影算符方法。他个呢局第一性原理从Liouville方程出发，严格推导出广义Kokker-Planck方程。几年后，Hazime\nMori用投影算符方法得到广义Langevin方程。\nZwanzig-Mori理论统一了各种非平衡态的问题经验方程，提供了一普适性更强的方法，给线性响应理论提供严格的理论基础，给出计算相关函数的新方法。\n密度泛函理论\n多电子体系的基态能量是电子密度的唯一泛函，在真实的基态电子密度时，体系能量泛函必定达到极小；在介观层次液体理论中，经典的Helmholtz自由能、巨势也是体系数密度的唯一泛函。\n多电子体系的密度泛函理论\nHohenberg-Kohn第一第二定理为电子密度泛函的基石，将基于波函数基础上的多电子体系量子理论经过统计粗粒化，改造成以电子数密度为基础的理论。\nHohenberg-Kohn第一定理\nHohenberg-Kohn第一定理：多电子体系的基态是无论是非简并的或是简并的，则该基态体系中核与电子的相互作用势能v(r)唯一地取决于体系的电子密度ρ(r)（只差一个无关紧要的常数）。\nHohenberg-Kohn第二定理\nHohenberg-Kohn第二定理给出了电子密度泛函理论的能量变分原理。\n用Rayleigh-Ritz变分原理导出量子力学的定态Schrodinger方程H|Ψ⟩ = E|Ψ⟩，体系能量的均值为⟨Ψ|H|Ψ⟩，同时体系波函数必须归一化⟨Ψ|Ψ⟩ = 1，把这个当成约束同时利用改变波函数求能量均值的最小值。利用Lagrange乘子法，变为一个无约束的变分问题：\nΩ ≡ ⟨Ψ|H|Ψ⟩ − ε(⟨Ψ ∣ Ψ⟩ − 1)\n其中 ε 为待定常数, 即所谓\nLagrange 待定乘子. 于是达到极值时必有 $$\n0=\\frac{\\partial\n\\Omega}{\\partial|\\Psi\\rangle}=\\frac{\\partial}{\\partial|\\Psi\\rangle}\\{\\langle\\Psi|H|\n\\Psi\\rangle-\\varepsilon(\\langle\\Psi \\mid\n\\Psi\\rangle-1)\\}=H|\\Psi\\rangle+\\left[\\left\\langle H^{\\dagger}\n\\Psi\\right|\\right]^{\\dagger}-\\varepsilon|\\Psi\\rangle-\\varepsilon[\\langle\\Psi|]^{\\dagger},\n$$\n于是得到 H|Ψ⟩ = ε|Ψ⟩\n接下来考虑电子密度泛函理论的数密度ρ(r)的变分原理。将能量泛函的外场项记为Ev[ρ]。体系电子总能量应为三相之和：电子总动能T，核与电子的相互作用Vne，电子间相互作用Vee：\nEv[ρ] = T[ρ] + Vne[ρ] + Vee[ρ] = FHK[ρ] + ∫v(r)ρ(r)dr\n其中定义 $$\n\\begin{gathered}\nF_{\\mathrm{HK}}[\\rho] \\equiv\nT[\\rho]+V_{\\mathrm{ee}}[\\rho]=\\left\\langle\\Psi\\left|T+V_{\\mathrm{ee}}\\right|\n\\Psi\\right\\rangle, \\\\\nV_{\\mathrm{ee}}[\\rho] \\equiv J[\\rho]+(\\text { not classical }) \\simeq\nJ[\\rho]+E_{\\mathrm{xc}}[\\rho],\n\\end{gathered}\n$$\nJ[ρ]为根据经典电动力学计算该体系的电子间作用势能（静电势能or\n库伦势能）： $$\\begin{align}\nJ[\\rho]=\\frac{1}{2}\\iint\\frac{\\rho(r_1)\\rho(r_2)}{|r_1-r_2|}dr_1dr_2\n\\end{align}$$ 在电子间作用势能Vee[ρ]种扣除J[ρ]之后得到的非经典项的主要部分Exc[ρ]，称为交换相关能。\n另一方面电子密度ρ(r)在全空间积分为N： ∫drρ(r) = N\nHohenberg-Kohn第二定理：设ρ̃(r)为“试探密度“，同时满足条件0 ≤ ρ̃(r)和∫drρ̃(r) = N。将ρ̃(r)代入体系的能量表达式，有：\n$$\\begin{align}\nE_0\\leq E_v[\\tilde \\rho]\n\\end{align}$$ 其中E0为基态能量。\nv 可表示性 ( v-representable): 设多电子体系的\nHamilton 量为 $$\nH=\\sum_{i=1}^N\\left(-\\frac{1}{2} \\nabla_i^2\\right)+\\sum_{i=1}^N\nv\\left(\\boldsymbol{r}_i\\right)+\\sum_{i&lt;j}^N \\frac{1}{r_{i j}} .\n$$\n若电子密度 ρ(r) 具有与 H 对应的反对称性基态波函数,\n则该密度称为可表达外势 v(r) 的, 即所谓具有\nv 可表示性.\n由此, 可以把 Hohenberg-Kohn 第一定理重新表述如下:\n多电子体系的基态波函数与 v\n可表示的密度 ρ(r) 是一一对应的,\n所以从这样的密度 ρ(r)\n出发就可以得到该基态的一切性质.\nHohenberg-Kohn 第二定理可重新表述如下: 对于所有的 v 可表示的密度 ρ(r),存在 Ev[ρ] = FHK[ρ] + ∫drρ(r)v(r) ≥ Ev[ρ0],\n其中 Ev[ρ0]\n为含外场 v(r)\n的 Hamilton 量体系的基态能量, ρ0 为基态密度.\nLevy约束搜索法\n根据Hohenberg-Kohn第一定理，基态的电子密度ρ0(r)与基态波函数Ψ0之间是一一对应的，因此接下来需要知道如何从给定的ρ0中求出Ψ0。\n基于第一性原理的电负性、绝对硬度、Fukui函数\n最大硬度原理\n介观体系的密度泛函理论\n","categories":["Statistical Physics"],"tags":["Nonequilibrium Thermodynamics","基本概念","系综","Clasical dynamics"]},{"title":"Robustness May Be at Odds with Accuracy","url":"/2026/01/12/ML/RobustOddWithAcc/RobustOddWithAcc/","content":"研究发现模型的正确率与鲁棒性之间存在取舍，宾且这种现象不针对特定模型，是一个具有普适的现象。这种取舍带来了意想不到的收益，模型可以提取出人类的感知以及数据特征。\nReference: * Robustness May Be at\nOdds with Accuracy\n\n展现了标准正确率与鲁棒性之间的细微差别，这两者是不兼容的。而且这种排他性，不仅仅是网络中存在，在自然的设置中同样存在。\n主要存在两个问题： 1.\n文章通过什么方式说明，鲁棒性和正确率是不兼容的？ 2.\n为什么作者认为这种不兼容性是根植于自然的？一个神经网络的现象为什么和自然有关？\n鲁棒性\n神经网络的训练目标，是在数据集上让似然最大化： $$\\begin{align}\n\\argmin_\\theta \\underset{(x, y) \\sim D}{E} [\\max_{\\delta \\in \\Delta} L(x\n+ \\delta, y; \\theta)]\n\\end{align}$$\n对抗攻击训练是一个minmax训练，在一定攻击强度下让模型的正确率最大：\n$$\\argmin_\\theta E_{(x, y) \\sim D}\n[\\max_{\\delta \\in \\Delta} L(x + \\delta, y; \\theta)]$$\n对抗攻击训练包含生成新的训练数据集D̂，然后训练模型参数： $$\\begin{align}\n\\argmin_\\theta \\underset{(x, y) \\sim \\widehat{D} }{E} [\\max_{\\delta \\in\nS} L(x + \\delta, y; \\theta)]\n\\end{align}$$\n通过鲁棒性训练的模型是否在任何情况下都比标准训练优秀，通过实验进行对比。\n \n以上是三种不同的数据集，分别在不同的对抗攻击训练下的标准正确率。同时使用不同规模的训练大小数据集。可以看出来标准训来模型的正确率普遍好于对抗攻击模型，除了在MNIST在小数据集下表现不同。可以得到一个结论：\n\n为什么正确率和鲁棒性看起来像是一对取舍？\n\n理论\n假设一个合成数据： $$\\begin{equation}\ny \\stackrel{u.a.r}{\\sim} \\{-1, +1\\},\\qquad\nx_1 = \\begin{cases}\n        +y, &amp;\\text{w.p. }p\\\\\n        -y, &amp;\\text{w.p. }1-p\n      \\end{cases},\\qquad\nx_2,\\ldots,x_{d+1} \\stackrel{i.i.d}{\\sim} \\N(\\eta y,1),\n\\end{equation}$$\n通过这样的二分类任务，进行理论分析，可以得到如下结论： &gt;\n对于任何类别，在 D数据集上至少存在 1 − δ 准确率，在 l∞攻击下鲁棒性有$\\frac{p}{1-p}\\delta$ 正确率，当 ϵ ≥ 2η。\n可以发现，在理论分析下，对抗攻击和正确率是跷跷板的两端。\n意外惊喜\n鲁棒性训练会使得模型更加倾向人类对图片的理解：\n\n\n在输入数据下的梯度\n\n可以看到在对抗训练下，模型的梯度会反映与人类十分类似的梯度信息。\n同时可以将这个梯度进行平滑，可以发现可以通过对抗攻击将图片进行平滑的修改\n\n如上图所示，模型可以将乌龟逐渐改为孔雀，猫修改为两只狗。\n","categories":["Machine Learning"],"tags":["Robustness"]}]